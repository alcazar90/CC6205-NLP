{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zbrMqMPyncTC"
      },
      "source": [
        "# **Tarea 1 - CC6205 Natural Language Processing üìö**\n",
        "\n",
        "**Integrantes:** Crist√≥bal Alc√°zar, Gianina Salom√≥\n",
        "\n",
        "**Fecha l√≠mite de entrega üìÜ:** Martes 4 de Abril.\n",
        "\n",
        "**Tiempo estimado de dedicaci√≥n:** \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D1HFX-9PpxF9"
      },
      "source": [
        "` ` \n",
        "\n",
        "\n",
        "Bienvenid@s a la primera tarea en el curso de Natural Language Processing (NLP). Esta tarea tiene como objetivo evaluar los contenidos te√≥ricos de las primeras semanas de clases, enfocado principalmente en ***Information Retrieval (IR)*** y ***Vector Space Models***. Si a√∫n no han visto las clases, se recomienda visitar los links de las referencias.\n",
        "\n",
        "La tarea consta de una parte te√≥rica que busca evaluar conceptos vistos en clases. Seguido por una parte pr√°ctica con el f√≠n de introducirlos a la programaci√≥n en Python enfocada en NLP. \n",
        "\n",
        "` ` \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "**Instrucciones:**\n",
        "- La tarea se realiza en grupos de **m√°ximo** 2 personas. Puede ser invidivual pero no es recomendable.\n",
        "- La entrega es a trav√©s de u-cursos a m√°s tardar el d√≠a estipulado arriba. No se aceptan atrasos.\n",
        "- El formato de entrega es este mismo Jupyter Notebook.\n",
        "- Al momento de la revisi√≥n tu c√≥digo ser√° ejecutado. Por favor verifica que tu entrega no tenga errores de compilaci√≥n. \n",
        "- Est√° **PROHIBIDO** usar cualquier librer√≠a que implemente los algoritmos pedidos (Spacy, scikit, etc). S√≥lo se podr√°n utilizar las librer√≠as importadas al inicio de la secci√≥n de pr√°ctica.\n",
        "- En el horario de auxiliar pueden realizar consultas acerca de la tarea a trav√©s del canal de Discord del curso. \n",
        "\n",
        "\n",
        "\n",
        "Ahora s√≠, empecemos! üòÑüöÄ\n",
        "\n",
        "` ` \n",
        "\n",
        "**Referencias:**\n",
        "\n",
        "\n",
        "Slides:\n",
        "    \n",
        "- [Introducci√≥n al curso](https://github.com/dccuchile/CC6205/blob/master/slides/NLP-introduction.pdf)\n",
        "- [Vector Space Model / Information Retrieval](https://github.com/dccuchile/CC6205/blob/master/slides/NLP-IR.pdf)    \n",
        "\n",
        "Videos: \n",
        "\n",
        "- [CC6205 - Procesamiento de Lenguaje Natural: CC6205 - Procesamiento de Lenguaje Natural: Introducci√≥n parte I](https://www.youtube.com/watch?v=HEKTNOttGvU)\n",
        "- [CC6205 - Procesamiento de Lenguaje Natural: CC6205 - Procesamiento de Lenguaje Natural: Introducci√≥n parte II](https://www.youtube.com/watch?v=P8cwnI-f-Kg)\n",
        "- [CC6205 - Procesamiento de Lenguaje Natural: Vector Space Model and Information Retrieval parte 1](https://youtu.be/FXIVClF370w)\n",
        "- [CC6205 - Procesamiento de Lenguaje Natural: Vector Space Model and Information Retrieval parte 2](https://youtu.be/f8nG1EMmPZk)\n",
        "\n",
        "` ` \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hJshpe1yrKJr"
      },
      "source": [
        "## **1 - Preguntas te√≥ricas üìï (2 puntos).** ##\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MBEDKXBPoA7w"
      },
      "source": [
        "Las siguientes celdas contienen preguntas acerca del contenido visto en clases y en el material del curso.  Contestar cada pregunta en su celda correspondiente y **no extenderse m√°s de 100 palabras** . üôè\n",
        "` ` "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xNJPR1kMrw9R"
      },
      "source": [
        "**Pregunta 1 (0.2 puntos): ¬øPor qu√© el an√°lisis del lenguaje humano es una tarea compleja? Mencione dos razones seg√∫n lo visto en clases. Debe citar la slide donde cree que est√° la respuesta.**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mlTBYHEptdde"
      },
      "source": [
        "` ` \n",
        "**Desaf√≠os debido a sus propiedades**\n",
        "- _Discreto_: Las letras de una palabra no entregan mucha informaci√≥n sobre la relaci√≥n entre ellas.\n",
        "- _Composicional_: El significado de una oraci√≥n va m√°s all√° del significado individual de las palabras (depende del orden).\n",
        "- _Disperso_: Existen infinitas combinaciones de palabras.\n",
        "\n",
        "**Desaf√≠os asociados a los datos de entrenamiento**\n",
        "\n",
        "- _Costos de etiquetado_: En ML supervisado. Esto puede significar un costo de trabajo humano y tiempo.\n",
        "- _Variaciones del dominio_: Los patrones del lenguaje pueden cambiar de un corpus a otro dependiendo del tema. Adem√°s, el lenguaje evoluciona en el tiempo, por lo que un modelo entrenado puede quedar desactualizado.\n",
        "\n",
        "` ` \n",
        "_Referencia: Presentaci√≥n \"Natural Language Processing\n",
        "Introduction\", diapositivas 16 y 22_."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tVMXilrYsiSZ"
      },
      "source": [
        "**Pregunta 2 (0.4 puntos): ¬øCu√°les son las diferencias entre usar Deep learning y Machine Learning cl√°sico (empirismo) para un problema de NLP? Ejemplifique con alguna task.** Puede utilizar ChatGPT (debe indicarlo) para generar la respuesta y luego debe indicar si la respuesta entregada por ChatGPT es correcta o no. Mencione por qu√© seg√∫n lo visto en clases.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_QXWMzpTtBZL"
      },
      "source": [
        "` ` \n",
        "ML cl√°sico requiere de una construcci√≥n manual de caracter√≠sticas (considera ling√º√≠stica) y en general trabaja con bolsas de palabras. En cambio DL construye las caracter√≠sticas durante el entrenamiento y trabaja con word embeddings, adem√°s de requerir mucho mayor volumen de datos y por ende recursos. \n",
        "\n",
        "**Ejemplo: Clasificaci√≥n de correo spam / no spam**\n",
        "\n",
        "Con ML cl√°sico se puede entrenar un modelo de Multinomial Naive Bayes (utiliza frecuencia de palabras en cada clase), mientras que con DL se puede entrenar una red MLP directamente desde el input, aprendiendo las caracter√≠sticas (word embeddings), m√°s una capa de salida de clasificaci√≥n.\n",
        "` ` \n",
        "\n",
        "_No se utiliz√≥ ChatGPT. Referencias: Presentaci√≥n \"Natural Language Processing Introduction\", diapositiva 27_, y cursos de Aprendizaje de m√°quinas y de Deep Learning."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " **Pregunta 3 (0.4 puntos) Seg√∫n las primeras clases, ¬øQu√© m√©todo cl√°sico nos permite rankear las similitudes existentes entre documentos?, ¬øC√≥mo son las representaciones que genera y problemas que podr√≠an experimentar estas soluciones simples?** "
      ],
      "metadata": {
        "id": "XXc4XuVG7Loa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "` ` \n",
        "Un m√©todo que permite esto es la similitud coseno. Esta usa representaciones vectoriales de las palabras, que se pueden obtener mediante el vector space model, o \"bag of words\"; Esto logra que documentos de distinto largo residan en el mismo espacio vectorial. Como problema, se pierde la estructura ling√º√≠stica lo cual no es ideal en algunas tareas. Se debe adem√°s suavizar para que todos los t√©rminos tengan ocurrencia y evitar indefiniciones (Ej: Agregar 0.5 a cada frecuencia).\n",
        "\n",
        "Un problema del rankeo por similitud coseno es que no considera relevancia de los documentos, cosa que s√≠ hacen los buscadores web.\n",
        "` ` \n",
        "\n",
        "_Referencia: Presentaci√≥n \"Natural Language Processing\n",
        "Vector Space Model and Information Retrieval\", diapositivas 12-16_."
      ],
      "metadata": {
        "id": "rtaQ_aVE8LhH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Pregunta 4 (0.4 puntos) Usted se encuentra realizando un modelo de clasificaci√≥n de sentimientos con texto, su jefe le se√±ala que debe eliminar las palabras mas comunes para obtener una mejor clasificaci√≥n. ¬øQu√© palabras le se√±ala que elimine su jefe?, ¬øes acaso esto una buena idea?.** Puede utilizar ChatGPT (debe indicarlo) para generar la respuesta y luego debe indicar si la respuesta entregada por ChatGPT es correcta o no. Mencione por qu√© seg√∫n lo visto en clases."
      ],
      "metadata": {
        "id": "EKNDNy047tcY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "` ` \n",
        "El jefe sugiere eliminar palabras con frecuencia sobre x%. No es una buena idea, ya que dentro de estas palabras podr√≠a haber palabras comunes como \"no\", que puede ser indicativas de sentimiento (en este caso negativo). Por ejemplo, frases como \"no me gusta\" o \"no me siento bien\" quedar√≠an como \"gusta\" y \"siento bien\", que podr√≠an clasificarse err√≥neamente como positivas, siendo que en realidad son negativas. Adem√°s, si se trabaja con textos cortos pueden generarse textos que pierden el sentido original. Por esto es importante revisar el caso particular y no usar siempre t√©cnicas est√°ndar (ej: eliminar stopwords de nltk).\n",
        "` ` \n",
        "\n",
        "_No se us√≥ ChatGPT. Referencia: Presentaci√≥n \"Natural Language Processing Vector Space Model and Information Retrieval\", diapositiva 4, y video de la clase_.\n"
      ],
      "metadata": {
        "id": "cRe4QaGS8MqY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Pregunta 5 (0.6 puntos): Acorde al paper [A Vector Space Model for automatic indexing](https://dl.acm.org/doi/pdf/10.1145/361219.361220) un documento, $D_i$, puede ser definido formalmente como una tupla de t√©rminos, $(d_{i1}, d_{i2}, ..., d_{in})$, donde $d_{ij}$ representa el paso del j-esimo t√©rmino. En clase vieron algunas formas medir los pesos de estos t√©rminos. Mencione cuales fueron y sus ventajas y desventajas.** "
      ],
      "metadata": {
        "id": "uPkWmrmLHWnQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "` ` \n",
        "**Booleano**\n",
        "- Ventaja: Simple de construir.\n",
        "- Desventaja: No considera la frecuencia de los t√©rminos; Puede dar el mismo ranking a dos documentos, siendo que uno de ellos mencione m√°s veces los t√©rminos de la query.\n",
        "\n",
        "**Term Frequency**\n",
        "- Ventaja: S√≠ considera la frecuencia de los t√©rminos.\n",
        "- Desventaja: No normaliza las frecuencias; T√©rminos frecuentes en todos los documentos debiesen penalizarse.\n",
        "\n",
        "**Tf-Idf**\n",
        "- Ventaja: Asigna mayor peso a t√©rminos frecuentes en el documento e infrecuentes en el corpus.\n",
        "- Desventaja: Igual que los anteriores, no considera la ling√º√≠stica. Adem√°s, palabras presentes en un documento (y no en el corpus) no son necesariamente relevantes para su tema.\n",
        "` ` \n",
        "\n",
        "_Referencia: Presentaci√≥n \"Natural Language Processing Vector Space Model and Information Retrieval\", diapositivas 12-14_."
      ],
      "metadata": {
        "id": "JLqRTW08SzDN"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Fpsz2pQt8x5"
      },
      "source": [
        "## **2 - Preguntas pr√°cticas üíª (4 puntos).** ##"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YB92kQXspvbR"
      },
      "source": [
        "Esta segunda secci√≥n incluye ejercicios de programaci√≥n ü§ô. Leer atentamente las instrucciones entregadas a continuaci√≥n para facilitar el proceso de revisi√≥n de sus trabajos.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PosWgWgRxHKp"
      },
      "source": [
        "` ` \n",
        "\n",
        "**Instrucciones:**\n",
        "\n",
        "\n",
        "\n",
        "- Escribe tu c√≥digo entre las lineas de comentarios **### Aqu√≠ inicia tu c√≥digo ###** y **### Aqu√≠ termina tu c√≥digo ###**.\n",
        "- Cuando el ejercicio incluya un bloque llamado ***Test***, comprueba que el resultado de la ejecuci√≥n coincida con el resultado esperado.\n",
        "- Recuerde siempre mantener buenas pr√°cticas de c√≥digo.\n",
        "- Est√° permitido s√≥lo utilizar las librer√≠as importadas antes del Ejercicio 1.\n",
        "- **Recordar** que: *Documento = Oraci√≥n. Dataset = Corpus. Vocabulario = Tokens*.\n",
        "- El **orden de los resultados** pueden variar dependiendo de su m√°quina, pero los valores de los resultados son los mismos.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jBrmFHXhqUww"
      },
      "source": [
        "**Ejemplo:** Implemente una funci√≥n **`hello_world()`** que imprima en pantalla `\"Hello World\"`. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tu7cIsawyJHx"
      },
      "source": [
        "def hello_world():\n",
        "  ### Aqu√≠ inicia tu c√≥digo ###\n",
        "  print(\"Hello World\")\n",
        "  ### Aqu√≠ termina tu c√≥digo ###"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fz6klw12lwbW"
      },
      "source": [
        "***Test:***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ac-WMk2dyQbp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "199a74e5-438d-4a47-d390-90cee47cad0c"
      },
      "source": [
        "hello_world()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello World\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fIoiAMxtyUjQ"
      },
      "source": [
        "***Resultado esperado***: \n",
        "<table>\n",
        "    <tr> \n",
        "        <td> Hello World </td> \n",
        "    </tr>\n",
        "</table> \n",
        "\n",
        "``\n",
        "``\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dlPyrPXiH0l4"
      },
      "source": [
        "Estas son las librer√≠as permitidas. Si quieren utilizar alguna librer√≠a adicional, pueden realizar la consulta a trav√©s de Discord. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CtP6Emjo1kF0"
      },
      "source": [
        "import codecs\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from string import punctuation"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "En caso de desarrollar la tarea desde colab, utilizar el siguiente c√≥digo para cargar los archivos desde el drive:"
      ],
      "metadata": {
        "id": "Bj9Do0LdC9w2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```python\n",
        "try:\n",
        "    from google.colab import drive\n",
        "\n",
        "    drive.mount(\"/content/drive\")\n",
        "    path = 'path/to/marcianeke.txt'\n",
        "except: \n",
        "    print('Ignorando conexi√≥n drive-colab')\n",
        "```"
      ],
      "metadata": {
        "id": "Kt3qGK44hEx5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Archivo descargado directamente desde repositorio de GitHub\n",
        "!wget https://raw.githubusercontent.com/alcazar90/CC6205-NLP/main/data/marcianeke.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0TpewI7bg8Vz",
        "outputId": "9f752f95-37f6-4735-bb98-e1d6135b1995"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-03-23 11:46:22--  https://raw.githubusercontent.com/alcazar90/CC6205-NLP/main/data/marcianeke.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2084 (2.0K) [text/plain]\n",
            "Saving to: ‚Äòmarcianeke.txt‚Äô\n",
            "\n",
            "marcianeke.txt      100%[===================>]   2.04K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-03-23 11:46:22 (42.8 MB/s) - ‚Äòmarcianeke.txt‚Äô saved [2084/2084]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tSN4bBoY2Td4"
      },
      "source": [
        "` ` \n",
        "\n",
        "**Ejercicio 1 - *Tokenizaci√≥n* (0.5 puntos).** \n",
        "` `  \n",
        "` ` \n",
        "\n",
        "En el primer ejercicio veremos la dificultad üò® de tokenizar textos no estructurados, destacando la importancia de tener librer√≠as que realicen este trabajo. \n",
        "\n",
        "El archivo adjunto al enunciado de la tarea contiene la letra de una canci√≥n del marcianeke üëΩ. Utilice este texto para realizar su primera tokenizaci√≥n y ver qu√© tan bien funciona su funci√≥n. \n",
        "\n",
        "Ejecute el c√≥digo a continuaci√≥n para cargar el ejemplo. Recuerde realizar la modificaci√≥n al directorio en caso que el archivo no se encuentre en el mismo directorio del Jupyter Notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FnNUYlWo21g4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bae26428-dfdc-4729-d257-7912a1b634f7"
      },
      "source": [
        "text = codecs.open('marcianeke.txt', 'r', 'UTF-8').read()\n",
        "print(text)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Brr\r\n",
            "Marcianeke\r\n",
            "Vamo' a estar con Pailita\r\n",
            "Dimelo m√°\r\n",
            "Ando en busca de una criminal (ah, ah)\r\n",
            "Esa que el gatillo le gusta jalar (rata-ta)\r\n",
            "Que le guste flotar y fumar (brr)\r\n",
            "Tussi, keta quiere' mezclar\r\n",
            "Dimelo m√°\r\n",
            "\r\n",
            "Ando en busca de una criminal (ah, ah)\r\n",
            "Esa que el gatillo le gusta jalar (rata-ta)\r\n",
            "Que le guste flotar y fumar\r\n",
            "Tussi, keta pura quiere' mezclar\r\n",
            "Di-dimelo m√°\r\n",
            "Di-dimelo m√°\r\n",
            "Di-dimelo m√°\r\n",
            "Di-dimelo m√°\r\n",
            "Di-dimelo m√°\r\n",
            "Di-dimelo m√°\r\n",
            "Di-dimelo m√°\r\n",
            "\r\n",
            "Esperame que ahora entro yo\r\n",
            "Y lo que pide yo lo traje\r\n",
            "No visto de traje\r\n",
            "Puro corte calle, no de maquillaje\r\n",
            "Pronto coronamos y nos vamo' de viaje\r\n",
            "Tanto hit que hago que lo' culo bajen\r\n",
            "Ella se va de shopping\r\n",
            "Sale positivo si se hace el doping\r\n",
            "Baila twerk con un poco de popping\r\n",
            "Los fardos en el bot√≠n\r\n",
            "\r\n",
            "Si quieren letra llamen pa' mi booking\r\n",
            "Generando, sigo en la m√≠a lowkey\r\n",
            "Cooking en el estudio con tu woman\r\n",
            "Tanto whisky, pisco que hasta lo' vecinos toman\r\n",
            "Si se tiran pa' aca puede que la arena coman\r\n",
            "Ja, en el chanteo titulado sin diploma\r\n",
            "Di-dimelo m√°\r\n",
            "Di-dimelo m√°\r\n",
            "Di-dimelo m√°\r\n",
            "Di-dimelo m√°\r\n",
            "Di-dimelo m√°\r\n",
            "Di-dimelo m√°\r\n",
            "Di-dimelo m√°\r\n",
            "\r\n",
            "Ah, pe-peligrosa\r\n",
            "Quiero ver como perreando me acosa\r\n",
            "Eso de atra' con el Gucci me lo roza\r\n",
            "Tengo tussi del naranjo me aburrio el rosa\r\n",
            "Capaz que tosa con el blunt\r\n",
            "Sprite con Flemibron\r\n",
            "Louis Vuitton, le quito la polera Champion\r\n",
            "A tu pretendiente con la fory lo espanto\r\n",
            "Puro perro, le doy de comer Champion Dog\r\n",
            "Ese toto lo corono yo\r\n",
            "La movie en play no hay stop\r\n",
            "Flow de sobra no hay stock\r\n",
            "Me la topo en la disco queda en shock\r\n",
            "My love, rica en las redes y en persona\r\n",
            "No usa Photoshop\r\n",
            "La llevo a comprar blone' al growshop\r\n",
            "En ropa interior los do'\r\n",
            "Me roza su vicky con mi boxer Top\r\n",
            "Dimelo m√°\r\n",
            "Ando en busca de una cri\r\n",
            "minal (ah, ah)\r\n",
            "Esa que el gatillo le gusta jalar (rata-ta)\r\n",
            "Que le guste flotar y fumar\r\n",
            "Tussi, keta quiere' mezclar\r\n",
            "Dimelo m√°\r\n",
            "\r\n",
            "Ando en busca de una criminal (ah, ah)\r\n",
            "Esa que el gatillo le gusta jalar (rata-ta)\r\n",
            "Que le guste flotar y fumar\r\n",
            "Tussi, keta pura quiere' mezclar\r\n",
            "Marcianeke, Pailita\r\n",
            "Young Varas\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UIaOYzMk3v1X"
      },
      "source": [
        "Implementen una funci√≥n **`get_tokens()`** que reciba un texto y entregue una lista con sus tokens. Son libres de elegir la forma de tokenizar mientras no utilicen librer√≠as con tokenizadores ya implementados. Pueden utilizar la librer√≠a **re** importada para trabajar s√≠mbolos.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5dl42-hgIhqB"
      },
      "source": [
        "Ejemplo de uso:\n",
        "\n",
        "`get_tokens('Este es un ejemplo de prueba.')` \n",
        "\n",
        "Nos entregar√≠a:\n",
        "\n",
        "`['Este', 'es', 'un', 'ejemplo', 'de', 'prueba', '.']`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IF1RcIwq4G2x"
      },
      "source": [
        "def get_tokens(text):\n",
        "  \"\"\"\n",
        "    Recibe una cadena de texto, y retorna una lista de Python\n",
        "    con los tokens del texto de entrada.\n",
        "  \"\"\"\n",
        "   # Elimina retorno de carro y tabs\n",
        "  text = text.replace(\"\\r\", \" \").replace(\"\\t\", \" \")\n",
        "\n",
        "  # Elimina d√≠gitos\n",
        "  text = re.sub('\\d+', '', text) \n",
        "\n",
        "  # Genera lista separando por s√≠mbolos y espacios\n",
        "  reg = r'(' + \"|\".join([re.escape(i) for i in punctuation]) + r'| )'\n",
        "  text = re.split(reg, text)\n",
        "\n",
        "  # Elimina espacios al principio y final de los tokens\n",
        "  text = [t.strip() for t in text if t.strip()]\n",
        "  return text\n",
        "\n",
        "  ### Fin del c√≥digo ###"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KqlSpefv4_EH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ca723e6-58ce-4b24-c103-b0b0c14259c8"
      },
      "source": [
        "tokens = get_tokens(text)\n",
        "print(tokens)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Brr', 'Marcianeke', 'Vamo', \"'\", 'a', 'estar', 'con', 'Pailita', 'Dimelo', 'm√°', 'Ando', 'en', 'busca', 'de', 'una', 'criminal', '(', 'ah', ',', 'ah', ')', 'Esa', 'que', 'el', 'gatillo', 'le', 'gusta', 'jalar', '(', 'rata', '-', 'ta', ')', 'Que', 'le', 'guste', 'flotar', 'y', 'fumar', '(', 'brr', ')', 'Tussi', ',', 'keta', 'quiere', \"'\", 'mezclar', 'Dimelo', 'm√°', 'Ando', 'en', 'busca', 'de', 'una', 'criminal', '(', 'ah', ',', 'ah', ')', 'Esa', 'que', 'el', 'gatillo', 'le', 'gusta', 'jalar', '(', 'rata', '-', 'ta', ')', 'Que', 'le', 'guste', 'flotar', 'y', 'fumar', 'Tussi', ',', 'keta', 'pura', 'quiere', \"'\", 'mezclar', 'Di', '-', 'dimelo', 'm√°', 'Di', '-', 'dimelo', 'm√°', 'Di', '-', 'dimelo', 'm√°', 'Di', '-', 'dimelo', 'm√°', 'Di', '-', 'dimelo', 'm√°', 'Di', '-', 'dimelo', 'm√°', 'Di', '-', 'dimelo', 'm√°', 'Esperame', 'que', 'ahora', 'entro', 'yo', 'Y', 'lo', 'que', 'pide', 'yo', 'lo', 'traje', 'No', 'visto', 'de', 'traje', 'Puro', 'corte', 'calle', ',', 'no', 'de', 'maquillaje', 'Pronto', 'coronamos', 'y', 'nos', 'vamo', \"'\", 'de', 'viaje', 'Tanto', 'hit', 'que', 'hago', 'que', 'lo', \"'\", 'culo', 'bajen', 'Ella', 'se', 'va', 'de', 'shopping', 'Sale', 'positivo', 'si', 'se', 'hace', 'el', 'doping', 'Baila', 'twerk', 'con', 'un', 'poco', 'de', 'popping', 'Los', 'fardos', 'en', 'el', 'bot√≠n', 'Si', 'quieren', 'letra', 'llamen', 'pa', \"'\", 'mi', 'booking', 'Generando', ',', 'sigo', 'en', 'la', 'm√≠a', 'lowkey', 'Cooking', 'en', 'el', 'estudio', 'con', 'tu', 'woman', 'Tanto', 'whisky', ',', 'pisco', 'que', 'hasta', 'lo', \"'\", 'vecinos', 'toman', 'Si', 'se', 'tiran', 'pa', \"'\", 'aca', 'puede', 'que', 'la', 'arena', 'coman', 'Ja', ',', 'en', 'el', 'chanteo', 'titulado', 'sin', 'diploma', 'Di', '-', 'dimelo', 'm√°', 'Di', '-', 'dimelo', 'm√°', 'Di', '-', 'dimelo', 'm√°', 'Di', '-', 'dimelo', 'm√°', 'Di', '-', 'dimelo', 'm√°', 'Di', '-', 'dimelo', 'm√°', 'Di', '-', 'dimelo', 'm√°', 'Ah', ',', 'pe', '-', 'peligrosa', 'Quiero', 'ver', 'como', 'perreando', 'me', 'acosa', 'Eso', 'de', 'atra', \"'\", 'con', 'el', 'Gucci', 'me', 'lo', 'roza', 'Tengo', 'tussi', 'del', 'naranjo', 'me', 'aburrio', 'el', 'rosa', 'Capaz', 'que', 'tosa', 'con', 'el', 'blunt', 'Sprite', 'con', 'Flemibron', 'Louis', 'Vuitton', ',', 'le', 'quito', 'la', 'polera', 'Champion', 'A', 'tu', 'pretendiente', 'con', 'la', 'fory', 'lo', 'espanto', 'Puro', 'perro', ',', 'le', 'doy', 'de', 'comer', 'Champion', 'Dog', 'Ese', 'toto', 'lo', 'corono', 'yo', 'La', 'movie', 'en', 'play', 'no', 'hay', 'stop', 'Flow', 'de', 'sobra', 'no', 'hay', 'stock', 'Me', 'la', 'topo', 'en', 'la', 'disco', 'queda', 'en', 'shock', 'My', 'love', ',', 'rica', 'en', 'las', 'redes', 'y', 'en', 'persona', 'No', 'usa', 'Photoshop', 'La', 'llevo', 'a', 'comprar', 'blone', \"'\", 'al', 'growshop', 'En', 'ropa', 'interior', 'los', 'do', \"'\", 'Me', 'roza', 'su', 'vicky', 'con', 'mi', 'boxer', 'Top', 'Dimelo', 'm√°', 'Ando', 'en', 'busca', 'de', 'una', 'cri', 'minal', '(', 'ah', ',', 'ah', ')', 'Esa', 'que', 'el', 'gatillo', 'le', 'gusta', 'jalar', '(', 'rata', '-', 'ta', ')', 'Que', 'le', 'guste', 'flotar', 'y', 'fumar', 'Tussi', ',', 'keta', 'quiere', \"'\", 'mezclar', 'Dimelo', 'm√°', 'Ando', 'en', 'busca', 'de', 'una', 'criminal', '(', 'ah', ',', 'ah', ')', 'Esa', 'que', 'el', 'gatillo', 'le', 'gusta', 'jalar', '(', 'rata', '-', 'ta', ')', 'Que', 'le', 'guste', 'flotar', 'y', 'fumar', 'Tussi', ',', 'keta', 'pura', 'quiere', \"'\", 'mezclar', 'Marcianeke', ',', 'Pailita', 'Young', 'Varas']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TPbgTvAW-stF"
      },
      "source": [
        "**Describa cu√°les fueron sus supuestos para realizar la tokenizaci√≥n y compare sus tokens con los entregados por la librer√≠a nltk en el bloque de c√≥digo de m√°s abajo.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jGQ7CJy3-3aH"
      },
      "source": [
        "**Supuestos en los que basamos nuestra tokenizaci√≥n**:\n",
        "\n",
        "- Se asume que un token no necesariamente es una palabra con significado (como \"ra\" de \"rata-ta\" o \"di' de \"di-dimelo\").\n",
        "- Se asume que la puntuaci√≥n y otros s√≠mbolos constituyen tokens por s√≠ mismos.\n",
        "- Se asume que los tildes determinan palabras diferentes y por ende tokens diferentes, por lo que se conservan (Ej: \"papa\" $\\neq$ \"pap√°\").\n",
        "- Se asume que, para el caso de las letras de canciones, los n√∫meros no corresponden a \"palabras\" (o partes de ella), por lo que no se consideran como tokens. En otros casos, como detecci√≥n de spam, se podr√≠a reemplazar los n√∫meros por un token especial (ej: \"dinero\").\n",
        "- Se asume que no existen palabras compuestas; Cada token corresponde a texto, cumpliendo las condiciones anteriores, separado por espacio. Por tanto, cada token corresponde a un unigrama. Esta decisi√≥n se tom√≥ tomando en cuenta tambi√©n el ejemplo de referencia.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Comparaci√≥n con `nltk`**"
      ],
      "metadata": {
        "id": "ASf0Fem5NF0W"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YYtmAXTr9KXK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "909f1d36-f939-48cd-8cb7-60081ec12d8d"
      },
      "source": [
        "from nltk.tokenize import wordpunct_tokenize \n",
        "nltk_tokens = wordpunct_tokenize(text)\n",
        "print(nltk_tokens)\n",
        "print(f\"\\n# Tokens propios: {len(tokens)}\\n# Tokens nltk: {len(nltk_tokens)}\")\n",
        "\n",
        "assert tokens == nltk_tokens"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Brr', 'Marcianeke', 'Vamo', \"'\", 'a', 'estar', 'con', 'Pailita', 'Dimelo', 'm√°', 'Ando', 'en', 'busca', 'de', 'una', 'criminal', '(', 'ah', ',', 'ah', ')', 'Esa', 'que', 'el', 'gatillo', 'le', 'gusta', 'jalar', '(', 'rata', '-', 'ta', ')', 'Que', 'le', 'guste', 'flotar', 'y', 'fumar', '(', 'brr', ')', 'Tussi', ',', 'keta', 'quiere', \"'\", 'mezclar', 'Dimelo', 'm√°', 'Ando', 'en', 'busca', 'de', 'una', 'criminal', '(', 'ah', ',', 'ah', ')', 'Esa', 'que', 'el', 'gatillo', 'le', 'gusta', 'jalar', '(', 'rata', '-', 'ta', ')', 'Que', 'le', 'guste', 'flotar', 'y', 'fumar', 'Tussi', ',', 'keta', 'pura', 'quiere', \"'\", 'mezclar', 'Di', '-', 'dimelo', 'm√°', 'Di', '-', 'dimelo', 'm√°', 'Di', '-', 'dimelo', 'm√°', 'Di', '-', 'dimelo', 'm√°', 'Di', '-', 'dimelo', 'm√°', 'Di', '-', 'dimelo', 'm√°', 'Di', '-', 'dimelo', 'm√°', 'Esperame', 'que', 'ahora', 'entro', 'yo', 'Y', 'lo', 'que', 'pide', 'yo', 'lo', 'traje', 'No', 'visto', 'de', 'traje', 'Puro', 'corte', 'calle', ',', 'no', 'de', 'maquillaje', 'Pronto', 'coronamos', 'y', 'nos', 'vamo', \"'\", 'de', 'viaje', 'Tanto', 'hit', 'que', 'hago', 'que', 'lo', \"'\", 'culo', 'bajen', 'Ella', 'se', 'va', 'de', 'shopping', 'Sale', 'positivo', 'si', 'se', 'hace', 'el', 'doping', 'Baila', 'twerk', 'con', 'un', 'poco', 'de', 'popping', 'Los', 'fardos', 'en', 'el', 'bot√≠n', 'Si', 'quieren', 'letra', 'llamen', 'pa', \"'\", 'mi', 'booking', 'Generando', ',', 'sigo', 'en', 'la', 'm√≠a', 'lowkey', 'Cooking', 'en', 'el', 'estudio', 'con', 'tu', 'woman', 'Tanto', 'whisky', ',', 'pisco', 'que', 'hasta', 'lo', \"'\", 'vecinos', 'toman', 'Si', 'se', 'tiran', 'pa', \"'\", 'aca', 'puede', 'que', 'la', 'arena', 'coman', 'Ja', ',', 'en', 'el', 'chanteo', 'titulado', 'sin', 'diploma', 'Di', '-', 'dimelo', 'm√°', 'Di', '-', 'dimelo', 'm√°', 'Di', '-', 'dimelo', 'm√°', 'Di', '-', 'dimelo', 'm√°', 'Di', '-', 'dimelo', 'm√°', 'Di', '-', 'dimelo', 'm√°', 'Di', '-', 'dimelo', 'm√°', 'Ah', ',', 'pe', '-', 'peligrosa', 'Quiero', 'ver', 'como', 'perreando', 'me', 'acosa', 'Eso', 'de', 'atra', \"'\", 'con', 'el', 'Gucci', 'me', 'lo', 'roza', 'Tengo', 'tussi', 'del', 'naranjo', 'me', 'aburrio', 'el', 'rosa', 'Capaz', 'que', 'tosa', 'con', 'el', 'blunt', 'Sprite', 'con', 'Flemibron', 'Louis', 'Vuitton', ',', 'le', 'quito', 'la', 'polera', 'Champion', 'A', 'tu', 'pretendiente', 'con', 'la', 'fory', 'lo', 'espanto', 'Puro', 'perro', ',', 'le', 'doy', 'de', 'comer', 'Champion', 'Dog', 'Ese', 'toto', 'lo', 'corono', 'yo', 'La', 'movie', 'en', 'play', 'no', 'hay', 'stop', 'Flow', 'de', 'sobra', 'no', 'hay', 'stock', 'Me', 'la', 'topo', 'en', 'la', 'disco', 'queda', 'en', 'shock', 'My', 'love', ',', 'rica', 'en', 'las', 'redes', 'y', 'en', 'persona', 'No', 'usa', 'Photoshop', 'La', 'llevo', 'a', 'comprar', 'blone', \"'\", 'al', 'growshop', 'En', 'ropa', 'interior', 'los', 'do', \"'\", 'Me', 'roza', 'su', 'vicky', 'con', 'mi', 'boxer', 'Top', 'Dimelo', 'm√°', 'Ando', 'en', 'busca', 'de', 'una', 'cri', 'minal', '(', 'ah', ',', 'ah', ')', 'Esa', 'que', 'el', 'gatillo', 'le', 'gusta', 'jalar', '(', 'rata', '-', 'ta', ')', 'Que', 'le', 'guste', 'flotar', 'y', 'fumar', 'Tussi', ',', 'keta', 'quiere', \"'\", 'mezclar', 'Dimelo', 'm√°', 'Ando', 'en', 'busca', 'de', 'una', 'criminal', '(', 'ah', ',', 'ah', ')', 'Esa', 'que', 'el', 'gatillo', 'le', 'gusta', 'jalar', '(', 'rata', '-', 'ta', ')', 'Que', 'le', 'guste', 'flotar', 'y', 'fumar', 'Tussi', ',', 'keta', 'pura', 'quiere', \"'\", 'mezclar', 'Marcianeke', ',', 'Pailita', 'Young', 'Varas']\n",
            "\n",
            "# Tokens propios: 463\n",
            "# Tokens nltk: 463\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Los resultados generados con el tokenizador propio son iguales a los generados por `nltk`, al menos para este caso."
      ],
      "metadata": {
        "id": "sokwHc_sN6i0"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5QKlXAZwN1L"
      },
      "source": [
        "` `  \n",
        "` ` \n",
        "\n",
        "**Ejercicio 2 - *Stopwords y Stemming* (1 punto).** \n",
        "` `  \n",
        "` ` \n",
        "\n",
        "Considere el siguiente corpus:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sEp83zESwb2j"
      },
      "source": [
        "dataset = [\"I like human languages\", \"I like programming languages\", \"Spanish is my favorite language\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gmjdlJWuyS2E"
      },
      "source": [
        "Dise√±e una funci√≥n **`get_vocab()`** que extraiga los tokens de este corpus solamente tokenizando. Puede utilizar la funci√≥n del Ejercicio 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UudC-b6TzZgw"
      },
      "source": [
        "def get_vocab(dataset):\n",
        "  \"\"\"\n",
        "    Retorna una lista con el vocabulario de una colecci√≥n de\n",
        "    documentos. Se utiliza la funci√≥n get_tokens() para extraer\n",
        "    el vocabulario de los documentos.\n",
        "    \n",
        "    Nota: Utilice 'np.concatenate' porque estaba dentro\n",
        "    de las librer√≠as que se importaron al principio.\n",
        "  \"\"\"\n",
        "  ### Aqu√≠ inicia tu c√≥digo ###\n",
        "  vocab = set([token for doc in dataset for token in get_tokens(doc)])\n",
        "  return list(vocab)\n",
        "  ### Aqu√≠ termina tu c√≥digo ###"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5-m32IoNmSwM"
      },
      "source": [
        "***Test:***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BNzPKiAx0Aa1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ebc5f1a6-566a-42c5-86eb-2e2d1a33f619"
      },
      "source": [
        "vocab = get_vocab(dataset)\n",
        "print(vocab)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['like', 'human', 'Spanish', 'my', 'is', 'language', 'languages', 'programming', 'I', 'favorite']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZLV2hWf9FN7"
      },
      "source": [
        "``\n",
        "``\n",
        "\n",
        "***Resultado esperado***: \n",
        "<table>\n",
        "    <tr> \n",
        "        <td>['favorite',\n",
        " 'Spanish',\n",
        " 'language',\n",
        " 'I',\n",
        " 'like',\n",
        " 'programming',\n",
        " 'languages',\n",
        " 'my',\n",
        " 'human',\n",
        " 'is'] </td> \n",
        "    </tr>\n",
        "</table> \n",
        "\n",
        "``\n",
        "``"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "esperado = [\n",
        "    'favorite', 'Spanish', 'language', 'I', 'like', 'programming', 'languages',\n",
        "    'my', 'human', 'is'\n",
        "]\n",
        "\n",
        "assert sorted(esperado) == sorted(vocab)"
      ],
      "metadata": {
        "id": "lQJN-W8-aYSh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L3KB0fL2zk2v"
      },
      "source": [
        "Ahora dise√±e reglas que usted estime convenientes tanto de **Stemming** como de **Stopwords**. Implemente una funci√≥n que reciba una lista con los elementos del vocabulario, le aplique sus reglas y devuelva el vocabulario actualizado. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iY7g67Ml0aby"
      },
      "source": [
        "**Explique sus reglas aqu√≠**:\n",
        "\n",
        "Stopwords\n",
        "- Una forma de armar una lista de stopwords es tomando las \"x\" primeras palabras del ranking de palabras m√°s usadas en ingl√©s. \n",
        "- Para este ejercicio, tomamos como referencia el sitio [word frequency](https://www.wordfrequency.info/), el cual tiene disponible en forma gratuita las primeras 5.000 palabras del ranking de palabras en ingl√©s.\n",
        "- En nuestra implementaci√≥n, se utiliz√≥ el par√°metro \"top\" (por defecto 20, valor utilizado en la implementaci√≥n) para modificar la cantidad de palabras frecuentes a retornar.\n",
        "- Se debe se√±alar adem√°s que para un caso particular, en lugar de usar listas pre elaboradas de stop words, o usar las palabras m√°s frecuentes de todo el idioma (como hicimos en este caso), se puede usar las palabras m√°s frecuentes dentro del corpus de entrenamiento. Por ejemplo, en casos de clasificaci√≥n (como sentimientos), se puede considerar como stop words aquellas palabras que tengan alta frecuencia en las distintas clases (ya que no facilitan la discriminaci√≥n entre una clase y otra). Sin embargo, para este ejercicio decidimos usar las palabras m√°s frecuentes del idioma ingl√©s, y no las m√°s frecuentes de este caso espec√≠fico, ya que el corpus entregado es muy peque√±o.\n",
        "\n",
        "Stemming\n",
        "- Para este ejercicio, se considera las reglas del algoritmo de Porter vistas en clase (Presentaci√≥n \"Natural Language Processing Vector Space Model and Information Retrieval\", diapositiva 5).\n",
        "- Se debe considerar que el [algoritmo de Porter](https://nlp.stanford.edu/IR-book/html/htmledition/stemming-and-lemmatization-1.html) es mucho m√°s complejo, y considera muchas m√°s reglas y heur√≠sticas, por lo que la soluci√≥n implementada puede entregar reemplazos err√≥neos (Ej: \"is\" $\\rightarrow$ \"i\").\n",
        "- De todas formas, la soluci√≥n implementada es escalable, y se le puede agregar m√°s reglas o un llamado a otra funci√≥n de procesamiento.\n",
        "- Finalmente, destacar que el algoritmo de Porter se encuentra implementado en `nltk`, pero de todas formas muchas veces no suele ser la soluci√≥n m√°s √≥ptima al momento de preprocesar texto y generar tipos; Otra alternativa es el uso de _lemmatizaci√≥n_ (tambi√©n disponible en `nltk`, que se basa en reglas y tablas de b√∫squeda, y tambi√©n lleva las palabras a sus ra√≠ces."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_most_frequent_words(top=20):\n",
        "  \"\"\"\n",
        "  Retorna una lista de Python con las \"top\" palabras frecuentes\n",
        "  en ingl√©s, seg√∫n el sitio wordfrequency\n",
        "  \"\"\"\n",
        "  df = pd.read_excel(\"https://www.wordfrequency.info/samples/wordFrequency.xlsx\",\n",
        "                     sheet_name=\"1 lemmas\")\n",
        "  \n",
        "  return df[\"lemma\"].head(top).to_list()\n",
        "\n",
        "# Test\n",
        "stopwords = get_most_frequent_words()\n",
        "print(stopwords)"
      ],
      "metadata": {
        "id": "CbU77qAyCidQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b01c33ca-5078-4e62-f262-fbe54a46b005"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['the', 'be', 'and', 'a', 'of', 'to', 'in', 'i', 'you', 'it', 'have', 'to', 'that', 'for', 'do', 'he', 'with', 'on', 'this', \"n't\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def pre_processing(vocab):\n",
        "  \"\"\"\n",
        "    Recibe un vocabulario (lista de tokens √∫nicos), y retorna\n",
        "    un vocabulario procesado, donde se eliminan stopwords\n",
        "    y se aplica una parte del algoritmo de Porter de Stemming\n",
        "  \"\"\"\n",
        "\n",
        "  ### Aqu√≠ inicia tu c√≥digo ###\n",
        "\n",
        "  # Remover stopwords\n",
        "  stopwords = get_most_frequent_words()\n",
        "  res = [w for w in vocab if w.lower() not in stopwords]\n",
        "\n",
        "  # Se aplica parte del algoritmo de Porter\n",
        "  # Esto podr√≠a expandirse a m√°s reglas seg√∫n se requiera\n",
        "  res = pd.Series(res).replace(\n",
        "      [r\"sses+$|SSES+$\", r\"ies+$|IES+$\", r\"s+$|S+$\"],\n",
        "      [\"ss\", \"i\", \"\"],\n",
        "      regex=True,\n",
        "  ).unique()\n",
        "  \n",
        "  return list(res)\n",
        "  ### Aqu√≠ termina tu c√≥digo ###\n",
        "    "
      ],
      "metadata": {
        "id": "CwQS8lcLJczI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "onOSuS-_mL2F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0dbf2134-0821-4333-9a81-dc9fb0f268c9"
      },
      "source": [
        "vocab = pre_processing(vocab)\n",
        "print(vocab)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['like', 'human', 'Spanish', 'my', 'i', 'language', 'programming', 'favorite']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65IwHx11uA75"
      },
      "source": [
        "\n",
        "**Ejercicio 3 - *Bag of Words* üê∂üêà(0.5 puntos).** \n",
        " \n",
        "\n",
        "\n",
        "Considere el siguiente corpus, donde cada elemento del arreglo representa un documento:\n",
        "\n",
        "**disclaimer: El orden de los resultados pueden variar**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rh-utMuozhsK"
      },
      "source": [
        "d0 = 'El perro se come la comida y despu√©s se duerme'\n",
        "d1 = 'El perro se despierta y despu√©s empieza a ladrar'\n",
        "d2 = 'El perro ladra y despu√©s se come la comida'\n",
        "d3 = 'El gato se come la comida y despu√©s se duerme'\n",
        "d4 = 'El gato se despierta y despu√©s empieza a maullar'\n",
        "d5 = 'El gato maulla y despu√©s se come la comida'\n",
        "dataset = [d0, d1, d2, d3, d4, d5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WH7ne8C6ltvE"
      },
      "source": [
        "El objetivo de este ejercicio es determinar cu√°les de  los documentos entregados son los m√°s similares entre s√≠. Para ello utilizaremos la t√©cnica TF-IDF. \n",
        "\n",
        "Como los algoritmos de Machine Learning no comprenden el texto en lenguaje natural, estos documentos deben ser convertidos a vectores num√©ricos. La representaci√≥n m√°s simple vista en clases es el **Bag of Words**, m√©todo mediante el cu√°l se cuentan las apariciones de cada palabra en cada uno de los documentos entregados.\n",
        "\n",
        "Implemente la funci√≥n **`bag_of_words()`**, que reciba como input un arreglo de documentos y devuelva un pandas dataframe con la representaci√≥n Bag of Words de los documentos entregados. En esta representaci√≥n las columnas son el vocabulario y las filas representa las apariciones de cada una de las palabras en los documentos. En otras palabras, cada fila representa el bow de un determinado documento.\n",
        "\n",
        "\n",
        "Por ejemplo para el siguiente dataset: \n",
        "\n",
        "```\n",
        "dataset = ['El perro ladra', 'El perro come']\n",
        "```\n",
        "\n",
        "Debiese entregarnos lo siguiente:\n",
        "\n",
        "\n",
        "|   | el | perro | ladra | come |\n",
        "|---|----|-------|------|-------|\n",
        "| 0 | 1  | 1     | 1    | 0     |\n",
        "| 1 | 1  | 1     | 0    | 1     |\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kXDMAyFmnq5j"
      },
      "source": [
        "def bag_of_words(dataset):\n",
        "  \"\"\"\n",
        "    Retorna matriz de bag-of-words o matriz de ocurrencia por documento.\n",
        "\n",
        "    Nota: falta incluir el preprocessing dentro del vocabulario y la\n",
        "    obtenci√≥n de tokens.\n",
        "    \n",
        "  \"\"\"\n",
        "  ### Aqu√≠ inicia tu c√≥digo ###\n",
        "  # Obtener vocabulario del dataset\n",
        "  vocab = get_vocab(dataset)\n",
        "\n",
        "  # Crear matriz de ocurrencia: n√∫mero de documentos x largoo vocabulario\n",
        "  bow = np.zeros((len(dataset), len(vocab)))\n",
        "\n",
        "  # Iterar por cada documento y poblar matriz de ocurrencia\n",
        "  row_names = []\n",
        "\n",
        "  for idx, doc in enumerate(dataset):\n",
        "\n",
        "    row_names.append('d' + str(idx))\n",
        "    # obtener tokens por documento seg√∫n nuestra funci√≥n get_tokens()\n",
        "    tokens_in_doc = get_tokens(doc)\n",
        "\n",
        "    for token in tokens_in_doc:\n",
        "      # seg√∫n idx del documento y posici√≥n del token dentro del vocabulario\n",
        "      # las columnas siguen el orden de la lista de vocabulario\n",
        "      bow[idx, vocab.index(token)] += 1\n",
        "\n",
        "  # Retornar como pandas dataframe\n",
        "  return pd.DataFrame(bow, columns=vocab, index=row_names).astype(int)\n",
        "  ### Aqu√≠ termina tu c√≥digo ###"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "okfo-nEQmW1R"
      },
      "source": [
        "***Test:***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_Kk9GwCoDW8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "outputId": "3bfd5973-f0d1-4595-e20e-9f3dbdb944ac"
      },
      "source": [
        "dataset_bow = bag_of_words(dataset)\n",
        "dataset_bow"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    maullar  perro  y  despu√©s  duerme  El  gato  la  empieza  se  despierta  \\\n",
              "d0        0      1  1        1       1   1     0   1        0   2          0   \n",
              "d1        0      1  1        1       0   1     0   0        1   1          1   \n",
              "d2        0      1  1        1       0   1     0   1        0   1          0   \n",
              "d3        0      0  1        1       1   1     1   1        0   2          0   \n",
              "d4        1      0  1        1       0   1     1   0        1   1          1   \n",
              "d5        0      0  1        1       0   1     1   1        0   1          0   \n",
              "\n",
              "    ladra  a  maulla  comida  ladrar  come  \n",
              "d0      0  0       0       1       0     1  \n",
              "d1      0  1       0       0       1     0  \n",
              "d2      1  0       0       1       0     1  \n",
              "d3      0  0       0       1       0     1  \n",
              "d4      0  1       0       0       0     0  \n",
              "d5      0  0       1       1       0     1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fcd28292-ccce-409b-8a05-13a109c7ea47\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>maullar</th>\n",
              "      <th>perro</th>\n",
              "      <th>y</th>\n",
              "      <th>despu√©s</th>\n",
              "      <th>duerme</th>\n",
              "      <th>El</th>\n",
              "      <th>gato</th>\n",
              "      <th>la</th>\n",
              "      <th>empieza</th>\n",
              "      <th>se</th>\n",
              "      <th>despierta</th>\n",
              "      <th>ladra</th>\n",
              "      <th>a</th>\n",
              "      <th>maulla</th>\n",
              "      <th>comida</th>\n",
              "      <th>ladrar</th>\n",
              "      <th>come</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>d0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>d1</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>d2</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>d3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>d4</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>d5</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fcd28292-ccce-409b-8a05-13a109c7ea47')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fcd28292-ccce-409b-8a05-13a109c7ea47 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fcd28292-ccce-409b-8a05-13a109c7ea47');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oeR5ADGz-MPa"
      },
      "source": [
        "``\n",
        "``\n",
        "\n",
        "***Resultado esperado***: \n",
        "\n",
        "|    | El | perro | se | come | la | comida | y | despu√©s | duerme | despierta | empieza | a | ladrar | ladra | gato | maullar | maulla |\n",
        "|----|---:|------:|---:|-----:|---:|-------:|--:|--------:|-------:|----------:|--------:|--:|-------:|------:|-----:|--------:|-------:|\n",
        "| d0 |  1 |     1 |  2 |    1 |  1 |      1 | 1 |       1 |      1 |         0 |       0 | 0 |      0 |     0 |    0 |       0 |      0 |\n",
        "| d1 |  1 |     1 |  1 |    0 |  0 |      0 | 1 |       1 |      0 |         1 |       1 | 1 |      1 |     0 |    0 |       0 |      0 |\n",
        "| d2 |  1 |     1 |  1 |    1 |  1 |      1 | 1 |       1 |      0 |         0 |       0 | 0 |      0 |     1 |    0 |       0 |      0 |\n",
        "| d3 |  1 |     0 |  2 |    1 |  1 |      1 | 1 |       1 |      1 |         0 |       0 | 0 |      0 |     0 |    1 |       0 |      0 |\n",
        "| d4 |  1 |     0 |  1 |    0 |  0 |      0 | 1 |       1 |      0 |         1 |       1 | 1 |      0 |     0 |    1 |       1 |      0 |\n",
        "| d5 |  1 |     0 |  1 |    1 |  1 |      1 | 1 |       1 |      0 |         0 |       0 | 0 |      0 |     0 |    1 |       0 |      1 |\n",
        "\n",
        "``\n",
        "``"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K4OXMz7opWcd"
      },
      "source": [
        "` `  \n",
        "` ` \n",
        "\n",
        "**Ejercicio 4 - *Calcular TF* (0.5 puntos):** Ahora debemos usar el dataframe del ejercicio anterior para calcular la matriz de TF normalizada por la m√°xima frecuencia ${max_i({\\text{tf}_{i,j})}}$, donde\n",
        "i corresponde al √≠ndice de las filas (bow) y j al de las columnas (palabras). Es decir, dividir cada bow en la cantidad de veces de la palabra que aparezca m√°s veces en ese vector. \n",
        "\n",
        "\n",
        "$$\\text{nft}_{i,j} = \\frac{\\text{tf}_{i,j}}{max_i({\\text{tf}_{i,j})}}$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xWE16xhBpswc"
      },
      "source": [
        "def calc_tf(dataset_bow):\n",
        "  \"\"\"\n",
        "  Retorna matriz de frecuencia por t√©rmino en formato pd.DataFrame.\n",
        "\n",
        "  Esto es simplemente normalizar por fila las ocurrencias. Luego,\n",
        "  volver a normalizar por m√°xima frecunecia.\"\"\"\n",
        "  ### Aqu√≠ inicia tu c√≥digo ###\n",
        "\n",
        "  # Normalizar por fila para obtener la frecuencias t_{ij}\n",
        "  # t_{ij} = frecuencia del t√©rmino \"i\" en el documento \"j\"\n",
        "  tf = dataset_bow.div(dataset_bow.sum(axis=1), axis=0)\n",
        "\n",
        "  # Normalizar por el t√©rmino con m√°xima frecuencia en el documento\n",
        "  # max_{i}(tf_{ij}) = mayor frecuencia en documento \"j\"\n",
        "  return tf.div(tf.max(axis=1), axis=0)\n",
        "\n",
        "  ### Aqu√≠ termina tu c√≥digo ###"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AZQPZe3JmYqy"
      },
      "source": [
        "***Test:***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQ2h8jEYp4nZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "outputId": "4d73d1d6-743a-4517-ad2e-b781082a1190"
      },
      "source": [
        "tf = calc_tf(dataset_bow)\n",
        "tf"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    maullar  perro    y  despu√©s  duerme   El  gato   la  empieza   se  \\\n",
              "d0      0.0    0.5  0.5      0.5     0.5  0.5   0.0  0.5      0.0  1.0   \n",
              "d1      0.0    1.0  1.0      1.0     0.0  1.0   0.0  0.0      1.0  1.0   \n",
              "d2      0.0    1.0  1.0      1.0     0.0  1.0   0.0  1.0      0.0  1.0   \n",
              "d3      0.0    0.0  0.5      0.5     0.5  0.5   0.5  0.5      0.0  1.0   \n",
              "d4      1.0    0.0  1.0      1.0     0.0  1.0   1.0  0.0      1.0  1.0   \n",
              "d5      0.0    0.0  1.0      1.0     0.0  1.0   1.0  1.0      0.0  1.0   \n",
              "\n",
              "    despierta  ladra    a  maulla  comida  ladrar  come  \n",
              "d0        0.0    0.0  0.0     0.0     0.5     0.0   0.5  \n",
              "d1        1.0    0.0  1.0     0.0     0.0     1.0   0.0  \n",
              "d2        0.0    1.0  0.0     0.0     1.0     0.0   1.0  \n",
              "d3        0.0    0.0  0.0     0.0     0.5     0.0   0.5  \n",
              "d4        1.0    0.0  1.0     0.0     0.0     0.0   0.0  \n",
              "d5        0.0    0.0  0.0     1.0     1.0     0.0   1.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a794aaa2-bcb1-42d4-a6ea-45102b9df1c9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>maullar</th>\n",
              "      <th>perro</th>\n",
              "      <th>y</th>\n",
              "      <th>despu√©s</th>\n",
              "      <th>duerme</th>\n",
              "      <th>El</th>\n",
              "      <th>gato</th>\n",
              "      <th>la</th>\n",
              "      <th>empieza</th>\n",
              "      <th>se</th>\n",
              "      <th>despierta</th>\n",
              "      <th>ladra</th>\n",
              "      <th>a</th>\n",
              "      <th>maulla</th>\n",
              "      <th>comida</th>\n",
              "      <th>ladrar</th>\n",
              "      <th>come</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>d0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>d1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>d2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>d3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>d4</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>d5</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a794aaa2-bcb1-42d4-a6ea-45102b9df1c9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a794aaa2-bcb1-42d4-a6ea-45102b9df1c9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a794aaa2-bcb1-42d4-a6ea-45102b9df1c9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TOzdRwx9_UMM"
      },
      "source": [
        "``\n",
        "``\n",
        "\n",
        "***Resultado esperado***: \n",
        "\n",
        "|    |  El | perro |  se | come |  la | comida |   y | despu√©s | duerme | despierta | empieza |   a | ladrar | ladra | gato | maullar | maulla |\n",
        "|----|----:|------:|----:|-----:|----:|-------:|----:|--------:|-------:|----------:|--------:|----:|-------:|------:|-----:|--------:|-------:|\n",
        "| d0 | 0.5 |   0.5 | 1.0 |  0.5 | 0.5 |    0.5 | 0.5 |     0.5 |    0.5 |       0.0 |     0.0 | 0.0 |    0.0 |   0.0 |  0.0 |     0.0 |    0.0 |\n",
        "| d1 | 1.0 |   1.0 | 1.0 |  0.0 | 0.0 |    0.0 | 1.0 |     1.0 |    0.0 |       1.0 |     1.0 | 1.0 |    1.0 |   0.0 |  0.0 |     0.0 |    0.0 |\n",
        "| d2 | 1.0 |   1.0 | 1.0 |  1.0 | 1.0 |    1.0 | 1.0 |     1.0 |    0.0 |       0.0 |     0.0 | 0.0 |    0.0 |   1.0 |  0.0 |     0.0 |    0.0 |\n",
        "| d3 | 0.5 |   0.0 | 1.0 |  0.5 | 0.5 |    0.5 | 0.5 |     0.5 |    0.5 |       0.0 |     0.0 | 0.0 |    0.0 |   0.0 |  0.5 |     0.0 |    0.0 |\n",
        "| d4 | 1.0 |   0.0 | 1.0 |  0.0 | 0.0 |    0.0 | 1.0 |     1.0 |    0.0 |       1.0 |     1.0 | 1.0 |    0.0 |   0.0 |  1.0 |     1.0 |    0.0 |\n",
        "| d5 | 1.0 |   0.0 | 1.0 |  1.0 | 1.0 |    1.0 | 1.0 |     1.0 |    0.0 |       0.0 |     0.0 | 0.0 |    0.0 |   0.0 |  1.0 |     0.0 |    1.0 |\n",
        "\n",
        "``\n",
        "``"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZqgW4Ni4t0xC"
      },
      "source": [
        "` `  \n",
        "` ` \n",
        "\n",
        "**Ejercicio 5 - *Calcular IDF* (0.5 punto):**\n",
        "\n",
        "\n",
        "Implementar `calc_idf(dataset_bow)`. Este debe retornar un diccionario en donde las llaves sean las palabras y los valores sean el calculo de cada idf por palabra.\n",
        "\n",
        "Recordar que $idf_{t_i} = log_{10}\\frac{N}{n_i}$ con $N = $ n√∫mero de documentos y $n_i = $ N√∫mero de documentos que contienen la palabra $t_i$ "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "thhDY1-Ht6T5"
      },
      "source": [
        "def calc_idf(dataset_bow):\n",
        "  \"\"\"\n",
        "  Retorna diccionario con los score idf por cada token en el\n",
        "  vocabulario en dataset_bow.\n",
        "\n",
        "    - dataset_bow [pd.DataFrame]: bag-of-words dataframe, o matriz\n",
        "    de ocurrencia, computado por la funci√≥n bag_of_words()\n",
        "  \"\"\"\n",
        "  ### Aqu√≠ inicia tu c√≥digo ###\n",
        "\n",
        "  # Extraemos el vocabulario de las clumnas\n",
        "  vocab = dataset_bow.columns\n",
        "\n",
        "  # Matriz de ocurrencia (C) y n√∫mero de documentos (N)\n",
        "  C = dataset_bow.to_numpy()\n",
        "  N, _ = C.shape\n",
        "\n",
        "  # Colapsamos las filas en un vector ni y computamos idf\n",
        "  ni = np.sum(np.where(C > 0.0, 1.0, 0.0), axis=0)\n",
        "  idf = np.log10(N/ ni)\n",
        "\n",
        "  # Retornamos idf por vocabulario en un diccionario\n",
        "  return {vocab[idx]: val for idx, val in enumerate(idf)}\n",
        "\n",
        "  ### Aqu√≠ termina tu c√≥digo ###"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yR_j3pYemcAc"
      },
      "source": [
        "***Test:***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ro-OMGpduC0R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7d2788d-d3e2-41d5-d437-a0466b04eefc"
      },
      "source": [
        "idf = calc_idf(dataset_bow)\n",
        "idf"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'maullar': 0.7781512503836436,\n",
              " 'perro': 0.3010299956639812,\n",
              " 'y': 0.0,\n",
              " 'despu√©s': 0.0,\n",
              " 'duerme': 0.47712125471966244,\n",
              " 'El': 0.0,\n",
              " 'gato': 0.3010299956639812,\n",
              " 'la': 0.17609125905568124,\n",
              " 'empieza': 0.47712125471966244,\n",
              " 'se': 0.0,\n",
              " 'despierta': 0.47712125471966244,\n",
              " 'ladra': 0.7781512503836436,\n",
              " 'a': 0.47712125471966244,\n",
              " 'maulla': 0.7781512503836436,\n",
              " 'comida': 0.17609125905568124,\n",
              " 'ladrar': 0.7781512503836436,\n",
              " 'come': 0.17609125905568124}"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Resultado esperado***: \n",
        "\n",
        "```python\n",
        "{'El': 0.0, \n",
        " 'a': 0.47712125471966244,\n",
        " 'come': 0.17609125905568124,\n",
        " 'comida': 0.17609125905568124,\n",
        " 'despierta': 0.47712125471966244,\n",
        " 'despu√©s': 0.0,\n",
        " 'duerme': 0.47712125471966244,\n",
        " 'empieza': 0.47712125471966244,\n",
        " 'gato': 0.3010299956639812,\n",
        " 'la': 0.17609125905568124,\n",
        " 'ladra': 0.7781512503836436,\n",
        " 'ladrar': 0.7781512503836436,\n",
        " 'maulla': 0.7781512503836436,\n",
        " 'maullar': 0.7781512503836436,\n",
        " 'perro': 0.3010299956639812,\n",
        " 'se': 0.0,\n",
        " 'y': 0.0}\n",
        "```"
      ],
      "metadata": {
        "id": "Ioy_HicQDr-a"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IzKAzJtSJ7gx"
      },
      "source": [
        "Puede notar el bajo puntaje otorgado a las palabras que m√°s se repiten! üòÆ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D17lm6l9uJPo"
      },
      "source": [
        "**Ejercicio 6 - *Calcular TF-IDF & concluir similitud de documentos.* (1 punto)**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bc7FTQ19Kcwo"
      },
      "source": [
        "Programe la funci√≥n `calc_tf_idf(tf, idf)` que entrega el dataframe TF-IDF asociado al dataset que estamos analizando."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9knMl0KguMwo"
      },
      "source": [
        "def calc_tf_idf(tf, idf):\n",
        "  \"\"\"\n",
        "  Retorna matriz de scores tf-idf.\n",
        "\n",
        "    tf [pd.DataFrame]: term frequency matrix en formato dataframe.\n",
        "    idf [dict]: diccionario (vocab, idf).\n",
        "\n",
        "    Nota: vocab concuerda con los nombres de las columnas de tf.\n",
        "  \"\"\"\n",
        "  ### Aqu√≠ inicia tu c√≥digo ###\n",
        "\n",
        "  # Dado que la llave de idf == tf.columns:\n",
        "  return tf.mul(idf)\n",
        "  ### Aqu√≠ termina tu c√≥digo ### "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tRzIr1nQmepp"
      },
      "source": [
        "***Test.***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H8z6jaq2uPEo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "outputId": "34937487-4799-4523-d377-9df0503fb7a8"
      },
      "source": [
        "tf_idf = calc_tf_idf(tf, idf)\n",
        "tf_idf"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     maullar     perro    y  despu√©s    duerme   El      gato        la  \\\n",
              "d0  0.000000  0.150515  0.0      0.0  0.238561  0.0  0.000000  0.088046   \n",
              "d1  0.000000  0.301030  0.0      0.0  0.000000  0.0  0.000000  0.000000   \n",
              "d2  0.000000  0.301030  0.0      0.0  0.000000  0.0  0.000000  0.176091   \n",
              "d3  0.000000  0.000000  0.0      0.0  0.238561  0.0  0.150515  0.088046   \n",
              "d4  0.778151  0.000000  0.0      0.0  0.000000  0.0  0.301030  0.000000   \n",
              "d5  0.000000  0.000000  0.0      0.0  0.000000  0.0  0.301030  0.176091   \n",
              "\n",
              "     empieza   se  despierta     ladra         a    maulla    comida  \\\n",
              "d0  0.000000  0.0   0.000000  0.000000  0.000000  0.000000  0.088046   \n",
              "d1  0.477121  0.0   0.477121  0.000000  0.477121  0.000000  0.000000   \n",
              "d2  0.000000  0.0   0.000000  0.778151  0.000000  0.000000  0.176091   \n",
              "d3  0.000000  0.0   0.000000  0.000000  0.000000  0.000000  0.088046   \n",
              "d4  0.477121  0.0   0.477121  0.000000  0.477121  0.000000  0.000000   \n",
              "d5  0.000000  0.0   0.000000  0.000000  0.000000  0.778151  0.176091   \n",
              "\n",
              "      ladrar      come  \n",
              "d0  0.000000  0.088046  \n",
              "d1  0.778151  0.000000  \n",
              "d2  0.000000  0.176091  \n",
              "d3  0.000000  0.088046  \n",
              "d4  0.000000  0.000000  \n",
              "d5  0.000000  0.176091  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-43177db3-c250-494b-bd7e-a1cba107c2e8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>maullar</th>\n",
              "      <th>perro</th>\n",
              "      <th>y</th>\n",
              "      <th>despu√©s</th>\n",
              "      <th>duerme</th>\n",
              "      <th>El</th>\n",
              "      <th>gato</th>\n",
              "      <th>la</th>\n",
              "      <th>empieza</th>\n",
              "      <th>se</th>\n",
              "      <th>despierta</th>\n",
              "      <th>ladra</th>\n",
              "      <th>a</th>\n",
              "      <th>maulla</th>\n",
              "      <th>comida</th>\n",
              "      <th>ladrar</th>\n",
              "      <th>come</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>d0</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.150515</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.238561</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.088046</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.088046</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.088046</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>d1</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.301030</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.477121</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.477121</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.477121</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.778151</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>d2</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.301030</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.176091</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.778151</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.176091</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.176091</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>d3</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.238561</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.150515</td>\n",
              "      <td>0.088046</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.088046</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.088046</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>d4</th>\n",
              "      <td>0.778151</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.301030</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.477121</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.477121</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.477121</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>d5</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.301030</td>\n",
              "      <td>0.176091</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.778151</td>\n",
              "      <td>0.176091</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.176091</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-43177db3-c250-494b-bd7e-a1cba107c2e8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-43177db3-c250-494b-bd7e-a1cba107c2e8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-43177db3-c250-494b-bd7e-a1cba107c2e8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZBG2qfwv_6HK"
      },
      "source": [
        "``\n",
        "``\n",
        "\n",
        "***Resultado esperado***: \n",
        "\n",
        "|    |  El |    perro |  se |     come |       la |   comida |   y | despu√©s |   duerme | despierta |  empieza |        a |   ladrar |    ladra |     gato |  maullar |   maulla |\n",
        "|----|----:|---------:|----:|---------:|---------:|---------:|----:|--------:|---------:|----------:|---------:|---------:|---------:|---------:|---------:|---------:|---------:|\n",
        "| d0 | 0.0 | 0.150515 | 0.0 | 0.088046 | 0.088046 | 0.088046 | 0.0 |     0.0 | 0.238561 |  0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 |\n",
        "| d1 | 0.0 | 0.301030 | 0.0 | 0.000000 | 0.000000 | 0.000000 | 0.0 |     0.0 | 0.000000 |  0.477121 | 0.477121 | 0.477121 | 0.778151 | 0.000000 | 0.000000 | 0.000000 | 0.000000 |\n",
        "| d2 | 0.0 | 0.301030 | 0.0 | 0.176091 | 0.176091 | 0.176091 | 0.0 |     0.0 | 0.000000 |  0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.778151 | 0.000000 | 0.000000 | 0.000000 |\n",
        "| d3 | 0.0 | 0.000000 | 0.0 | 0.088046 | 0.088046 | 0.088046 | 0.0 |     0.0 | 0.238561 |  0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.150515 | 0.000000 | 0.000000 |\n",
        "| d4 | 0.0 | 0.000000 | 0.0 | 0.000000 | 0.000000 | 0.000000 | 0.0 |     0.0 | 0.000000 |  0.477121 | 0.477121 | 0.477121 | 0.000000 | 0.000000 | 0.301030 | 0.778151 | 0.000000 |\n",
        "| d5 | 0.0 | 0.000000 | 0.0 | 0.176091 | 0.176091 | 0.176091 | 0.0 |     0.0 | 0.000000 |  0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.301030 | 0.000000 | 0.778151 |\n",
        "\n",
        "\n",
        "``\n",
        "``"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WmVlbpzMp5NU"
      },
      "source": [
        "Ahora que tenemos el dataframe de TF-IDF, nos queda calcular la similitud coseno entre todos los vectores. Notar que la matriz resultante ser√° una matriz sim√©trica. Implemente la funci√≥n *cosine_similarity(v1, v2)* que recibe dos vectores (v1 y v2) y calcula la similitud coseno entre ambos vectores. Concluya cu√°les son los dos documentos m√°s similares."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HEgUtgBkQAae"
      },
      "source": [
        "def cosine_similarity(v1, v2):\n",
        "  ### Aqu√≠ inicia tu c√≥digo ###\n",
        "\n",
        "  # v1.dot(v1) ** 0.5 <-> np.sqrt((v1 ** 2).sum())\n",
        "  return v1.dot(v2) / (v1.dot(v1)**.5 * v2.dot(v2)**.5)\n",
        "  \n",
        "  ### Aqu√≠ termina tu c√≥digo ### \n",
        "\n",
        "# N√∫mero de documentos en le dataset \n",
        "N_DOC = len(dataset)\n",
        "\n",
        "# Crear matriz N_DOC x N_DOC para guardar similitudes entre documentos\n",
        "similarity_matrix = np.zeros((N_DOC, N_DOC))  \n",
        "\n",
        "for i, v1 in enumerate(tf_idf.index.values):\n",
        "  for j, v2 in enumerate(tf_idf.index.values):\n",
        "      similarity = cosine_similarity(tf_idf.loc[v1].values, tf_idf.loc[v2].values)\n",
        "      similarity_matrix[i][j] = similarity\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(similarity_matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-qNJH1fbiH5G",
        "outputId": "35914531-adf0-4b19-ff5c-875c30a744dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1.         0.12032418 0.3223436  0.77967014 0.         0.1632828 ]\n",
            " [0.12032418 1.         0.08686457 0.         0.4952126  0.        ]\n",
            " [0.3223436  0.08686457 1.         0.1632828  0.         0.11787732]\n",
            " [0.77967014 0.         0.1632828  1.         0.12032418 0.3223436 ]\n",
            " [0.         0.4952126  0.         0.12032418 1.         0.08686457]\n",
            " [0.1632828  0.         0.11787732 0.3223436  0.08686457 1.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Primero, dos _sanity checks_ de que la matriz de documentos fue computada correctamente.\n",
        "\n",
        "- [X] La matriz es simetrica dado que `cos(d1,d2)=cos(d2,d1)`.\n",
        "- [X] La diagonal de la matriz es 1 (i.e. `cos(d1,d1)=1`).\n"
      ],
      "metadata": {
        "id": "A5rAPLHJji5i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dado que es simetrica nos podemeos fijar en la parte triangular superior\n",
        "de la matriz,"
      ],
      "metadata": {
        "id": "BoQqHgimlwBK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.triu(similarity_matrix))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OdYDCskznXWi",
        "outputId": "41b8d301-b60e-4dba-8eb2-9875e7d9fddf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1.         0.12032418 0.3223436  0.77967014 0.         0.1632828 ]\n",
            " [0.         1.         0.08686457 0.         0.4952126  0.        ]\n",
            " [0.         0.         1.         0.1632828  0.         0.11787732]\n",
            " [0.         0.         0.         1.         0.12032418 0.3223436 ]\n",
            " [0.         0.         0.         0.         1.         0.08686457]\n",
            " [0.         0.         0.         0.         0.         1.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Seg√∫n la similitud por coseno, y el proceso de tokenizaci√≥n realizado, los\n",
        "documentos m√°s similares son la tupla $(d_{0}$ y $d_{3})$. Reportando una\n",
        "m√©trica de $0.77967$.\n",
        "\n",
        "Observemos estos documentos:"
      ],
      "metadata": {
        "id": "EDTFmfh5oR1v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Los dos m√°s similares\n",
        "print(d0)\n",
        "print(d3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hcWMGIqboe_R",
        "outputId": "523aa1f8-87a4-4bd8-bfce-a51af49e9eaa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "El perro se come la comida y despu√©s se duerme\n",
            "El gato se come la comida y despu√©s se duerme\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Los siguientes dos m√°s similares\n",
        "print(d1)\n",
        "print(d4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T7VJnlrYWwQm",
        "outputId": "fb2f739d-e81f-488d-cae4-d10a6760425c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "El perro se despierta y despu√©s empieza a ladrar\n",
            "El gato se despierta y despu√©s empieza a maullar\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Conclusiones**\n",
        "\n",
        "- Se observa que los dos documentos con mayor similaridad entre s√≠ son los documentos `d0` y `d3`, los cuales difieren en 1 sola palabra. Por tanto, s√≠ hace sentido que la similaridad calculada sea la m√°s alta. En este caso la similaridad es de 0.78.\n",
        "- La segunda pareja de documentos m√°s similares, son los documentos `d1` y `d4`, los cuales difieren en 2 palabras; Por tanto, hace sentido que tengan una similaridad menor que el caso anterior. En este caso la similaridad baja mucho, a 0.5, aunque solo se agregue 1 palabra de diferencia. Esto tiene sentido, ya que la cantidad de vocabulario es peque√±a."
      ],
      "metadata": {
        "id": "eUjpQfhdonjc"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FUAc1zX0Lg16"
      },
      "source": [
        "![gato](https://live.staticflickr.com/4652/38904147065_0b6c446945_b.jpg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s1A95IaXLHaB"
      },
      "source": [
        "**Cualquier recomendaci√≥n que nos quisieran dar para una futura tarea es bienvenid@!**"
      ]
    }
  ]
}