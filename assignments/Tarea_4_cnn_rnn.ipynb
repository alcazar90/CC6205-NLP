{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "L2Bi4lWPqy4I",
        "3Op1hOqgsg33"
      ],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UwaDuQqCOyLJ"
      },
      "source": [
        "# **Tarea 4 - CC6205 Natural Language Processing üìö**\n",
        "\n",
        "**Integrantes:** Crist√≥bal Alc√°zar, Gianina Salom√≥\n",
        "\n",
        "**Fecha l√≠mite de entrega üìÜ:** Martes 13 de junio.\n",
        "\n",
        "**Tiempo estimado de dedicaci√≥n:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X4lL5hGw07yP"
      },
      "source": [
        "Bienvenid@s a la cuarta tarea del curso de Natural Language Processing (NLP).\n",
        "En esta tarea estaremos tratando el problema de **tagging** (generaci√≥n de secuencias de etiquetas del mismo largo que la secuencia de input), el uso de **Convolutional Neural Networks** y **Recurrent Neural Networks**, e implementaremos una red usando PyTorch.\n",
        "\n",
        "Usen $\\LaTeX$ para las f√≥rmulas matem√°ticas. En la parte de programaci√≥n pueden usar lo que quieran, pero la [Auxiliar 3](https://youtu.be/36WTXvg3zh0) les puede ser de *gran ayuda*.\n",
        "\n",
        "**Instrucciones:**\n",
        "- La tarea se realiza en grupos de **m√°ximo** 2 personas. Puede ser invidivual pero no es recomendable.\n",
        "- La entrega es a trav√©s de u-cursos a m√°s tardar el d√≠a estipulado arriba. No se aceptan atrasos.\n",
        "- El formato de entrega es este mismo Jupyter Notebook.\n",
        "- Al momento de la revisi√≥n tu c√≥digo ser√° ejecutado. Por favor verifica que tu entrega no tenga errores de compilaci√≥n.\n",
        "- En el horario de auxiliar pueden realizar consultas acerca de la tarea a trav√©s del canal de Discord del curso.\n",
        "\n",
        "Si a√∫n no han visto las clases, se recomienda visitar los links de las referencias.\n",
        "\n",
        "**Referencias:**\n",
        "\n",
        "- [Tagging, and Hidden Markov Models ](http://www.cs.columbia.edu/~mcollins/cs4705-spring2019/slides/tagging.pdf) (slides by Michael Collins), [notes](http://www.cs.columbia.edu/~mcollins/hmms-spring2013.pdf), [video 1](https://youtu.be/-ngfOZz8yK0), [video 2](https://youtu.be/Tjgb-yQOg54), [video 3](https://youtu.be/aaa5Qoi8Vco), [video 4](https://youtu.be/4pKWIDkF_6Y)\n",
        "- [MEMMs and CRFs](https://github.com/dccuchile/CC6205/blob/master/slides/NLP-CRF.pdf): [notes 1](http://www.cs.columbia.edu/~mcollins/crf.pdf), [notes 2](http://www.cs.columbia.edu/~mcollins/fb.pdf), [video 1](https://youtu.be/qlI-4lSUDkg), [video 2](https://youtu.be/PLoLKQwkONw), [video 3](https://youtu.be/ZpUwDy6o28Y)\n",
        "- [Convolutional Neural Networks](https://github.com/dccuchile/CC6205/blob/master/slides/NLP-CNN.pdf): [video](https://youtu.be/lLZW5Fn40r8)\n",
        "- [Recurrent Neural Networks](https://github.com/dccuchile/CC6205/blob/master/slides/NLP-RNN.pdf): [video 1](https://youtu.be/BmhjUkzz3nk), [video 2](https://youtu.be/z43YFR1iIvk), [video 3](https://youtu.be/7L5JxQdwNJk)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hidden Markov Models (HMM), Maximum Entropy Markov Models (MEMM) and Conditional Random Field(CRF) (1,5 puntos)"
      ],
      "metadata": {
        "id": "ANqzQ3G9WNw3"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bWXD3D7RYKJ-"
      },
      "source": [
        "### Pregunta 1 (1 pt)\n",
        "Para un problema de POS tagging se define el conjunto de etiquetas $S = \\{ \\text{DET}, \\text{NOUN}, \\text{VERB}, \\text{ADP} \\}$ y se tiene un Hidden Markov Model con los siguientes par√°metros estimados a partir de un corpus de entrenamiento:\n",
        "\n",
        "\\begin{equation}\n",
        "\\begin{split}\n",
        "q(\\text{NOUN}| \\text{ VERB}, \\text{DET}) &= 0.3 \\\\\n",
        "q(\\text{NOUN}|\\ w, \\text{DET}) &= 0 \\qquad \\forall w \\in S, w \\neq \\text{VERB} \\\\\n",
        "q(\\text{DET}| \\text{ VERB}, \\text{NOUN}) &= 0.4 \\\\\n",
        "q(\\text{DET}|\\ w, \\text{NOUN}) &= 0 \\qquad \\forall w \\in S, w \\neq \\text{VERB} \\\\\n",
        "e(the|\\text{ DET}) &= 0.5 \\\\\n",
        "e(pasta|\\text{ NOUN}) &= 0.6\n",
        "\\end{split}\n",
        "\\end{equation}\n",
        "\n",
        "Luego para la oraci√≥n: `the man is pouring sauce on the pasta`, se tiene una tabla de programaci√≥n din√°mica con los siguientes valores:\n",
        "\\begin{equation}\n",
        "\\begin{split}\n",
        "\\pi(7,\\text{DET},\\text{DET})&=0.1\\\\\n",
        "\\pi(7,\\text{NOUN},\\text{DET})&=0.2\\\\\n",
        "\\pi(7,\\text{VERB},\\text{DET})&=0.01\\\\\n",
        "\\pi(7,\\text{ADP},\\text{DET})&=0.5\n",
        "\\end{split}\n",
        "\\end{equation}\n",
        "\n",
        "Con esta informaci√≥n, calcule el valor de $\\pi(8,\\text{DET},\\text{NOUN})$. Puede dejar el resultado expresado como una fracci√≥n.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5EzgysW9kGi-"
      },
      "source": [
        "**Respuesta**\n",
        "\n",
        "Se tiene la siguiente funci√≥n recursiva para cualquier $k \\in {1 \\dots 8}$, para cualquier $u \\in S_{k-1}$ y $v \\in S_k$.\n",
        "\n",
        "$$\n",
        "\\begin{align}\n",
        "\\pi(k, u, v) &= \\underset{\\substack{w \\in S_{k-2}}}{\\text{max}} \\;(\\pi(k-1, w, u) \\times q(v|w, u) \\times e(x_k|v))\n",
        "\\end{align}\n",
        "$$\n",
        "\n",
        "Donde:\n",
        "* $k$: Posici√≥n dentro de la oraci√≥n\n",
        "* $u$: Etiqueta de la posici√≥n $k-1$\n",
        "* $v$: Etiqueta de la posici√≥n $k$\n",
        "* $w$: Etiqueta de la posici√≥n $k-2$\n",
        "* $x_k$: Palabra en la posici√≥n $k$\n",
        "\n",
        "Se calcula $\\pi(k-1, w, u) \\times q(v|w, u) \\times e(x_k|v)$ para cada elemento de $S$:\n",
        "\n",
        "$\n",
        "\\pi(7, \\text{DET}, \\text{DET}) \\times q(\\text{NOUN}|\\text{DET}, \\text{DET}) \\times e(\\text{pasta}|\\text{NOUN}) = 0.1 \\times 0 \\times 0.6 = 0\n",
        "$\n",
        "$\n",
        "\\pi(7, \\text{NOUN}, \\text{DET}) \\times q(\\text{NOUN}|\\text{NOUN}, \\text{DET}) \\times e(\\text{pasta}|\\text{NOUN}) = 0.2 \\times 0 \\times 0.6 = 0\n",
        "$\n",
        "$\n",
        "\\pi(7, \\text{VERB}, \\text{DET}) \\times q(\\text{NOUN}|\\text{VERB}, \\text{DET}) \\times e(\\text{pasta}|\\text{NOUN}) = 0.01 \\times 0.3 \\times 0.6 = 0.0018\n",
        "$\n",
        "$\n",
        "\\pi(7, \\text{ADP}, \\text{DET}) \\times q(\\text{NOUN}|\\text{ADP}, \\text{DET}) \\times e(\\text{pasta}|\\text{NOUN}) = 0.5 \\times 0 \\times 0.6 = 0\n",
        "$\n",
        "\n",
        "\n",
        "Entonces\n",
        "\n",
        "$$\n",
        "\\begin{align}\n",
        "\\pi(8, \\text{DET}, \\text{NOUN}) &= \\text{max}(0, 0, 0.0018, 0) = 0.0018\n",
        "\\end{align}\n",
        "$$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oiwJb_vmkKLZ"
      },
      "source": [
        "### Pregunta 2 (0.5 pts)\n",
        "Comente  sobre las similitudes o diferencias entre los HMMs, MEMMs y CRFs. Para esto, responda las siguientes preguntas.\n",
        "\n",
        "#### 2.1. ¬øPara qu√© tipo de tarea sirven? D√© dos ejemplo de este tipo de tarea y descr√≠balos brevemente. (0.1 pts)\n",
        "\n",
        "**Respuesta:**\n",
        "\n",
        "Sirven para el tipo de tarea de _sequence labeling_, donde el output (secuencia de etiquetas) es del mismo largo del input (secuencia de tokens). Dos tareas que se pueden modelar como problemas de sequence labeling son:\n",
        "* **POS tagging**: Etiquetado de _part of speech_. El output es la secuencia de POS para cada token del input. La idea es entender cu√°l es el rol sint√°ctico que tiene una palabra en la oraci√≥n, lo cual depende del contexto. Algunos POS son NOUN, VERB, PREPOSITION.\n",
        "* **NER**: _Named Entity Recognition_, que corresponde a la detecci√≥n de entidades nombradas de cada token del input. Algunas entidades pueden ser \"Location\" o \"Company\", dependiendo de qu√© entidades se desea identificar. Para el resto de entidades, se usa la etiqueta \"NA\" (ninguna entidad).\n",
        "\n",
        "#### 2.2. ¬øQu√© modelos usan features? ¬øQu√© ventajas conlleva esto? (0.1 pts)\n",
        "\n",
        "**Respuesta:**\n",
        "\n",
        "Los modelos que usan features son MEMMs y CRFs. La ventaja de esto es que en los features se puede a√±adir informaci√≥n que no se puede codificar trivialmente en una HMM, como ver relaciones entre las etiquetas y las palabras. Las features pueden ser combinaciones de covocabulario, palabras, o del espacio de etiquetas, tomando en cuenta por ejemplo prefijos y sufijos.\n",
        "\n",
        "#### 2.3. ¬øC√≥mo maneja cada uno de los modelos las palabras con baja frecuencia en el set de train? (0.1 pts)\n",
        "\n",
        "**Respuesta:**\n",
        "\n",
        "En el caso de HMM, se divide el vocabulario en un conjunto de palabras frecuentes y otro de palabras infrecuentes, siendo las primeras las que ocurren alg√∫n n√∫mero m√≠nimo de veces en el corpus de entrenamiento (ej: 5). Luego se mapea todas las palabras de baja frecuencia, seg√∫n sus sufijos y prefijos, a un conjunto fijo de categor√≠as (ej: token \"90\" se puede mapear a la categor√≠a twoDigitNum).\n",
        "\n",
        "En el caso de MEMMs, se beneficia de la construcci√≥n de features que pueden hacer uso de los sufijos y prefijos de las palabras y asocian esto con la etiqueta (ej en ingl√©s: si termina en \"ly\" es adverbio), o relaciones entre los tokens (ej en ingl√©s: si la palabra anterior es adjetivo, la actual es sustantivo). De esta forma si la palabra es poco frecuente, pero cumple con las reglas de las features, va a contribuir a aumentar el peso asociado las features en entrenamiento.\n",
        "\n",
        "En el caso de CRF, tiene la ventaha de que resuelve el problema de sesgo de etiqueta; Como MEMM hace una normalizaci√≥n local, se pierde informaci√≥n de cosas que co ocurren poco frecuentemente en todo el corpus. En cambio, CRF soluciona el problema anterior porque hace una optimizaci√≥n global, entonces considera puntajes para las secuencias completas antes de hacer la normalizaci√≥n.\n",
        "\n",
        "#### 2.4. ¬øQu√© le permite a los CRF realizar decisiones globales? ¬øQu√© diferencia con respecto a los MEMMs permite lograr esto? ¬øPor qu√© los HMMs tampoco son capaces de tomar decisiones globales? (0.1 pts)\n",
        "\n",
        "**Respuesta:**\n",
        "\n",
        "Lo que permite a los CRF realizar decisiones globales es que se modela la probabilidad de la secuencia de etiquetas candidatas dado la secuencia de palabras del input, $P(s_{1:m}|x_{1:m})$, directamente con un modelo lineal, el cual normaliza por todas las secuencias posibles, siendo entonces una normalizaci√≥n global (la suma corre por todas las secuencias de etiquetas posibles, $|S|^m$, siendo $m$ la cantidad de tokens del input o de etiquetas del output). Tienen un feature vector global para todas las secuencias, que toma en cuenta toda la secuencia de etiquetas (no se restringe a una posici√≥n).\n",
        "\n",
        "Lo que diferencia a los CRF respecto de los MEMMs para lograr lo anterior es que los MEMMs no modelan directamente la probabilidad condicional $P(s_{1:m}|x_{1:m})$, sino que hacen un supuesto de independencia Markoviano que asume que la etiqueta solamente depende de la etiqueta anterior, modelando esto con un modelo log lineal.\n",
        "\n",
        "Los HMM tampoco son capaces de tomar decisiones globales ya que tambi√©n aplican un supuesto de independencia Markoviano para la probabilidad conjunta de la secuencia de palabras y la secuencia de etiquetas, donde cada etiqueta solo depende de sus dos etiquetas anteriores, y cada palabra solo depende de su etiqueta correspondiente (por ende todo lo dem√°s, que permitir√≠a realizar una decisi√≥n global, lo considera independiente).\n",
        "\n",
        "#### 2.5 Dado una secuencia de $x_1, ..., x_m$ ¬øCu√°ntas posibles secuencias de etiquetas se pueden generar para un conjunto de etiquetas $S$ con $|S|=k$ ? ¬øAnalizarlas todas ser√≠a computacionalmente tratable? (0.1 pts)\n",
        "\n",
        "**Respuesta:**\n",
        "\n",
        "El n√∫mero de posibles secuencias de etiquetas que se pueden generar para un conjunto de etiquetas $S$ con $|S|=k$ es de $k^m$. Es decir, el n√∫mero de secuencias posibles crece exponencialmente con el largo de la secuencia. Por tanto, analizar todas las posibles frecuencias _no_ es coputacionalmente tratable; Se tendr√≠a que evaluar la secuencia de palabras para todas las secuencias posibles de etiquetas, y para todas calcular la probabilidad. Para la decodificaci√≥n entonces, lo que se hace en su lugar es utilizar una t√©cnica de programaci√≥n din√°mica, como el algoritmo de Viterbi, que permite encontrar la secuencia m√°s probable de manera eficiente, logrando esto en tiempo polinomial en lugar de tiempo exponencial."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Convolutional Neural Networks (0,5 puntos)"
      ],
      "metadata": {
        "id": "44ACHHZIWGF1"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ClRAHR95Y8aB"
      },
      "source": [
        "### Pregunta 3 (0,5 puntos)\n",
        "\n",
        "Considere la frase $w_{1..7}=$ `El agua moja y el fuego quema` $=[El, agua, moja, y, el, fuego, quema]$.\n",
        "\n",
        "La siguiente matriz de embeddings, donde la i-√©sima fila corresponde al vector de embedding de la i-√©sima palabra, ordenadas seg√∫n aparecen en la frase. (vectores de largo 2).\n",
        "\\begin{equation}\n",
        "E = \\begin{pmatrix}\n",
        "2 & 2\\\\\n",
        "0 & -2\\\\\n",
        "0 & 1\\\\\n",
        "-2 & 1\\\\\n",
        "1 & 0\\\\\n",
        "-1 & 1\\\\\n",
        "1 & 1\n",
        "\\end{pmatrix}\n",
        "\\end{equation}\n",
        "\n",
        "Los siguientes 3 filtros\n",
        "\\begin{equation}\n",
        "U = \\begin{pmatrix}\n",
        "-1 & 1 & 0\\\\\n",
        "1 & 1 & 0\\\\\n",
        "0 & 0 & -1\\\\\n",
        "1 & -1 & -1\\\\\n",
        "-1 & -1 & 1\\\\\n",
        "1 & 0 & -1\n",
        "\\end{pmatrix}\n",
        "\\end{equation}\n",
        "\n",
        "Y la funci√≥n de activaci√≥n\n",
        "\\begin{equation}\n",
        "tanh = \\frac{e^{2x} - 1}{e^{2x} + 1}\n",
        "\\end{equation}\n",
        "\n",
        "Usando estos param√°tros escriba los pasos para calcular la representaci√≥n (vector) resultante de aplicar la operaci√≥n de convoluci√≥n (sin padding) + max pooling. ¬øDe qu√© tama√±o ser√≠a la ventana que debemos usar?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SlQ30Arkq0u4"
      },
      "source": [
        "**Respuesta**\n",
        "\n",
        "Pasos para calcular la reepresentaci√≥n resultante de la convoluci√≥n:\n",
        "\n",
        "1. Utilizando los √≠ndices que representan cada palabra, realizamos una\n",
        "operaci√≥n _look-up_ en la tabla de _embeddings_ $E$ para obtener la\n",
        "representaci√≥n vectorial continua y compacta de estas. Cada una de las palabras $w_{1:7}$ de la frase `El agua moja y el fuego quema` es representada por un vector $E_{[w_j]}=\\bar{w}_{j}\\in \\mathrm{R}^2$ (i.e. filas en $E$).\n",
        "2. Luego, concatenamos todos estos vectores que conforman la frase de 7 palabras, y obtenemos el input que ingresar√° a la red $\\bar{x}\\in\\mathrm{R}^{7\\cdot 2=14}$.\n",
        "<br>\n",
        "\n",
        "$$\n",
        "\\bar{x}=\\oplus~(\\bar{w}_1, \\dots, \\bar{w}_7)\n",
        "$$\n",
        "<br>\n",
        "3. La matriz $U\\in\\mathrm{R}^{k\\times\\ell}$ contiene $\\ell=3$ diferentes filtros representados por sus columnas, todos de largo $k=6$.\n",
        "Se convolucionaran estas 3 \"versiones\" de ventanas m√≥viles de largo $6$ con el\n",
        "_input_ $\\bar{x}$ de largo $n=14$. Debemos considerar el par√°metro [_stride_](https://d2l.ai/chapter_convolutional-neural-networks/padding-and-strides.html#stride)\n",
        "en el movimiento de las ventanas, en este caso particular, la ventana de largo $k=6$ se mueve saltando 2 posiciones, es decir seg√∫n un _stride_ de $s=2$. Este\n",
        "par√°metro responde al n√∫mero de dimensiones de los _embeddings_, y es porque\n",
        "b√∫scamos tratarlos como unidades indivisibles a esta operaci√≥n. Nos gustar√≠a\n",
        "realizar operaciones sobre varios vectores de _embeddings_, pero no sobre versiones parciales de estos vectores. **La formula que determina el tama√±o del _output_ de la convoluci√≥n, sin considerar _padding_,\n",
        "y con un _stride_ de $2$, es $(n-k+s)~/~s=(14-6+2)~/~2=5$**. Es decir, tendremos $3$ \"versiones\" de secuencias _output_ de largo $5$ (una por cada $\\ell$). Esto como resultado de convolucionar cada filtro a lo largo de toda la secuencia _input_.\n",
        "4. **Sobre el tama√±o de la ventana que debemos usar**; nuestra\n",
        "matriz de pesos $U$, tiene en las columnas los filtros, y en las filas `k= (dim. embedding) x (# tokens en la ventana)` (i.e. $2\\times 3$). Es decir, **estamos computando\n",
        "representaciones con un tama√±o de ventana de $3$ tokens, o trigramas, usando convoluciones**. El tama√±o del _output_ pensando en tokens, es $n-k+1=7-3+1=5$ (sin _padding_). Este coincide con el tama√±o\n",
        "del punto (3), solo que en esta version pensamos los par√°metros de la convoluci√≥n respecto a lo que estamos representando que son los _tokens_ (i.e.\n",
        "palabras) que b√∫scamos modelar. En cambio, en el punto anterior (3), estamos pensando los par√°metros\n",
        "directos que recibir√° la capa de convoluci√≥n, en este caso no son los mismos, porque hay una capa de representaci√≥n entremedio que son los _embeddings_. Esto es importante\n",
        "cuando se realiza una implementaci√≥n de esto, dado que las capas de convoluci√≥n necesitan considerar en su par√°metro de tama√±o de ventana la dimension de los _embeddings_, y adem√°s el _stride_ para computar los n-gramas correctamente.\n",
        "5. Cuando el filtro esta convolucionando con secciones de la secuencia del\n",
        "_input_ (i.e. `x[i*s:(i*s+k)]`), se realiza una operaci√≥n lineal de la sub-secuencia del _input_ con los par√°metros del filtro que es un producto punto + el _bias_, seguido\n",
        "de una no-linealidad como la `tanh`: `tanh(x[s*i:(s*i+k)].dot(U[:,l])+b[l])`. El resultado es un escalar, y se repite esta operaci√≥n con las 5 sub-secuencias seg√∫n el movimiento de la ventana, dando\n",
        "en conjunto el output de la convoluci√≥n.\n",
        "<br>\n",
        "\n",
        "$$\n",
        "\\{y^{(\\ell)}\\}_{0:5}=\\tanh\\big(\\bar{x}_{2\\cdot i:(2\\cdot i+6)}\\cdot \\bar{u}_{\\ell} + b_{\\ell}\\big),~i=0,\n",
        "\\dots, 5.~~\\bar{u}_{\\ell}=U_{[:, \\ell]}\n",
        "$$\n",
        "<br>\n",
        "6. Dado que tenemos 3 filtros, obtendremos 3 versiones del _output_\n",
        "$\\{y^{(\\ell)}\\}_{0:5}$, cada uno de los filtros\n",
        "comparte un mismo conjunto de pesos o par√°metros. Excluyendo el _bias_ en\n",
        "cada filtro, tenemos $k=6$ par√°metros por cada filtro $\\ell=3$, un total de $6\\times 3=18$ par√°metros encargados de aprender representaciones locales del texto. Considerando el _bias_, tenemos 1 por cada grupo, subiendo a un total\n",
        "de $18+3=21$ par√°metros relacionados a las operaciones de convoluci√≥n.\n",
        "7. Finalmente, aplicamos _max pooling_ para agregar la secuencia\n",
        "de la convoluci√≥n en el m√°ximo valor, terminaremos con un valor por\n",
        "cada canal/filtro/kernel, es decir de tama√±o 3."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A continuaci√≥n se implementa en c√≥digo con los valores de los\n",
        "par√°metros los pasos anteriores para obtener el vector resultado\n",
        "de largo 3, despu√©s de aplicar _max pooling_."
      ],
      "metadata": {
        "id": "8JkztoTAe2ef"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### C√≥digo ilustrando e implementando los pasos anteriores:"
      ],
      "metadata": {
        "id": "5iDnPZgGZRrx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definimos $w, E, U$ seg√∫n el enunciado de la pregunta."
      ],
      "metadata": {
        "id": "ebsehWBtTZ6C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# definir activaci√≥n tanh\n",
        "tanh = lambda x: (torch.exp(2 * x) - 1) / (torch.exp(2 * x) + 1)\n",
        "\n",
        "E = torch.tensor([[ 2, 2],\n",
        "                  [ 0,-2],\n",
        "                  [ 0, 1],\n",
        "                  [-2, 1],\n",
        "                  [ 1, 0],\n",
        "                  [-1, 1],\n",
        "                  [ 1, 1]], dtype=torch.float)\n",
        "\n",
        "U = torch.tensor([[-1, 1, 0],\n",
        "                  [ 1, 1, 0],\n",
        "                  [ 0, 0,-1],\n",
        "                  [ 1,-1,-1],\n",
        "                  [-1,-1, 1],\n",
        "                  [1, 0, -1]], dtype=torch.float)\n",
        "\n",
        "# vector de enteros que representa cada palabra en la\n",
        "# frase: \"El agua moja y el fuego quema\"\n",
        "w = torch.arange(7)\n",
        "\n",
        "# operaci√≥n look-up y concatenaci√≥n implicita de los embedding\n",
        "# de cada palabra\n",
        "x = E[w].view(-1)\n",
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "glAI0K_FHNb1",
        "outputId": "d6c25906-e14f-44da-d982-bc57342f0b0c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 2.,  2.,  0., -2.,  0.,  1., -2.,  1.,  1.,  0., -1.,  1.,  1.,  1.])"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creamos una funci√≥n para convolucionar filtros en $U$ sobre una\n",
        "secuencia de _tokens_ representados por sus _embeddings_, el_input_ $x$. Esta convoluci√≥n no tiene _padding_, pero si tiene el par√°metro _stride_ para ajustar la convoluci√≥n a la dimension de los _embeddings_."
      ],
      "metadata": {
        "id": "YPACxc3ZTl5b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def conv1D(x, U, s=1):\n",
        "  \"\"\"Simple convoluci√≥n sobre input 1D sin padding, aka 'wide convolution'. Se\n",
        "     utiliza par√°metro stride para ajustar la dimensi√≥n del output a la\n",
        "     dimension de los embeddings.\n",
        "        Input:\n",
        "          - x: secuencia de embeddings de los tokens\n",
        "          - U: matriz de filtros (kernels) con largo_kernel x numero_kernel\n",
        "          - s: stride\n",
        "\n",
        "        Notaci√≥n:\n",
        "          - n: largo secuencia del input x (i.e.  x.shape[0])\n",
        "          - k: tama√±o del filtro (i.e. U.shape[0])\n",
        "          - ell: identificador de filtro (i.e. U.shape[1])\n",
        "  \"\"\"\n",
        "  k = U.shape[0]\n",
        "  ell = U.shape[1]\n",
        "  n = x.shape[0]\n",
        "\n",
        "  # inicializamos el tensor output, de tama√±o ((n-k+s)/s, ell)\n",
        "  out = torch.zeros(((n - k + s) // s, ell))\n",
        "\n",
        "  # un bias por cada filtro l, de tama√±o (ell, )\n",
        "  b = torch.zeros(ell)\n",
        "\n",
        "  # por cada filtro l, convolucionar el filtro con la secuencia input\n",
        "  for l in range(ell):\n",
        "    # extraer filtro correspondiente\n",
        "    u = U[:, l]\n",
        "    for i in range(out.shape[0]):\n",
        "      # convolucionar filtro a tr√°ves del input\n",
        "      out[i, l] = x[(s*i):((s*i)+k)].dot(u) + b[l]\n",
        "  return out"
      ],
      "metadata": {
        "id": "hkQh-F_tMfhC"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cada _output_ asociado al filtro se encuentra en las columnas, en este caso,\n",
        "replicamos los _inputs_ del ejercicio y obtenemos 3 secuencias de largo 5\n",
        "una vez que se convoluciona cada uno de los 3 filtros respectivos con el\n",
        "_input_."
      ],
      "metadata": {
        "id": "w6Htcuryb994"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "conv1D(x, U, s=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vYEZKlk_a45K",
        "outputId": "e207ec08-7751-4630-f552-aa83c88484cc"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-1.,  6.,  1.],\n",
              "        [ 2., -1., -4.],\n",
              "        [ 1., -1.,  2.],\n",
              "        [ 5.,  0., -3.],\n",
              "        [ 0., -1.,  0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Los resultados de la convoluci√≥n previos aplicar la no-linealidad `tanh` elemento-a-elemento\n",
        "en cada vector:\n",
        "\n",
        "$$\\bar{y}^{(\\ell=1)}=(-1, 2, 1, 5, 0) \\in \\mathrm{R}^{5}$$\n",
        "$$\\bar{y}^{(\\ell=2)}=(6, -1, -1, 0, -1) \\in \\mathrm{R}^{5}$$\n",
        "$$\\bar{y}^{(\\ell=3)}=(1, -4, 2, -3, 0) \\in \\mathrm{R}^{5}$$"
      ],
      "metadata": {
        "id": "hSMTp47DfHAn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora aplicamos `tanh` y realizamos _max pooling_."
      ],
      "metadata": {
        "id": "sj2NRMS3eD-s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tanh(conv1D(x, U, s=2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wfb2wL4AfbVs",
        "outputId": "7db1f64d-c5b5-4a55-c2d4-2360fa2a82d7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.7616,  1.0000,  0.7616],\n",
              "        [ 0.9640, -0.7616, -0.9993],\n",
              "        [ 0.7616, -0.7616,  0.9640],\n",
              "        [ 0.9999,  0.0000, -0.9951],\n",
              "        [ 0.0000, -0.7616,  0.0000]])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comparemos el paso anterior, se observa como _max pooling_ agrega y\n",
        "selecciona para cada _feature_ (columna) el m√°ximo valor. Compactando\n",
        "las versiones de output por cada filtro en un solo n√∫mero."
      ],
      "metadata": {
        "id": "J2b0NV5zzf-T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.nn.functional.max_pool1d(tanh(conv1D(x, U, s=2)).permute(1,0), kernel_size=(3,)).permute(1,0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f0t_aY7RfG-v",
        "outputId": "ed83ba64-4432-4189-ba39-55b3027a789d"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.9640, 1.0000, 0.9640]])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Recurrent Neural Networks (1 punto)\n"
      ],
      "metadata": {
        "id": "A0rCwen3WREC"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U0et78Z4oKIq"
      },
      "source": [
        "### Pregunta 4 (0,5 puntos)\n",
        "Usando los embeddings de dos dimensiones de la pregunta anteror, la oraci√≥n `el fuego quema` la podemos representar por una secuencia de vectores $(\\vec{x}_1,\\vec{x}_2,\\vec{x}_3)$, con $\\vec{x}_i \\in \\mathbb{R}^{d_x}$ y $d_x=2$.\n",
        "\n",
        "Tenemos una red recurrente *Elman* definidad como:\n",
        "\\begin{equation}\n",
        "\\begin{split}\n",
        "\\vec{s}_i &= R_{SRNN}\\left (\\vec{x}_i, \\vec{s}_{i-1}\\right ) = g \\left (\\vec{s}_{i-1}W^s + \\vec{x}_i W^x + \\vec{b}\\right ) \\\\\n",
        "\\vec{y}_i &= O_{SRNN}\\left(\\vec{s}_i\\right) = \\vec{s}_i \\\\\n",
        "\\end{split}\n",
        "\\end{equation}\n",
        "donde\n",
        "\\begin{equation}\n",
        "\\vec{s}_i, \\vec{y}_i \\in \\mathbb{R}^{d_s}, \\quad W^x \\in \\mathbb{R}^{d_x \\times d_s}, \\quad W^s \\in \\mathbb{R}^{d_s \\times d_s}, \\quad \\vec{b} \\in \\mathbb{R}^{d_s},\n",
        "\\end{equation}\n",
        "y los vectores de estado $s_i$ son de tres dimensiones, $ds= 3$.\n",
        "\n",
        "Sea\n",
        "\\begin{equation}\n",
        "\\begin{split}\n",
        "\\vec{s}_0 &= [0,0,0]\\\\\n",
        "W^x &= \\begin{pmatrix}\n",
        "0 &  0 & 1\\\\\n",
        "1 & -1 & 0\n",
        "\\end{pmatrix} \\\\\n",
        "W^s &= \\begin{pmatrix}\n",
        "1 & 0 &  1\\\\\n",
        "0 & 1 & -1\\\\\n",
        "1 & 1 &  1\n",
        "\\end{pmatrix} \\\\\n",
        "\\vec{b} &= [0, 0, 0] \\\\\n",
        "g(x) &= ReLu(x) = max(0, x)\n",
        "\\end{split}\n",
        "\\end{equation}\n",
        "\n",
        "<br>\n",
        "\n",
        "Calcule manualmente los valores de los vectores $\\vec{s}_1, \\vec{s}_2,\\vec{s}_3$ y de $\\vec{y}_1, \\vec{y}_2,\\vec{y}_3$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fim2W8JioPhL"
      },
      "source": [
        "**Respuesta**\n",
        "\n",
        "1. Definimos $\\vec{x}_1=[1,0]$,  $~\\vec{x}_2=[-1, 1]$, y $~\\vec{x}_3=[1, 1]$ seg√∫n\n",
        "la posici√≥n original de las palabras `el fuego quema` en la tabla\n",
        "de _embeddings_ $E$ anterior.\n",
        "1. Sabemos que todos los estados $s_{i}$ tienen una dimensionalidad de $d_s=3$.\n",
        "Dado que el _bias_ es 0, por simplificaci√≥n omitimos su notaci√≥n en los\n",
        "siguientes pasos. Adem√°s, para esta red recurrente Elman, $O_{SRNN}(\\cdot)$ es\n",
        "la funci√≥n identidad, por lo que el output $\\vec{y}_i$\n",
        "es simplemente el estado oculto $\\vec{s}_i$. Es decir, los calculos\n",
        "se concentran en estimar los estados ocultos.\n",
        "1. Computamos el primer estado oculto:\n",
        "\\begin{split}\n",
        "\\vec{s}_1 &= \\max(\\boldsymbol 0, ~\\vec{s}_0W^{s} + \\vec{x}_{1}W^{x}) \\\\\n",
        "          &= \\max(\\boldsymbol 0, ~[0,0,0]\\cdot W^{s} + [1,0]\\cdot W^{x}) \\\\\n",
        "          &= \\max(\\boldsymbol 0, [0,0,0] + [0, 0, 1]) \\\\\n",
        "          &=[0,0,1]\n",
        "\\end{split}\n",
        "1. Por lo tanto, $\\vec{y}_1=[0,0,1]$\n",
        "1. Actualizamos el estado oculto $\\vec{s}_2$ usando el estado anterior $\\vec{s}_1$ y el _input_ actual $\\vec{x}_2$:\n",
        "\\begin{split}\n",
        "\\vec{s}_2 &= \\max(\\boldsymbol 0,~\\vec{s}_1W^{s}+\\vec{x}_2W^x) \\\\\n",
        "          &= \\max(\\boldsymbol 0,~[0,0,1]\\cdot W^{s} + [-1,1]\\cdot W^{x}) \\\\\n",
        "          &= \\max(\\boldsymbol 0,~[1, 1, 1] + [1, -1, -1]) \\\\\n",
        "          &= \\max(\\boldsymbol 0, ~ [2, 0, 0]) \\\\\n",
        "          &= [2, 0, 0]\n",
        "\\end{split}\n",
        "1. Por lo tanto, $\\vec{y}_2=[2,0,0]$.\n",
        "1. Finalmente,\n",
        "\\begin{split}\n",
        "\\vec{s}_3 &= \\max(\\boldsymbol 0,~\\vec{s}_2W^{s}+\\vec{x}_3W^x) \\\\\n",
        "          &= \\max(\\boldsymbol 0,~[2,0,0]\\cdot W^{s} + [1,1]\\cdot W^{x}) \\\\\n",
        "          &= \\max(\\boldsymbol 0,~[2, 0, 2] + [1, -1, 1]) \\\\\n",
        "          &= \\max(\\boldsymbol 0, ~ [3, -1, 3]) \\\\\n",
        "          &= [3, 0, 3]\n",
        "\\end{split}\n",
        "1. $\\vec{y}_3=[3, 0, 3]$.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W4rAT6ELxRZW"
      },
      "source": [
        "### Pregunta 5 (0.5 puntos)\n",
        "¬øDe qu√© forma las RNN y las CNN logran aprender representaciones espec√≠ficas\n",
        "para la tarea objetivo? Compare la forma en que las RNN y las CNN aprenden con los modelos que usan *features* dise√±adas manualmente."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6AXbQSgA_t8"
      },
      "source": [
        "**Respuesta**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Las redes convolucionales (CNN) y redes recurrentes (RNN) son un tipo de arquitectura de redes neuronales (NN), las cuales como toda NN, pueden aprender representaciones y resolver alguna tarea objetivo en conjunto a partir de los datos. A diferencia de modelos m√°s cl√°sicos de NLP, los cuales desacoplan la representaci√≥n de los datos con la soluci√≥n de la tarea objetivo, y donde los modelos requieren un dise√±o previo y manual para construir la representaci√≥n del texto (i.e. _feature engineering_), y as√≠ poder resolver la tarea en cuestion (e.g. clasificaci√≥n de sentimientos). Las redes neuronales puede aprender representaciones complejas respecto a informaci√≥n sin una estructura obvia ni f√°cil de representar, y que incluso pueden ser reutilizadas en la soluci√≥n de diversas tareas comparado con representaciones dise√±adas \"a la medida\" para una tarea en espec√≠fico.\n",
        "\n",
        "Respecto al caso particular de trabajar con texto, las arquitecturas de tipo CNN y RNN reciben tensores con secuencias de enteros, los cuales son _tokens_ que representan el texto a cierto nivel (e.g. caracteres, sub-palabras, palabras). Luego, estos enteros se utilizan como identificadores y pasan por una capa de _embeddings_, donde a trav√©s de una\n",
        "operaci√≥n _look-up_, cada _token_ √∫nico (aka vocabulario) se le\n",
        "asocia un vector continuo de $d$ dimensiones. Estos son\n",
        "_features_ que representan a los _tokens_ y son aprendidos durante el entrenamiento de las redes.\n",
        "\n",
        "Las ventajas de las arquitecturas CNN y RNN es que el dise√±o de sus\n",
        "redes facilita aprender relaciones m√°s complejas en los datos versus\n",
        "una arquitectura _fully connected_. En el caso de las CNN\n",
        "se pueden capturar estructuras locales a partir de sus filtros, de los cuales\n",
        "se pueden obtener _features_ de m√°s alto nivel. En cambio, las arquitecturas\n",
        "RNN permiten capturar en un estado la historia de una secuencia de largo arbitrario, y contar como informaci√≥n adicional a la de un _token_\n",
        "en determinado momento, emergiendo conceptos como contexto y temporalidad\n",
        "que no existen una red _fully connected_.\n"
      ],
      "metadata": {
        "id": "zrL4q2Y_ouA4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pregunta 6: Redes Neuronales con Pytorch (3 puntos) üí¨\n",
        "\n",
        "<center>\n",
        "<img src=\"https://www.anda.cl/wp-content/uploads/2021/03/0_5vNAtimPjYQr4W72.gif\" alt=\"chatbot\" width=\"400\">\n",
        "</center>"
      ],
      "metadata": {
        "id": "FRJkBpjWyHnb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En esta secci√≥n de la tarea deber√°n implementar un Chatbot que sea capaz de generar una conversaci√≥n *‚Äúb√°sica‚Äù* utilizando un dataset de *Star Wars*. **El objetivo** de esta pregunta es que puedan aplicar lo aprendido sobre redes neuronales utilizando Pytorch en un ejemplo pr√°ctico.  Durante el desarrollo, se espera que puedan dise√±ar un bot (que tendr√° por atr√°s un clasificador) que sea capaz de clasificar diferentes etiquetas, cosa que una vez identificada la etiqueta entregue una respuesta acorde a lo preguntado.\n",
        "\n",
        "**Aviso:** Antes de comenzar con una descripci√≥n mas profunda de esta secci√≥n, les recomendamos que visualicen y se familiaricen con el dataset entregado, de esta forma comprender√°n mejor la descripci√≥n del enunciado (aqu√≠ una peque√±a ayudita üÜò)."
      ],
      "metadata": {
        "id": "GEla92bUymrQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "\n",
        "example_data = pd.read_json('https://raw.githubusercontent.com/dccuchile/CC6205/master/assignments/star_wars_chatbot.json')\n",
        "print(\"Cantidad de tags: \", example_data['intents'].shape[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0eKOGlMs3Dx-",
        "outputId": "171e42c3-6b67-4be5-f578-104109346acf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cantidad de tags:  16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A continuaci√≥n, ejemplos del contenido del primer registro:"
      ],
      "metadata": {
        "id": "V-6fCE5fHkNS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "example_data['intents'][0]['patterns']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "axsi27BpHGOx",
        "outputId": "c89b3678-3195-4503-9a8e-dc678a3efbbf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Hi',\n",
              " 'Hey',\n",
              " 'How are you',\n",
              " 'Is anyone there?',\n",
              " 'Hello',\n",
              " 'Good day',\n",
              " \"What's up\",\n",
              " 'Yo!',\n",
              " 'Howdy',\n",
              " 'Nice to meet you.']"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example_data['intents'][0]['responses']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OV0vGdwoHeg3",
        "outputId": "23e98870-9157-49c2-d4de-6e54082fa7d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Hey',\n",
              " 'Hello, thanks for visiting.',\n",
              " 'Hi there, what can I do for you?',\n",
              " 'Hi there, how can I help?',\n",
              " 'Hello, there.',\n",
              " 'Hello Dear',\n",
              " 'Ooooo Hello, looking for someone or something?',\n",
              " 'Yes, I am here.',\n",
              " 'Listening carefully.',\n",
              " 'Ok, I am with you.']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example_data['intents'][0]['tag']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "0BnYez1oGtx3",
        "outputId": "0f52cc53-6aae-4bac-b64a-e8cc3cd9d817"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'greeting'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clases = pd.Series([\n",
        "    t[\"tag\"]\n",
        "    for t in example_data[\"intents\"]\n",
        "])\n",
        "clases.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v7frEa2cziKv",
        "outputId": "ed71948f-61bd-4d90-fb01-054cb0231383"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "greeting          1\n",
              "goodbye           1\n",
              "thanks            1\n",
              "tasks             1\n",
              "alive             1\n",
              "Menu              1\n",
              "help              1\n",
              "mission           1\n",
              "jedi              1\n",
              "sith              1\n",
              "bounti hounter    1\n",
              "funny             1\n",
              "about me          1\n",
              "creator           1\n",
              "myself            1\n",
              "stories           1\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = get_tokenizer(\"basic_english\")\n",
        "\n",
        "seq_len = pd.Series([\n",
        "    len([\n",
        "      token\n",
        "      for word in f.split()\n",
        "      for token in tokenizer(word)\n",
        "    ])\n",
        "    for p in example_data[\"intents\"]\n",
        "    for f in p[\"patterns\"]\n",
        "])\n",
        "\n",
        "seq_len.describe(), seq_len.quantile(.9)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VOHdDJQ-0Tlf",
        "outputId": "735374ce-6e97-4b44-9e14-97253ffc65e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(count    97.000000\n",
              " mean      5.175258\n",
              " std       2.622063\n",
              " min       1.000000\n",
              " 25%       4.000000\n",
              " 50%       5.000000\n",
              " 75%       7.000000\n",
              " max      13.000000\n",
              " dtype: float64,\n",
              " 9.0)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seq_len.plot(kind=\"hist\", bins=12);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "UTaF5g1J1-Ft",
        "outputId": "98dc0a08-eba6-4982-829b-16ae973b117f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Del dataset cargado podemos notar que este viene en un formato `JSON`, por lo que sus datos est√°n almacenados en diccionarios. Las llaves de los diccionarios no son aleatorias y estos nos sirven para identificar puntos relevantes en el desarrollo del bot. A continuaci√≥n, se realiza una peque√±a descripci√≥n de las llaves:\n",
        "\n",
        "- `patterns`: Almacena los patrones con los que entrenaremos el modelo üòÆ, en otras palabras, es el corpus de entrenamiento que contiene solo preguntas o expresiones que deber√° responder el bot.\n",
        "- `responses`: Son las respuestas üôã relacionadas a los `patterns`, estas las utilizaremos en una etapa posterior a la clasificaci√≥n, para dar una respuesta aleator√≠a al usuario.\n",
        "- `tag`: Son las labels con las que entrenaremos nuestro modelo üíª.\n",
        "\n",
        "En s√≠ntesis, las `keys` relevantes para el entrenamiento de nuestra red neuronal ser√°n `patterns` (corpus) y `tag` (etiquetas)."
      ],
      "metadata": {
        "id": "v6BvAWCw3zPM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Explicaci√≥n de la tarea a realizar:"
      ],
      "metadata": {
        "id": "KlOAdMjSSzNN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Explicaci√≥n de la tarea a realizar**: Implemente una Class llamada `CNNClassifier` que sea capaz de entrenar un modelo de texto a trav√©s de una red neuronal Feed Forward y una arquitectura convolucional (CNN 1D) [`torch.nn.Conv1d`](https://pytorch.org/docs/stable/generated/torch.nn.Conv1d.html#conv1d) . Para el dise√±o de las redes tienen completa libertad, pero se le aconseja que se gu√≠en de la √∫ltima auxiliar para la construcci√≥n. Es **important√≠simo** que el modelo a crear posea una capa de `Embedding` que se genere en base al entrenamiento del modelo. Creado el modelo, construya una funci√≥n batch para cargar los datos de entrenamiento del modelo.\n",
        "\n",
        "Construido el modelo, compare los resultados obtenidos para una red feed forward y una cnn. Para la comprobaci√≥n de sus resultados ejecute el chatbot y pruebelo, ¬øqu√© configuraci√≥n tiene mejores resultados?, ¬øa qu√© se deberan estos resultados?\n",
        "\n",
        "Ojo que un ejemplo de prueba con el chatbot puede ser (agregue mas preguntas ud):\n",
        "\n",
        "```\n",
        "Let's chat! (type 'finish_chat' to finish the chat)\n",
        "You: hi\n",
        "GA-97: Yes, I am here.\n",
        "You: can you tell me a joke?\n",
        "GA-97: Have you tried the gluten-free Wookiee treats? No, but I heard they are a little Chewy.\n",
        "```\n",
        "\n",
        "El resto del c√≥digo referido a la ejecuci√≥n del chat se los entregamos, por lo que no deber√≠an tener mayores problemas üò∏ (en caso de tener problemas con su c√≥digo, puede modificar cualquier parte sugerida siempre y cuando cumpla lo solicitado).\n",
        "\n",
        "**Igual [mucho texto](https://i0.wp.com/elgeneracionalpost.com/wp-content/uploads/2020/07/mucho-texto.jpg?fit=1280%2C720&ssl=1).... En resumen, ¬øQu√© se solicita?:**\n",
        "\n",
        "- [X] Dise√±ar una red neuronal Feed Forward.\n",
        "- [x] Dise√±ar un red convolucional.\n",
        "- [X] Utilizar una capa de embeddings para generar representaciones vectoriales del corpus.\n",
        "- [X] Crear el m√©todo forward de la clase `CNNClassifier`.\n",
        "- [X] Crear la funci√≥n BATCH.\n",
        "- [X] Probar el modelo y comparar los resultados obtenidos con la red Feed Forward y la red CNN. Comente sus resultados de forma cualitativa, se√±alando con qu√© tipo de red obtuvo mejores resultados con el chatbot.\n",
        "\n",
        "**Nota-1:** El modelo creado debe tener la opci√≥n de entrenar a traves de una feed forward y una CNN. Esto no significa que entrenar√° una FF y una CN, el modelo deber√° recibir un booleano que especifique que tipo de red utilizar√°.\n",
        "\n",
        "**Nota-2:** El dataset se descargar√° autom√°ticamente en la secci√≥n `Carga de Dataset üìö`, no os preocup√©is."
      ],
      "metadata": {
        "id": "9yGApnWVI4cO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Pasemos al C√≥digo ü¶æ\n",
        "\n",
        "Esqueleto propuesto (se **RECOMIENDA** que cambien **SOLO** la red neuronal y la funci√≥n Batch) ü¶¥:"
      ],
      "metadata": {
        "id": "a4bKfAdEy3oD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Instalamos librerias necesarias e importamos üòÄ"
      ],
      "metadata": {
        "id": "RUwxivx2MpMV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Esto toma su tiempo en ejecutarse\n",
        "%%capture\n",
        "!pip install torch==1.8.0+cu111 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "!pip install torchtext==0.9.0"
      ],
      "metadata": {
        "id": "TjSZkBsk1H4f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import json\n",
        "import torch\n",
        "import random\n",
        "from random import choice\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
        "\n",
        "from torch.optim import SGD, lr_scheduler\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.autograd import Variable\n",
        "\n",
        "from itertools import zip_longest\n",
        "\n",
        "import plotly.express as px\n",
        "\n",
        "import numpy as np\n",
        "import nltk\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "\n",
        "from sklearn.metrics import classification_report, accuracy_score"
      ],
      "metadata": {
        "id": "RfZ6SL-Q1Kwd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Carga de Dataset üìö"
      ],
      "metadata": {
        "id": "oj-Epe7XJLrL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# we obtain the dataset\n",
        "!wget 'https://raw.githubusercontent.com/dccuchile/CC6205/master/assignments/star_wars_chatbot.json'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hvlLqYRrVN6l",
        "outputId": "29d9b91f-6db6-4910-868f-9c3879dc1f12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-06-10 13:35:39--  https://raw.githubusercontent.com/dccuchile/CC6205/master/assignments/star_wars_chatbot.json\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 14469 (14K) [text/plain]\n",
            "Saving to: ‚Äòstar_wars_chatbot.json‚Äô\n",
            "\n",
            "\rstar_wars_chatbot.j   0%[                    ]       0  --.-KB/s               \rstar_wars_chatbot.j 100%[===================>]  14.13K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-06-10 13:35:39 (36.6 MB/s) - ‚Äòstar_wars_chatbot.json‚Äô saved [14469/14469]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset using json\n",
        "with open('star_wars_chatbot.json', 'r') as f:\n",
        "    dataset = json.load(f)\n",
        "\n",
        "# Create a vocab with the dataset and get the number of classes that have\n",
        "tokenizer = get_tokenizer(\"basic_english\")\n",
        "vocab = build_vocab_from_iterator(tokenizer(x) for list_words in dataset['intents'] for x in list_words['patterns'])\n",
        "\n",
        "# num_classes = len(dataset['intents']) # esto es demasiado ordinario\n",
        "num_classes = clases.nunique()\n",
        "\n",
        "# Add <unk> and <pad> -> 0, 1 respectively. Makes <unk> default token for missing\n",
        "# mapping word->?->'<unk>'\n",
        "UNK_IDX = 0\n",
        "vocab.insert_token('<unk>', UNK_IDX)\n",
        "vocab.set_default_index(UNK_IDX)\n",
        "vocab.insert_token('<pad>', 1)\n",
        "\n",
        "# Define a list with the labels\n",
        "labels = sorted(set([tag for tag in [intents['tag'] for intents in dataset['intents']]]))\n",
        "\n",
        "# Define a train_list where we can find the info in the format: [(tag_0, text_0)...,(tag_n-1, text_n-1)]\n",
        "train_list = [(labels.index(intents['tag']), text) for intents in dataset['intents'] for text in intents['patterns']]"
      ],
      "metadata": {
        "id": "MbbIsFUG1TXW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# first 5 word index, 0, ..., 4\n",
        "vocab.get_itos()[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vi9Gal8pelYs",
        "outputId": "0b7339dc-5934-4669-e734-3522e1715883"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<unk>', '<pad>', '.', '?', 'you']"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Creaci√≥n del modelo (2 puntos en total)"
      ],
      "metadata": {
        "id": "a52SUNKPJQxi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Construya el modelo\n",
        "class CNNClassifier(nn.Module):\n",
        "    def __init__(self, vocab_size, sequence_length, embed_dim=32, num_classes=10,\n",
        "                 use_cnn=False, cnn_pool_channels=24, cnn_kernel_size=3,\n",
        "                 pad_idx=1, hidden_sizes=[100, 90]):\n",
        "      super().__init__()\n",
        "      self.vocab_size = vocab_size\n",
        "      self.embed_dim = embed_dim\n",
        "      self.T = sequence_length\n",
        "      self.num_classes = num_classes\n",
        "\n",
        "      self.use_cnn = use_cnn\n",
        "\n",
        "      #padidx -> Se indica el √≠ndice del token de padding para que no le afecten los pesos\n",
        "      self.embedding = nn.Embedding(vocab_size, embed_dim, pad_idx)\n",
        "\n",
        "      if self.use_cnn:\n",
        "        # self.K es el tama√±o del kernel y la idea es que cubra K tokens de largo la dimension del embedding\n",
        "        self.K = self.embed_dim * cnn_kernel_size\n",
        "\n",
        "        # la convolucion mueve una ventana de largo self.K, y va saltando\n",
        "        # seg√∫n un stride de self.embed_dim, as√≠ salta la representaci√≥n\n",
        "        # de 1 token seg√∫n las dimensiones del embedding\n",
        "        self.conv_layer = nn.Conv1d(in_channels=1, out_channels=cnn_pool_channels,\n",
        "                               kernel_size=self.K, stride=self.embed_dim)\n",
        "\n",
        "        # TODO: utilizar nn.MaxPool1d en vez de torch.max(..)[0]\n",
        "        #self.pool_layer = nn.MaxPool1d(kernel_size=self.K)\n",
        "        self.linear = nn.Linear(cnn_pool_channels, self.num_classes)\n",
        "\n",
        "      else:\n",
        "        self.hidden_len = len(hidden_sizes)\n",
        "        self.feed_forward = None\n",
        "        layers = []\n",
        "\n",
        "        if self.hidden_len > 0:\n",
        "          # Caso capas ocultas:\n",
        "          # primer mapeo de capa de embedding a primera capa oculta\n",
        "          layers.append(nn.Linear(self.T * self.embed_dim, hidden_sizes[0]))\n",
        "          layers.append(nn.Tanh())\n",
        "\n",
        "          # agregar capas intermedias\n",
        "          for i, s in enumerate(hidden_sizes[1:]):\n",
        "            layers.append(\n",
        "                torch.nn.Linear(hidden_sizes[i], s)\n",
        "            )\n",
        "            # agregar no-linaridad entre capas excepto en la √∫ltima. Generalmente\n",
        "            # no se agrega nada entre la √∫ltima capa oculta y capa de output\n",
        "            if i != (self.hidden_len - 2):\n",
        "              layers.append(nn.Tanh())\n",
        "\n",
        "          # agregar capa final\n",
        "          layers.append(nn.Linear(hidden_sizes[-1], self.num_classes))\n",
        "          self.feed_forward = torch.nn.ModuleList(layers)\n",
        "\n",
        "        else:\n",
        "          # Caso sin capas ocultas: se mapea la capa de embedding directo a las clases\n",
        "          layers.append(nn.Linear(self.T * self.embed_dim, num_classes))\n",
        "          self.feed_forward = torch.nn.ModuleList(layers)\n",
        "          #self.feed_forward = nn.Linear(self.T * self.embed_dim, num_classes)\n",
        "\n",
        "    def init_weights(self):\n",
        "      # Esto puede ser util para inicializar los pesos\n",
        "      pass\n",
        "\n",
        "    def forward(self, x):\n",
        "      # Dimensiones del input x:          # (B, T)\n",
        "      out = self.embedding(x)             # (B, T, E)\n",
        "      out = out.view(out.shape[0], -1)    # (B, T * E)\n",
        "      if self.use_cnn:\n",
        "        # --------------------------------# Caso arquitectura CNN, C = # de filtros o kernels, K: tama√±o del kernel\n",
        "        out = out.unsqueeze(1)            # (B, C, T * E)\n",
        "        out = self.conv_layer(out)        # (B, C, T * E - K + 1)\n",
        "        out = torch.relu(out)\n",
        "        out = torch.max(out, dim=2)[0]    # (B, C)\n",
        "        out = self.linear(out)            # (B, num_classes)\n",
        "        return out\n",
        "      else:\n",
        "        # --------------------------------# Caso arquitectura FeedForward, H[i] = Dimension Hidden i\n",
        "        for layer in self.feed_forward:   # (B, T * E) -> (B, H[i])        - caso con capas ocultas\n",
        "          out = layer(out)                # (B, T * E) -> (B, num_classes) - caso sin capas ocultas\n",
        "        return out                        # (B, num_classes)"
      ],
      "metadata": {
        "id": "n-vQ24tMJG5H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Funci√≥n Batch üë∑ (0,5 puntos)"
      ],
      "metadata": {
        "id": "dGN-T0JoJtmS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defina su funci√≥n de BATCH\n",
        "def generate_batch(batch, max_sequence=60, train=True, debug=False):\n",
        "  \"\"\"\n",
        "    Collate Function para pasar a funci√≥n DataLoader y procesar un batch de\n",
        "    observaciones con la estructura: (label, [\"esto\", \"es\", \"un\", \"text\"]).\n",
        "\n",
        "    Se utiliza tokenizer y vocab (como variables globales) inicializados\n",
        "    previamente para el corpus de entrenamiento.\n",
        "\n",
        "    Se retorna una tupla con dos tensores: ((B, T), (B, ))\n",
        "    Donde B: batch size\n",
        "          T: tama√±o de la secuencia m√°s larga en el batch\n",
        "  \"\"\"\n",
        "\n",
        "  #debug\n",
        "\n",
        "  if debug:\n",
        "    for text in batch:\n",
        "      print(\"texto\", text)\n",
        "\n",
        "      for word in text[0].split():\n",
        "        print(\"palabra\", word)\n",
        "\n",
        "        for token in tokenizer(word):\n",
        "          print(\"token\", token)\n",
        "\n",
        "\n",
        "  # creamos una lista con una lista de enteros representando los token de cada texto\n",
        "  text_i = 1 if train else 0\n",
        "  x = [[vocab[token] for word in text[text_i].split() for token in tokenizer(word)] for text in batch]\n",
        "\n",
        "  # Normalizamos usando el m√°ximo entregado v√≠a par√°metro (i.e. max_sequence)\n",
        "  #-----------------------------------------------------------------------------\n",
        "  x = torch.tensor([\n",
        "      xs + [vocab['<pad>']] * (max_sequence - len(xs))\n",
        "      if len(xs) <= max_sequence\n",
        "      else xs[:max_sequence]\n",
        "      for xs in x\n",
        "  ])\n",
        "\n",
        "  if train:\n",
        "    # creamos tensor con valores del target para cada observaci√≥n del batch\n",
        "    y = torch.tensor([obs[0] for obs in batch])\n",
        "    return x, y\n",
        "\n",
        "  return x"
      ],
      "metadata": {
        "id": "K1AZpXc7JxTa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Sanity Checks üíä\n",
        "\n",
        "@Crist√≥bal: esta secci√≥n la agregu√© para realizar pruebas antes de llegar y saltar a entrenar.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "L2Bi4lWPqy4I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En esta secci√≥n realizamos pruebas en la construcci√≥n de `DataLoader`, inicializci√≥n de la red, y que los datos fluyan correctamente\n",
        "a trav√©s del modelo."
      ],
      "metadata": {
        "id": "7c_yAG-Kq7IB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora podemos usar nuestra funci√≥n para procesar los batches y obtener\n",
        "un tensor `y` para las clases, de tamano `(B,)`, junto a un tensor con las\n",
        "secuencias tokenizadas y normalizadas de tama√±o `(B, T)`. Siendo `B` el\n",
        "tama√±o del _batch_, y `T` el largo de la secuencia m√°xima en el dataset\n",
        "de entrenamiento post proceso."
      ],
      "metadata": {
        "id": "3tApDaTdiJvR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE=8\n",
        "dl = DataLoader(train_list, batch_size=BATCH_SIZE, collate_fn=generate_batch, shuffle=True)"
      ],
      "metadata": {
        "id": "qBByY9bqSDr0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Dimensiones (x, y) de un batch con tama√±o {BATCH_SIZE}:\\n\")\n",
        "xs, ys = next(iter(dl))\n",
        "print(f\"xs: {xs.shape}\")\n",
        "print(f\"ys: {ys.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W7Qbqf8mS9xX",
        "outputId": "3f4fef39-0b98-43c7-bed7-94a1922b87e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dimensiones (x, y) de un batch con tama√±o 8:\n",
            "\n",
            "xs: torch.Size([8, 60])\n",
            "ys: torch.Size([8])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# verificar integer con mapeo stoi de vocab...\n",
        "#vocab[tokenizer('Tell')[0]]"
      ],
      "metadata": {
        "id": "F0aoCvrgTfJM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Caso FeedForward sin capas ocultas:** mapeo directo de los _embeddings_ a las clases."
      ],
      "metadata": {
        "id": "IfxGDZHS8I00"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_CLASSES=10\n",
        "USE_CNN=False\n",
        "model = CNNClassifier(vocab_size=len(vocab), sequence_length=60, embed_dim=32,\n",
        "                      num_classes=NUM_CLASSES, use_cnn=USE_CNN, cnn_pool_channels=None,\n",
        "                      cnn_kernel_size=None, pad_idx=vocab['<pad>'],\n",
        "                      hidden_sizes=[])"
      ],
      "metadata": {
        "id": "U-fXIr4T8MUH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Batch size: {xs.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8vUMZBkX8PTC",
        "outputId": "f6c86dd0-9d0b-4d98-f47e-f2f866ee5cc9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch size: torch.Size([8, 60])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Arquitectura del modelo, caso embedding mapeado directo al output:\\n\\n {model}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4WS7hV7i8Qli",
        "outputId": "e0dea0c1-f7f0-4946-bd0b-583e9643e761"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Arquitectura del modelo, caso embedding mapeado directo al output:\n",
            "\n",
            " CNNClassifier(\n",
            "  (embedding): Embedding(132, 32, padding_idx=1)\n",
            "  (feed_forward): ModuleList(\n",
            "    (0): Linear(in_features=1920, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Pruebas realizadas con arquitectura dise√±ada para {NUM_CLASSES} clases de output\\n\")\n",
        "print(f\"Forward pass y dimensiones del output: {model(xs).shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XeC6LSHC8YTM",
        "outputId": "fe7361c8-c07c-43eb-9d6e-97cd9c7be868"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pruebas realizadas con arquitectura dise√±ada para 10 clases de output\n",
            "\n",
            "Forward pass y dimensiones del output: torch.Size([8, 10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Caso FeedForward una sola capa oculta:**"
      ],
      "metadata": {
        "id": "jMB5ffr07HHE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_CLASSES=20\n",
        "USE_CNN=False\n",
        "model = CNNClassifier(vocab_size=len(vocab), sequence_length=60, embed_dim=32,\n",
        "                      num_classes=NUM_CLASSES, use_cnn=USE_CNN, cnn_pool_channels=None,\n",
        "                      cnn_kernel_size=None, pad_idx=vocab['<pad>'],\n",
        "                      hidden_sizes=[200])"
      ],
      "metadata": {
        "id": "c6l6oOT37yAw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Batch size: {xs.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ic2BPbu372Bw",
        "outputId": "838ca5ff-cd4b-44e6-a92b-1fa7474c6cba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch size: torch.Size([8, 60])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Arquitectura del modelo, caso una sola capa oculta:\\n\\n {model}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N0VdQPx373cd",
        "outputId": "058a6881-1f9f-4347-cd27-3131d56a1d02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Arquitectura del modelo, caso una sola capa oculta:\n",
            "\n",
            " CNNClassifier(\n",
            "  (embedding): Embedding(132, 32, padding_idx=1)\n",
            "  (feed_forward): ModuleList(\n",
            "    (0): Linear(in_features=1920, out_features=200, bias=True)\n",
            "    (1): Tanh()\n",
            "    (2): Linear(in_features=200, out_features=20, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Pruebas realizadas con arquitectura dise√±ada para {NUM_CLASSES} clases de output\\n\")\n",
        "print(f\"Forward pass y dimensiones del output: {model(xs).shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d2mtJRKS8Aqx",
        "outputId": "ef9285d2-c88a-4338-dfed-8af6f154c710"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pruebas realizadas con arquitectura dise√±ada para 20 clases de output\n",
            "\n",
            "Forward pass y dimensiones del output: torch.Size([8, 20])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Caso FeedForward multiples capas ocultas:**"
      ],
      "metadata": {
        "id": "w6VpYApL6c9y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_CLASSES=4\n",
        "USE_CNN=False\n",
        "model = CNNClassifier(vocab_size=len(vocab), sequence_length=60, embed_dim=32,\n",
        "                      num_classes=NUM_CLASSES, use_cnn=USE_CNN, cnn_pool_channels=None,\n",
        "                      cnn_kernel_size=None, pad_idx=vocab['<pad>'],\n",
        "                      hidden_sizes=[20, 25, 50, 25, 20])"
      ],
      "metadata": {
        "id": "4O18NlF1l9Sg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Batch size: {xs.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SBXhpB2QsMqq",
        "outputId": "0ad312a5-afc0-483e-9b9e-3fe2e3489424"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch size: torch.Size([8, 60])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Arquitectura del modelo, caso capas ocultas:\\n\\n {model}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZW8EfVcX2dcs",
        "outputId": "983cc512-fd8e-4cfb-817a-44fccbfdcc3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Arquitectura del modelo, caso capas ocultas:\n",
            "\n",
            " CNNClassifier(\n",
            "  (embedding): Embedding(132, 32, padding_idx=1)\n",
            "  (feed_forward): ModuleList(\n",
            "    (0): Linear(in_features=1920, out_features=20, bias=True)\n",
            "    (1): Tanh()\n",
            "    (2): Linear(in_features=20, out_features=25, bias=True)\n",
            "    (3): Tanh()\n",
            "    (4): Linear(in_features=25, out_features=50, bias=True)\n",
            "    (5): Tanh()\n",
            "    (6): Linear(in_features=50, out_features=25, bias=True)\n",
            "    (7): Tanh()\n",
            "    (8): Linear(in_features=25, out_features=20, bias=True)\n",
            "    (9): Linear(in_features=20, out_features=4, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Pruebas realizadas con arquitectura dise√±ada para {NUM_CLASSES} clases de output\\n\")\n",
        "print(f\"Forward pass y dimensiones del output: {model(xs).shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SjDwXsnArbyz",
        "outputId": "23630570-0f79-4765-c1c9-9c967ac9f7ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pruebas realizadas con arquitectura dise√±ada para 4 clases de output\n",
            "\n",
            "Forward pass y dimensiones del output: torch.Size([8, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Caso CNN:**"
      ],
      "metadata": {
        "id": "LmkKZdl1NjCt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_CLASSES=4\n",
        "NUM_FEATURES=64\n",
        "USE_CNN=True\n",
        "model = CNNClassifier(vocab_size=len(vocab), sequence_length=60, embed_dim=32,\n",
        "                      num_classes=NUM_CLASSES, use_cnn=USE_CNN,\n",
        "                      cnn_pool_channels=NUM_FEATURES, cnn_kernel_size=8,\n",
        "                      pad_idx=vocab['<pad>'], hidden_sizes=None)"
      ],
      "metadata": {
        "id": "5j7aJ6C2NlYD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Batch size: {xs.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Nn3pEDkOCQM",
        "outputId": "98e91fc2-d501-4fd8-8470-7502536b1f17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch size: torch.Size([8, 60])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"La operaci√≥n de convoluci√≥n entrega {NUM_FEATURES} features para realizar la clasificaci√≥n por la √∫ltima capa lineal\\n\")\n",
        "print(f\"Arquitectura del modelo, caso capas ocultas:\\n\\n {model}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d2zhap9JOD8e",
        "outputId": "309314d3-34f5-4f25-b401-46f362e1de6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "La operaci√≥n de convoluci√≥n entrega 64 features para realizar la clasificaci√≥n por la √∫ltima capa lineal\n",
            "\n",
            "Arquitectura del modelo, caso capas ocultas:\n",
            "\n",
            " CNNClassifier(\n",
            "  (embedding): Embedding(132, 32, padding_idx=1)\n",
            "  (conv_layer): Conv1d(1, 64, kernel_size=(256,), stride=(32,))\n",
            "  (linear): Linear(in_features=64, out_features=4, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Pruebas realizadas con arquitectura dise√±ada para {NUM_CLASSES} clases de output\\n\")\n",
        "print(f\"Forward pass y dimensiones del output: {model(xs).shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "44jNDDkHOWCF",
        "outputId": "382e0773-44f4-42e0-ee3c-2ccfad70d21a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pruebas realizadas con arquitectura dise√±ada para 4 clases de output\n",
            "\n",
            "Forward pass y dimensiones del output: torch.Size([8, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Entrenamiento ü•ä"
      ],
      "metadata": {
        "id": "YChwpNrrNRBe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### Funciones"
      ],
      "metadata": {
        "id": "3Op1hOqgsg33"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def training_loop(model, train_list, epochs=1000, batch_size=16, lr=1e-1,\n",
        "                  optimizer=SGD, criterion=nn.CrossEntropyLoss,\n",
        "                  scheduler=lr_scheduler, print_every=100):\n",
        "\n",
        "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "  print(f\"GPU is avaible: {device}\")\n",
        "\n",
        "  model = model.to(device)\n",
        "\n",
        "  optimizer = optimizer(model.parameters(), lr=lr)\n",
        "  criterion = criterion().to(device)\n",
        "  scheduler = scheduler.LambdaLR(optimizer, lr_lambda=[lambda epoch: .9 ** (epoch // 10)])\n",
        "\n",
        "  print(f'train: {len(train_list)} elements')\n",
        "\n",
        "  # We train the model using the intents\n",
        "  loss_list = []\n",
        "  acc_list = []\n",
        "\n",
        "  for epoch in range(1, epochs):\n",
        "    train_loader = DataLoader(train_list, batch_size=BATCH_SIZE, shuffle=True,\n",
        "                              collate_fn=lambda x: generate_batch(x, SEQ_LEN))\n",
        "\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    y_true_list = []\n",
        "    y_pred_list = []\n",
        "\n",
        "    for i, (texts, cls) in enumerate(train_loader):\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      texts = texts.to(device)\n",
        "      cls = cls.to(device)\n",
        "\n",
        "      output = model(texts)\n",
        "\n",
        "      probs = torch.softmax(output, dim=1)\n",
        "      y_hat = probs.argmax(dim=-1)\n",
        "      y_true_list.extend(cls.cpu().detach().tolist())\n",
        "      y_pred_list.extend(y_hat.cpu().detach().tolist())\n",
        "\n",
        "      loss = criterion(output, cls)\n",
        "      total_loss += loss.item()\n",
        "\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "    acc = accuracy_score(y_true_list, y_pred_list)\n",
        "    acc_list.append(acc)\n",
        "    loss_list.append(total_loss)\n",
        "\n",
        "    if epoch % print_every == 0:\n",
        "      print(\n",
        "          f'Epoch: {epoch + 1} \\t Epoch loss: {round(total_loss, 3)}'\n",
        "          f' \\t Epoc Acc (train): {round(acc, 5)}'\n",
        "      )\n",
        "\n",
        "  print(f'\\nfinal loss: {total_loss:.4f}')\n",
        "  print(f\"Best acc: {max(acc_list)} (√âpoca {np.argmax(acc_list)})\")\n",
        "  return model, loss_list, acc_list\n",
        "\n",
        "\n",
        "def text_single_input(model, q_text, seq_len, **kwargs):\n",
        "  padded_X = generate_batch(\n",
        "    [(q_text,)], seq_len, False, **kwargs\n",
        "  )\n",
        "\n",
        "  model.eval()\n",
        "  output = model(padded_X)\n",
        "\n",
        "  _, predicted = torch.max(output, dim=1)\n",
        "  return labels[predicted]\n",
        "\n",
        "\n",
        "def save_model(model, data_dict, file_name):\n",
        "  # We save de model using pytorch (this is optional, just to learn how to do this in pytorch)\n",
        "  data_dict[\"model_state\"] = model.state_dict()\n",
        "  torch.save(data_dict, file_name)\n",
        "\n",
        "  print(f'training complete. file saved to {file_name}')\n",
        "\n",
        "def chat_bot(responses, model, seq_len, bot_name=\"GA-97\", **kwargs):\n",
        "  device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "  model.eval()\n",
        "\n",
        "  print(\"Let's chat! (type 'finish_chat' to finish the chat)\")\n",
        "\n",
        "  while True:\n",
        "      q_text = input(\"You: \")\n",
        "\n",
        "      if q_text == 'finish_chat':\n",
        "          break\n",
        "\n",
        "      padded_X = generate_batch(\n",
        "          [(q_text,)], seq_len, False, **kwargs\n",
        "      )\n",
        "\n",
        "      output = model(padded_X)\n",
        "      _, predicted = torch.max(output, dim=1)\n",
        "\n",
        "      tag = labels[predicted.item()]\n",
        "\n",
        "      probs = torch.softmax(output, dim=1)\n",
        "      prob = probs[0][predicted.item()]\n",
        "\n",
        "      if prob.item() > 0.50:\n",
        "        print(f\"{bot_name}: {random.choice(responses[tag])}\")\n",
        "\n",
        "      else:\n",
        "        print(f\"{bot_name}: My model can't understand you...\")"
      ],
      "metadata": {
        "id": "NwCt9PCRmJqR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### Experimentos"
      ],
      "metadata": {
        "id": "DBXqFyQsslc1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hiperpar√°metros generales a los distintos experimentos\n",
        "BATCH_SIZE = 16\n",
        "LR = 1e-1\n",
        "INPUT_SIZE = len(vocab)\n",
        "OUTPUT_SIZE = num_classes\n",
        "SEQ_LEN = 10"
      ],
      "metadata": {
        "id": "m9n2vQAjpoBj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mlp_1 = CNNClassifier(INPUT_SIZE, SEQ_LEN, num_classes=OUTPUT_SIZE,\n",
        "                      use_cnn=False, hidden_sizes=[])\n",
        "\n",
        "mlp_1, loss_mlp_1, acc_mlp_1 = training_loop(mlp_1, train_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OFcru6ROpW3d",
        "outputId": "9d967c7f-dc72-4b42-ba7e-6a1043ae2895"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU is avaible: cpu\n",
            "train: 97 elements\n",
            "Epoch: 101 \t Epoch loss: 0.117 \t Epoc Acc (train): 1.0\n",
            "Epoch: 201 \t Epoch loss: 0.074 \t Epoc Acc (train): 1.0\n",
            "Epoch: 301 \t Epoch loss: 0.036 \t Epoc Acc (train): 1.0\n",
            "Epoch: 401 \t Epoch loss: 0.035 \t Epoc Acc (train): 1.0\n",
            "Epoch: 501 \t Epoch loss: 0.023 \t Epoc Acc (train): 1.0\n",
            "Epoch: 601 \t Epoch loss: 0.021 \t Epoc Acc (train): 1.0\n",
            "Epoch: 701 \t Epoch loss: 0.015 \t Epoc Acc (train): 1.0\n",
            "Epoch: 801 \t Epoch loss: 0.013 \t Epoc Acc (train): 1.0\n",
            "Epoch: 901 \t Epoch loss: 0.011 \t Epoc Acc (train): 1.0\n",
            "\n",
            "final loss: 0.0119\n",
            "Best acc: 1.0 (√âpoca 17)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mlp_2 = CNNClassifier(INPUT_SIZE, SEQ_LEN, num_classes=OUTPUT_SIZE,\n",
        "                      use_cnn=False, hidden_sizes=[10])\n",
        "\n",
        "mlp_2, loss_mlp_2, acc_mlp_2 = training_loop(mlp_2, train_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J2grMqR6sqUj",
        "outputId": "32583d13-bd72-49ea-b860-ba7cc50dfc63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU is avaible: cpu\n",
            "train: 97 elements\n",
            "Epoch: 101 \t Epoch loss: 0.449 \t Epoc Acc (train): 1.0\n",
            "Epoch: 201 \t Epoch loss: 0.198 \t Epoc Acc (train): 1.0\n",
            "Epoch: 301 \t Epoch loss: 0.118 \t Epoc Acc (train): 1.0\n",
            "Epoch: 401 \t Epoch loss: 0.073 \t Epoc Acc (train): 1.0\n",
            "Epoch: 501 \t Epoch loss: 0.066 \t Epoc Acc (train): 1.0\n",
            "Epoch: 601 \t Epoch loss: 0.062 \t Epoc Acc (train): 1.0\n",
            "Epoch: 701 \t Epoch loss: 0.04 \t Epoc Acc (train): 1.0\n",
            "Epoch: 801 \t Epoch loss: 0.038 \t Epoc Acc (train): 1.0\n",
            "Epoch: 901 \t Epoch loss: 0.03 \t Epoc Acc (train): 1.0\n",
            "\n",
            "final loss: 0.0303\n",
            "Best acc: 1.0 (√âpoca 48)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_1 = CNNClassifier(INPUT_SIZE, SEQ_LEN, num_classes=OUTPUT_SIZE,\n",
        "                      use_cnn=True, hidden_sizes=[])\n",
        "\n",
        "cnn_1, loss_cnn_2, acc_cnn_2 = training_loop(cnn_1, train_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l4r64iv6s7ZG",
        "outputId": "49c222bc-a3b0-4496-fc04-ba519220cb60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU is avaible: cpu\n",
            "train: 97 elements\n",
            "Epoch: 101 \t Epoch loss: 0.08 \t Epoc Acc (train): 1.0\n",
            "Epoch: 201 \t Epoch loss: 0.024 \t Epoc Acc (train): 1.0\n",
            "Epoch: 301 \t Epoch loss: 0.014 \t Epoc Acc (train): 1.0\n",
            "Epoch: 401 \t Epoch loss: 0.012 \t Epoc Acc (train): 1.0\n",
            "Epoch: 501 \t Epoch loss: 0.007 \t Epoc Acc (train): 1.0\n",
            "Epoch: 601 \t Epoch loss: 0.006 \t Epoc Acc (train): 1.0\n",
            "Epoch: 701 \t Epoch loss: 0.005 \t Epoc Acc (train): 1.0\n",
            "Epoch: 801 \t Epoch loss: 0.004 \t Epoc Acc (train): 1.0\n",
            "Epoch: 901 \t Epoch loss: 0.003 \t Epoc Acc (train): 1.0\n",
            "\n",
            "final loss: 0.0037\n",
            "Best acc: 1.0 (√âpoca 22)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### A probar! üß™"
      ],
      "metadata": {
        "id": "9dlS4_X-L3DN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "q_text = \"'Do you know any joke?'\" # this must classify the label \"funny\"\n",
        "\n",
        "print(text_single_input(mlp_1, q_text, SEQ_LEN))\n",
        "print(text_single_input(mlp_2, q_text, SEQ_LEN))\n",
        "print(text_single_input(cnn_1, q_text, SEQ_LEN))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6IhhAKFXL3eH",
        "outputId": "e6809cde-6de9-4c01-83a9-382f285dab60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Menu\n",
            "sith\n",
            "Menu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ya pero prometiste hacer un chatbot, no una simple clasificaci√≥n...."
      ],
      "metadata": {
        "id": "udemze3zL549"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Guardamos modelo ü¶∫ (opcional)"
      ],
      "metadata": {
        "id": "OpSYGx2tL0tC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_dict = {\n",
        "  \"input_size\": INPUT_SIZE,\n",
        "  \"output_size\": OUTPUT_SIZE,\n",
        "  \"sequence_length\": SEQ_LEN,\n",
        "  \"labels\": labels\n",
        "}\n",
        "\n",
        "mlp_1_dict = data_dict.copy()\n",
        "mlp_1_dict[\"hidden_sizes\"] = []\n",
        "mlp_1_dict[\"use_cnn\"] = False\n",
        "\n",
        "mlp_2_dict = data_dict.copy()\n",
        "mlp_2_dict[\"hidden_sizes\"] = [10]\n",
        "mlp_2_dict[\"use_cnn\"] = False\n",
        "\n",
        "cnn_1_dict = data_dict.copy()\n",
        "cnn_1_dict[\"hidden_sizes\"] = []\n",
        "cnn_1_dict[\"use_cnn\"] = True\n",
        "\n",
        "save_model(mlp_1, mlp_1_dict, \"mlp_1.pth\")\n",
        "save_model(mlp_2, mlp_2_dict, \"mlp_2.pth\")\n",
        "save_model(cnn_1, cnn_1_dict, \"cnn_1.pth\")"
      ],
      "metadata": {
        "id": "ZBC4TyiqLzDv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0bca8586-70ec-4cf6-d51a-f1b63f7a56ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training complete. file saved to mlp_1.pth\n",
            "training complete. file saved to mlp_2.pth\n",
            "training complete. file saved to cnn_1.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Chatbot üí¨"
      ],
      "metadata": {
        "id": "ZYClbTtsMCjE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "responses = {key['tag']: key['responses'] for key in dataset['intents']}\n",
        "\n",
        "chat_bot(responses, mlp_1, SEQ_LEN)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UyaApiA2v0sk",
        "outputId": "b65cdeec-f14d-44ec-9735-957f9401103a"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Let's chat! (type 'finish_chat' to finish the chat)\n",
            "You: hello there\n",
            "GA-97: Hi there, how can I help?\n",
            "You: I have a bad feeling about this\n",
            "GA-97: My model can't understand you...\n",
            "You: finish_chat\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat_bot(responses, mlp_2, SEQ_LEN)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1xiDZUDFx43s",
        "outputId": "6c55a741-8f13-42eb-b7d4-2f536cf94851"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Let's chat! (type 'finish_chat' to finish the chat)\n",
            "You: hello there\n",
            "GA-97: Hey\n",
            "You: I have a bad feeling about this\n",
            "GA-97: be carreful with your choise: Fuzzy Tauntaun, Bloody Rancor, Jedi Mind Trick, T-16 Skyhopper, Yub Nub, Jet Juice, Hyperdrive, Rancor Beer.\n",
            "You: finish_chat\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat_bot(responses, cnn_1, SEQ_LEN)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EcP1Sv2hyCmw",
        "outputId": "ea687a21-4375-4027-e599-16e1628d99fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Let's chat! (type 'finish_chat' to finish the chat)\n",
            "You: hello there\n",
            "GA-97: Hello, there.\n",
            "You: I have a bad feeling about this\n",
            "GA-97: be carreful with your choise: Fuzzy Tauntaun, Bloody Rancor, Jedi Mind Trick, T-16 Skyhopper, Yub Nub, Jet Juice, Hyperdrive, Rancor Beer.\n",
            "You: finish_chat\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Comente los resultados aqu√≠ (0,5 puntos)"
      ],
      "metadata": {
        "id": "5Hu2QTuSURCt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dada la baja cantidad de datos proporcionados, no se realiz√≥ una divisi√≥n adicional para datos de prueba. Por tanto, solo se realiz√≥ medici√≥n de accuracy de cada √©poca en los datos de entrenamiento. En los tres experimentos realizados, se observa un aparente sobreajuste, ya que todos alcanzan un accuracy de 1 en los datos de entrenamiento. Nuevamente, esto se deba a la baja cantidad de datos proporcionados, ya que las redes neuronales, al ser modelos complejos, requieren de gran cantidad de datos para alcanzar un buen poder predictivo y a la vez buena capacidad de generalizaci√≥n.\n",
        "\n",
        "En cuanto a las pruebas de inferencia realizadas, es dif√≠cil realizar conclusiones frente a la baja cantidad de casos, pero al menos para una frase en particular se observa que el modelo MLP sin capas ocultas no logra obtener una probabilidad sobre 0.5.\n",
        "\n",
        "En conclusi√≥n, si bien las distintas arquitecturas propuestas parecen indicar que se obtiene un mejor desempe√±o, ya sea con una red MLP con capas ocultas, o con una CNN de 1 dimensi√≥n, se requiere de mayor cantidad de datos de entrenamiento (y una partici√≥n de test para evaluar desempe√±o) para determinar qu√© arquitectura es mejor para resolver esta tarea."
      ],
      "metadata": {
        "id": "fdFV63WVUX32"
      }
    }
  ]
}