{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "L2Bi4lWPqy4I",
        "3Op1hOqgsg33"
      ],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UwaDuQqCOyLJ"
      },
      "source": [
        "# **Tarea 4 - CC6205 Natural Language Processing 📚**\n",
        "\n",
        "**Integrantes:** Cristóbal Alcázar, Gianina Salomó\n",
        "\n",
        "**Fecha límite de entrega 📆:** Martes 13 de junio.\n",
        "\n",
        "**Tiempo estimado de dedicación:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X4lL5hGw07yP"
      },
      "source": [
        "Bienvenid@s a la cuarta tarea del curso de Natural Language Processing (NLP).\n",
        "En esta tarea estaremos tratando el problema de **tagging** (generación de secuencias de etiquetas del mismo largo que la secuencia de input), el uso de **Convolutional Neural Networks** y **Recurrent Neural Networks**, e implementaremos una red usando PyTorch.\n",
        "\n",
        "Usen $\\LaTeX$ para las fórmulas matemáticas. En la parte de programación pueden usar lo que quieran, pero la [Auxiliar 3](https://youtu.be/36WTXvg3zh0) les puede ser de *gran ayuda*.\n",
        "\n",
        "**Instrucciones:**\n",
        "- La tarea se realiza en grupos de **máximo** 2 personas. Puede ser invidivual pero no es recomendable.\n",
        "- La entrega es a través de u-cursos a más tardar el día estipulado arriba. No se aceptan atrasos.\n",
        "- El formato de entrega es este mismo Jupyter Notebook.\n",
        "- Al momento de la revisión tu código será ejecutado. Por favor verifica que tu entrega no tenga errores de compilación.\n",
        "- En el horario de auxiliar pueden realizar consultas acerca de la tarea a través del canal de Discord del curso.\n",
        "\n",
        "Si aún no han visto las clases, se recomienda visitar los links de las referencias.\n",
        "\n",
        "**Referencias:**\n",
        "\n",
        "- [Tagging, and Hidden Markov Models ](http://www.cs.columbia.edu/~mcollins/cs4705-spring2019/slides/tagging.pdf) (slides by Michael Collins), [notes](http://www.cs.columbia.edu/~mcollins/hmms-spring2013.pdf), [video 1](https://youtu.be/-ngfOZz8yK0), [video 2](https://youtu.be/Tjgb-yQOg54), [video 3](https://youtu.be/aaa5Qoi8Vco), [video 4](https://youtu.be/4pKWIDkF_6Y)\n",
        "- [MEMMs and CRFs](https://github.com/dccuchile/CC6205/blob/master/slides/NLP-CRF.pdf): [notes 1](http://www.cs.columbia.edu/~mcollins/crf.pdf), [notes 2](http://www.cs.columbia.edu/~mcollins/fb.pdf), [video 1](https://youtu.be/qlI-4lSUDkg), [video 2](https://youtu.be/PLoLKQwkONw), [video 3](https://youtu.be/ZpUwDy6o28Y)\n",
        "- [Convolutional Neural Networks](https://github.com/dccuchile/CC6205/blob/master/slides/NLP-CNN.pdf): [video](https://youtu.be/lLZW5Fn40r8)\n",
        "- [Recurrent Neural Networks](https://github.com/dccuchile/CC6205/blob/master/slides/NLP-RNN.pdf): [video 1](https://youtu.be/BmhjUkzz3nk), [video 2](https://youtu.be/z43YFR1iIvk), [video 3](https://youtu.be/7L5JxQdwNJk)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hidden Markov Models (HMM), Maximum Entropy Markov Models (MEMM) and Conditional Random Field(CRF) (1,5 puntos)"
      ],
      "metadata": {
        "id": "ANqzQ3G9WNw3"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bWXD3D7RYKJ-"
      },
      "source": [
        "### Pregunta 1 (1 pt)\n",
        "Para un problema de POS tagging se define el conjunto de etiquetas $S = \\{ \\text{DET}, \\text{NOUN}, \\text{VERB}, \\text{ADP} \\}$ y se tiene un Hidden Markov Model con los siguientes parámetros estimados a partir de un corpus de entrenamiento:\n",
        "\n",
        "\\begin{equation}\n",
        "\\begin{split}\n",
        "q(\\text{NOUN}| \\text{ VERB}, \\text{DET}) &= 0.3 \\\\\n",
        "q(\\text{NOUN}|\\ w, \\text{DET}) &= 0 \\qquad \\forall w \\in S, w \\neq \\text{VERB} \\\\\n",
        "q(\\text{DET}| \\text{ VERB}, \\text{NOUN}) &= 0.4 \\\\\n",
        "q(\\text{DET}|\\ w, \\text{NOUN}) &= 0 \\qquad \\forall w \\in S, w \\neq \\text{VERB} \\\\\n",
        "e(the|\\text{ DET}) &= 0.5 \\\\\n",
        "e(pasta|\\text{ NOUN}) &= 0.6\n",
        "\\end{split}\n",
        "\\end{equation}\n",
        "\n",
        "Luego para la oración: `the man is pouring sauce on the pasta`, se tiene una tabla de programación dinámica con los siguientes valores:\n",
        "\\begin{equation}\n",
        "\\begin{split}\n",
        "\\pi(7,\\text{DET},\\text{DET})&=0.1\\\\\n",
        "\\pi(7,\\text{NOUN},\\text{DET})&=0.2\\\\\n",
        "\\pi(7,\\text{VERB},\\text{DET})&=0.01\\\\\n",
        "\\pi(7,\\text{ADP},\\text{DET})&=0.5\n",
        "\\end{split}\n",
        "\\end{equation}\n",
        "\n",
        "Con esta información, calcule el valor de $\\pi(8,\\text{DET},\\text{NOUN})$. Puede dejar el resultado expresado como una fracción.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5EzgysW9kGi-"
      },
      "source": [
        "**Respuesta**\n",
        "\n",
        "Se tiene la siguiente función recursiva para cualquier $k \\in {1 \\dots 8}$, para cualquier $u \\in S_{k-1}$ y $v \\in S_k$.\n",
        "\n",
        "$$\n",
        "\\begin{align}\n",
        "\\pi(k, u, v) &= \\underset{\\substack{w \\in S_{k-2}}}{\\text{max}} \\;(\\pi(k-1, w, u) \\times q(v|w, u) \\times e(x_k|v))\n",
        "\\end{align}\n",
        "$$\n",
        "\n",
        "Donde:\n",
        "* $k$: Posición dentro de la oración\n",
        "* $u$: Etiqueta de la posición $k-1$\n",
        "* $v$: Etiqueta de la posición $k$\n",
        "* $w$: Etiqueta de la posición $k-2$\n",
        "* $x_k$: Palabra en la posición $k$\n",
        "\n",
        "Se calcula $\\pi(k-1, w, u) \\times q(v|w, u) \\times e(x_k|v)$ para cada elemento de $S$:\n",
        "\n",
        "$\n",
        "\\pi(7, \\text{DET}, \\text{DET}) \\times q(\\text{NOUN}|\\text{DET}, \\text{DET}) \\times e(\\text{pasta}|\\text{NOUN}) = 0.1 \\times 0 \\times 0.6 = 0\n",
        "$\n",
        "$\n",
        "\\pi(7, \\text{NOUN}, \\text{DET}) \\times q(\\text{NOUN}|\\text{NOUN}, \\text{DET}) \\times e(\\text{pasta}|\\text{NOUN}) = 0.2 \\times 0 \\times 0.6 = 0\n",
        "$\n",
        "$\n",
        "\\pi(7, \\text{VERB}, \\text{DET}) \\times q(\\text{NOUN}|\\text{VERB}, \\text{DET}) \\times e(\\text{pasta}|\\text{NOUN}) = 0.01 \\times 0.3 \\times 0.6 = 0.0018\n",
        "$\n",
        "$\n",
        "\\pi(7, \\text{ADP}, \\text{DET}) \\times q(\\text{NOUN}|\\text{ADP}, \\text{DET}) \\times e(\\text{pasta}|\\text{NOUN}) = 0.5 \\times 0 \\times 0.6 = 0\n",
        "$\n",
        "\n",
        "\n",
        "Entonces\n",
        "\n",
        "$$\n",
        "\\begin{align}\n",
        "\\pi(8, \\text{DET}, \\text{NOUN}) &= \\text{max}(0, 0, 0.0018, 0) = 0.0018\n",
        "\\end{align}\n",
        "$$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oiwJb_vmkKLZ"
      },
      "source": [
        "### Pregunta 2 (0.5 pts)\n",
        "Comente  sobre las similitudes o diferencias entre los HMMs, MEMMs y CRFs. Para esto, responda las siguientes preguntas.\n",
        "\n",
        "#### 2.1. ¿Para qué tipo de tarea sirven? Dé dos ejemplo de este tipo de tarea y descríbalos brevemente. (0.1 pts)\n",
        "\n",
        "**Respuesta:**\n",
        "\n",
        "Sirven para el tipo de tarea de _sequence labeling_, donde el output (secuencia de etiquetas) es del mismo largo del input (secuencia de tokens). Dos tareas que se pueden modelar como problemas de sequence labeling son:\n",
        "* **POS tagging**: Etiquetado de _part of speech_. El output es la secuencia de POS para cada token del input. La idea es entender cuál es el rol sintáctico que tiene una palabra en la oración, lo cual depende del contexto. Algunos POS son NOUN, VERB, PREPOSITION.\n",
        "* **NER**: _Named Entity Recognition_, que corresponde a la detección de entidades nombradas de cada token del input. Algunas entidades pueden ser \"Location\" o \"Company\", dependiendo de qué entidades se desea identificar. Para el resto de entidades, se usa la etiqueta \"NA\" (ninguna entidad).\n",
        "\n",
        "#### 2.2. ¿Qué modelos usan features? ¿Qué ventajas conlleva esto? (0.1 pts)\n",
        "\n",
        "**Respuesta:**\n",
        "\n",
        "Los modelos que usan features son MEMMs y CRFs. La ventaja de esto es que en los features se puede añadir información que no se puede codificar trivialmente en una HMM, como ver relaciones entre las etiquetas y las palabras. Las features pueden ser combinaciones de covocabulario, palabras, o del espacio de etiquetas, tomando en cuenta por ejemplo prefijos y sufijos.\n",
        "\n",
        "#### 2.3. ¿Cómo maneja cada uno de los modelos las palabras con baja frecuencia en el set de train? (0.1 pts)\n",
        "\n",
        "**Respuesta:**\n",
        "\n",
        "En el caso de HMM, se divide el vocabulario en un conjunto de palabras frecuentes y otro de palabras infrecuentes, siendo las primeras las que ocurren algún número mínimo de veces en el corpus de entrenamiento (ej: 5). Luego se mapea todas las palabras de baja frecuencia, según sus sufijos y prefijos, a un conjunto fijo de categorías (ej: token \"90\" se puede mapear a la categoría twoDigitNum).\n",
        "\n",
        "En el caso de MEMMs, se beneficia de la construcción de features que pueden hacer uso de los sufijos y prefijos de las palabras y asocian esto con la etiqueta (ej en inglés: si termina en \"ly\" es adverbio), o relaciones entre los tokens (ej en inglés: si la palabra anterior es adjetivo, la actual es sustantivo). De esta forma si la palabra es poco frecuente, pero cumple con las reglas de las features, va a contribuir a aumentar el peso asociado las features en entrenamiento.\n",
        "\n",
        "En el caso de CRF, tiene la ventaha de que resuelve el problema de sesgo de etiqueta; Como MEMM hace una normalización local, se pierde información de cosas que co ocurren poco frecuentemente en todo el corpus. En cambio, CRF soluciona el problema anterior porque hace una optimización global, entonces considera puntajes para las secuencias completas antes de hacer la normalización.\n",
        "\n",
        "#### 2.4. ¿Qué le permite a los CRF realizar decisiones globales? ¿Qué diferencia con respecto a los MEMMs permite lograr esto? ¿Por qué los HMMs tampoco son capaces de tomar decisiones globales? (0.1 pts)\n",
        "\n",
        "**Respuesta:**\n",
        "\n",
        "Lo que permite a los CRF realizar decisiones globales es que se modela la probabilidad de la secuencia de etiquetas candidatas dado la secuencia de palabras del input, $P(s_{1:m}|x_{1:m})$, directamente con un modelo lineal, el cual normaliza por todas las secuencias posibles, siendo entonces una normalización global (la suma corre por todas las secuencias de etiquetas posibles, $|S|^m$, siendo $m$ la cantidad de tokens del input o de etiquetas del output). Tienen un feature vector global para todas las secuencias, que toma en cuenta toda la secuencia de etiquetas (no se restringe a una posición).\n",
        "\n",
        "Lo que diferencia a los CRF respecto de los MEMMs para lograr lo anterior es que los MEMMs no modelan directamente la probabilidad condicional $P(s_{1:m}|x_{1:m})$, sino que hacen un supuesto de independencia Markoviano que asume que la etiqueta solamente depende de la etiqueta anterior, modelando esto con un modelo log lineal.\n",
        "\n",
        "Los HMM tampoco son capaces de tomar decisiones globales ya que también aplican un supuesto de independencia Markoviano para la probabilidad conjunta de la secuencia de palabras y la secuencia de etiquetas, donde cada etiqueta solo depende de sus dos etiquetas anteriores, y cada palabra solo depende de su etiqueta correspondiente (por ende todo lo demás, que permitiría realizar una decisión global, lo considera independiente).\n",
        "\n",
        "#### 2.5 Dado una secuencia de $x_1, ..., x_m$ ¿Cuántas posibles secuencias de etiquetas se pueden generar para un conjunto de etiquetas $S$ con $|S|=k$ ? ¿Analizarlas todas sería computacionalmente tratable? (0.1 pts)\n",
        "\n",
        "**Respuesta:**\n",
        "\n",
        "El número de posibles secuencias de etiquetas que se pueden generar para un conjunto de etiquetas $S$ con $|S|=k$ es de $k^m$. Es decir, el número de secuencias posibles crece exponencialmente con el largo de la secuencia. Por tanto, analizar todas las posibles frecuencias _no_ es coputacionalmente tratable; Se tendría que evaluar la secuencia de palabras para todas las secuencias posibles de etiquetas, y para todas calcular la probabilidad. Para la decodificación entonces, lo que se hace en su lugar es utilizar una técnica de programación dinámica, como el algoritmo de Viterbi, que permite encontrar la secuencia más probable de manera eficiente, logrando esto en tiempo polinomial en lugar de tiempo exponencial."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Convolutional Neural Networks (0,5 puntos)"
      ],
      "metadata": {
        "id": "44ACHHZIWGF1"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ClRAHR95Y8aB"
      },
      "source": [
        "### Pregunta 3 (0,5 puntos)\n",
        "\n",
        "Considere la frase $w_{1..7}=$ `El agua moja y el fuego quema` $=[El, agua, moja, y, el, fuego, quema]$.\n",
        "\n",
        "La siguiente matriz de embeddings, donde la i-ésima fila corresponde al vector de embedding de la i-ésima palabra, ordenadas según aparecen en la frase. (vectores de largo 2).\n",
        "\\begin{equation}\n",
        "E = \\begin{pmatrix}\n",
        "2 & 2\\\\\n",
        "0 & -2\\\\\n",
        "0 & 1\\\\\n",
        "-2 & 1\\\\\n",
        "1 & 0\\\\\n",
        "-1 & 1\\\\\n",
        "1 & 1\n",
        "\\end{pmatrix}\n",
        "\\end{equation}\n",
        "\n",
        "Los siguientes 3 filtros\n",
        "\\begin{equation}\n",
        "U = \\begin{pmatrix}\n",
        "-1 & 1 & 0\\\\\n",
        "1 & 1 & 0\\\\\n",
        "0 & 0 & -1\\\\\n",
        "1 & -1 & -1\\\\\n",
        "-1 & -1 & 1\\\\\n",
        "1 & 0 & -1\n",
        "\\end{pmatrix}\n",
        "\\end{equation}\n",
        "\n",
        "Y la función de activación\n",
        "\\begin{equation}\n",
        "tanh = \\frac{e^{2x} - 1}{e^{2x} + 1}\n",
        "\\end{equation}\n",
        "\n",
        "Usando estos paramátros escriba los pasos para calcular la representación (vector) resultante de aplicar la operación de convolución (sin padding) + max pooling. ¿De qué tamaño sería la ventana que debemos usar?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SlQ30Arkq0u4"
      },
      "source": [
        "**Respuesta**\n",
        "\n",
        "Pasos para calcular la reepresentación resultante de la convolución:\n",
        "\n",
        "1. Utilizando los índices que representan cada palabra, realizamos una\n",
        "operación _look-up_ en la tabla de _embeddings_ $E$ para obtener la\n",
        "representación vectorial continua y compacta de estas. Cada una de las palabras $w_{1:7}$ de la frase `El agua moja y el fuego quema` es representada por un vector $E_{[w_j]}=\\bar{w}_{j}\\in \\mathrm{R}^2$ (i.e. filas en $E$).\n",
        "2. Luego, concatenamos todos estos vectores que conforman la frase de 7 palabras, y obtenemos el input que ingresará a la red $\\bar{x}\\in\\mathrm{R}^{7\\cdot 2=14}$.\n",
        "<br>\n",
        "\n",
        "$$\n",
        "\\bar{x}=\\oplus~(\\bar{w}_1, \\dots, \\bar{w}_7)\n",
        "$$\n",
        "<br>\n",
        "3. La matriz $U\\in\\mathrm{R}^{k\\times\\ell}$ contiene $\\ell=3$ diferentes filtros representados por sus columnas, todos de largo $k=6$.\n",
        "Se convolucionaran estas 3 \"versiones\" de ventanas móviles de largo $6$ con el\n",
        "_input_ $\\bar{x}$ de largo $n=14$. Debemos considerar el parámetro [_stride_](https://d2l.ai/chapter_convolutional-neural-networks/padding-and-strides.html#stride)\n",
        "en el movimiento de las ventanas, en este caso particular, la ventana de largo $k=6$ se mueve saltando 2 posiciones, es decir según un _stride_ de $s=2$. Este\n",
        "parámetro responde al número de dimensiones de los _embeddings_, y es porque\n",
        "búscamos tratarlos como unidades indivisibles a esta operación. Nos gustaría\n",
        "realizar operaciones sobre varios vectores de _embeddings_, pero no sobre versiones parciales de estos vectores. **La formula que determina el tamaño del _output_ de la convolución, sin considerar _padding_,\n",
        "y con un _stride_ de $2$, es $(n-k+s)~/~s=(14-6+2)~/~2=5$**. Es decir, tendremos $3$ \"versiones\" de secuencias _output_ de largo $5$ (una por cada $\\ell$). Esto como resultado de convolucionar cada filtro a lo largo de toda la secuencia _input_.\n",
        "4. **Sobre el tamaño de la ventana que debemos usar**; nuestra\n",
        "matriz de pesos $U$, tiene en las columnas los filtros, y en las filas `k= (dim. embedding) x (# tokens en la ventana)` (i.e. $2\\times 3$). Es decir, **estamos computando\n",
        "representaciones con un tamaño de ventana de $3$ tokens, o trigramas, usando convoluciones**. El tamaño del _output_ pensando en tokens, es $n-k+1=7-3+1=5$ (sin _padding_). Este coincide con el tamaño\n",
        "del punto (3), solo que en esta version pensamos los parámetros de la convolución respecto a lo que estamos representando que son los _tokens_ (i.e.\n",
        "palabras) que búscamos modelar. En cambio, en el punto anterior (3), estamos pensando los parámetros\n",
        "directos que recibirá la capa de convolución, en este caso no son los mismos, porque hay una capa de representación entremedio que son los _embeddings_. Esto es importante\n",
        "cuando se realiza una implementación de esto, dado que las capas de convolución necesitan considerar en su parámetro de tamaño de ventana la dimension de los _embeddings_, y además el _stride_ para computar los n-gramas correctamente.\n",
        "5. Cuando el filtro esta convolucionando con secciones de la secuencia del\n",
        "_input_ (i.e. `x[i*s:(i*s+k)]`), se realiza una operación lineal de la sub-secuencia del _input_ con los parámetros del filtro que es un producto punto + el _bias_, seguido\n",
        "de una no-linealidad como la `tanh`: `tanh(x[s*i:(s*i+k)].dot(U[:,l])+b[l])`. El resultado es un escalar, y se repite esta operación con las 5 sub-secuencias según el movimiento de la ventana, dando\n",
        "en conjunto el output de la convolución.\n",
        "<br>\n",
        "\n",
        "$$\n",
        "\\{y^{(\\ell)}\\}_{0:5}=\\tanh\\big(\\bar{x}_{2\\cdot i:(2\\cdot i+6)}\\cdot \\bar{u}_{\\ell} + b_{\\ell}\\big),~i=0,\n",
        "\\dots, 5.~~\\bar{u}_{\\ell}=U_{[:, \\ell]}\n",
        "$$\n",
        "<br>\n",
        "6. Dado que tenemos 3 filtros, obtendremos 3 versiones del _output_\n",
        "$\\{y^{(\\ell)}\\}_{0:5}$, cada uno de los filtros\n",
        "comparte un mismo conjunto de pesos o parámetros. Excluyendo el _bias_ en\n",
        "cada filtro, tenemos $k=6$ parámetros por cada filtro $\\ell=3$, un total de $6\\times 3=18$ parámetros encargados de aprender representaciones locales del texto. Considerando el _bias_, tenemos 1 por cada grupo, subiendo a un total\n",
        "de $18+3=21$ parámetros relacionados a las operaciones de convolución.\n",
        "7. Finalmente, aplicamos _max pooling_ para agregar la secuencia\n",
        "de la convolución en el máximo valor, terminaremos con un valor por\n",
        "cada canal/filtro/kernel, es decir de tamaño 3."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A continuación se implementa en código con los valores de los\n",
        "parámetros los pasos anteriores para obtener el vector resultado\n",
        "de largo 3, después de aplicar _max pooling_."
      ],
      "metadata": {
        "id": "8JkztoTAe2ef"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Código ilustrando e implementando los pasos anteriores:"
      ],
      "metadata": {
        "id": "5iDnPZgGZRrx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definimos $w, E, U$ según el enunciado de la pregunta."
      ],
      "metadata": {
        "id": "ebsehWBtTZ6C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# definir activación tanh\n",
        "tanh = lambda x: (torch.exp(2 * x) - 1) / (torch.exp(2 * x) + 1)\n",
        "\n",
        "E = torch.tensor([[ 2, 2],\n",
        "                  [ 0,-2],\n",
        "                  [ 0, 1],\n",
        "                  [-2, 1],\n",
        "                  [ 1, 0],\n",
        "                  [-1, 1],\n",
        "                  [ 1, 1]], dtype=torch.float)\n",
        "\n",
        "U = torch.tensor([[-1, 1, 0],\n",
        "                  [ 1, 1, 0],\n",
        "                  [ 0, 0,-1],\n",
        "                  [ 1,-1,-1],\n",
        "                  [-1,-1, 1],\n",
        "                  [1, 0, -1]], dtype=torch.float)\n",
        "\n",
        "# vector de enteros que representa cada palabra en la\n",
        "# frase: \"El agua moja y el fuego quema\"\n",
        "w = torch.arange(7)\n",
        "\n",
        "# operación look-up y concatenación implicita de los embedding\n",
        "# de cada palabra\n",
        "x = E[w].view(-1)\n",
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "glAI0K_FHNb1",
        "outputId": "d6c25906-e14f-44da-d982-bc57342f0b0c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 2.,  2.,  0., -2.,  0.,  1., -2.,  1.,  1.,  0., -1.,  1.,  1.,  1.])"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creamos una función para convolucionar filtros en $U$ sobre una\n",
        "secuencia de _tokens_ representados por sus _embeddings_, el_input_ $x$. Esta convolución no tiene _padding_, pero si tiene el parámetro _stride_ para ajustar la convolución a la dimension de los _embeddings_."
      ],
      "metadata": {
        "id": "YPACxc3ZTl5b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def conv1D(x, U, s=1):\n",
        "  \"\"\"Simple convolución sobre input 1D sin padding, aka 'wide convolution'. Se\n",
        "     utiliza parámetro stride para ajustar la dimensión del output a la\n",
        "     dimension de los embeddings.\n",
        "        Input:\n",
        "          - x: secuencia de embeddings de los tokens\n",
        "          - U: matriz de filtros (kernels) con largo_kernel x numero_kernel\n",
        "          - s: stride\n",
        "\n",
        "        Notación:\n",
        "          - n: largo secuencia del input x (i.e.  x.shape[0])\n",
        "          - k: tamaño del filtro (i.e. U.shape[0])\n",
        "          - ell: identificador de filtro (i.e. U.shape[1])\n",
        "  \"\"\"\n",
        "  k = U.shape[0]\n",
        "  ell = U.shape[1]\n",
        "  n = x.shape[0]\n",
        "\n",
        "  # inicializamos el tensor output, de tamaño ((n-k+s)/s, ell)\n",
        "  out = torch.zeros(((n - k + s) // s, ell))\n",
        "\n",
        "  # un bias por cada filtro l, de tamaño (ell, )\n",
        "  b = torch.zeros(ell)\n",
        "\n",
        "  # por cada filtro l, convolucionar el filtro con la secuencia input\n",
        "  for l in range(ell):\n",
        "    # extraer filtro correspondiente\n",
        "    u = U[:, l]\n",
        "    for i in range(out.shape[0]):\n",
        "      # convolucionar filtro a tráves del input\n",
        "      out[i, l] = x[(s*i):((s*i)+k)].dot(u) + b[l]\n",
        "  return out"
      ],
      "metadata": {
        "id": "hkQh-F_tMfhC"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cada _output_ asociado al filtro se encuentra en las columnas, en este caso,\n",
        "replicamos los _inputs_ del ejercicio y obtenemos 3 secuencias de largo 5\n",
        "una vez que se convoluciona cada uno de los 3 filtros respectivos con el\n",
        "_input_."
      ],
      "metadata": {
        "id": "w6Htcuryb994"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "conv1D(x, U, s=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vYEZKlk_a45K",
        "outputId": "e207ec08-7751-4630-f552-aa83c88484cc"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-1.,  6.,  1.],\n",
              "        [ 2., -1., -4.],\n",
              "        [ 1., -1.,  2.],\n",
              "        [ 5.,  0., -3.],\n",
              "        [ 0., -1.,  0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Los resultados de la convolución previos aplicar la no-linealidad `tanh` elemento-a-elemento\n",
        "en cada vector:\n",
        "\n",
        "$$\\bar{y}^{(\\ell=1)}=(-1, 2, 1, 5, 0) \\in \\mathrm{R}^{5}$$\n",
        "$$\\bar{y}^{(\\ell=2)}=(6, -1, -1, 0, -1) \\in \\mathrm{R}^{5}$$\n",
        "$$\\bar{y}^{(\\ell=3)}=(1, -4, 2, -3, 0) \\in \\mathrm{R}^{5}$$"
      ],
      "metadata": {
        "id": "hSMTp47DfHAn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora aplicamos `tanh` y realizamos _max pooling_."
      ],
      "metadata": {
        "id": "sj2NRMS3eD-s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tanh(conv1D(x, U, s=2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wfb2wL4AfbVs",
        "outputId": "7db1f64d-c5b5-4a55-c2d4-2360fa2a82d7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.7616,  1.0000,  0.7616],\n",
              "        [ 0.9640, -0.7616, -0.9993],\n",
              "        [ 0.7616, -0.7616,  0.9640],\n",
              "        [ 0.9999,  0.0000, -0.9951],\n",
              "        [ 0.0000, -0.7616,  0.0000]])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comparemos el paso anterior, se observa como _max pooling_ agrega y\n",
        "selecciona para cada _feature_ (columna) el máximo valor. Compactando\n",
        "las versiones de output por cada filtro en un solo número."
      ],
      "metadata": {
        "id": "J2b0NV5zzf-T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.nn.functional.max_pool1d(tanh(conv1D(x, U, s=2)).permute(1,0), kernel_size=(3,)).permute(1,0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f0t_aY7RfG-v",
        "outputId": "ed83ba64-4432-4189-ba39-55b3027a789d"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.9640, 1.0000, 0.9640]])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Recurrent Neural Networks (1 punto)\n"
      ],
      "metadata": {
        "id": "A0rCwen3WREC"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U0et78Z4oKIq"
      },
      "source": [
        "### Pregunta 4 (0,5 puntos)\n",
        "Usando los embeddings de dos dimensiones de la pregunta anteror, la oración `el fuego quema` la podemos representar por una secuencia de vectores $(\\vec{x}_1,\\vec{x}_2,\\vec{x}_3)$, con $\\vec{x}_i \\in \\mathbb{R}^{d_x}$ y $d_x=2$.\n",
        "\n",
        "Tenemos una red recurrente *Elman* definidad como:\n",
        "\\begin{equation}\n",
        "\\begin{split}\n",
        "\\vec{s}_i &= R_{SRNN}\\left (\\vec{x}_i, \\vec{s}_{i-1}\\right ) = g \\left (\\vec{s}_{i-1}W^s + \\vec{x}_i W^x + \\vec{b}\\right ) \\\\\n",
        "\\vec{y}_i &= O_{SRNN}\\left(\\vec{s}_i\\right) = \\vec{s}_i \\\\\n",
        "\\end{split}\n",
        "\\end{equation}\n",
        "donde\n",
        "\\begin{equation}\n",
        "\\vec{s}_i, \\vec{y}_i \\in \\mathbb{R}^{d_s}, \\quad W^x \\in \\mathbb{R}^{d_x \\times d_s}, \\quad W^s \\in \\mathbb{R}^{d_s \\times d_s}, \\quad \\vec{b} \\in \\mathbb{R}^{d_s},\n",
        "\\end{equation}\n",
        "y los vectores de estado $s_i$ son de tres dimensiones, $ds= 3$.\n",
        "\n",
        "Sea\n",
        "\\begin{equation}\n",
        "\\begin{split}\n",
        "\\vec{s}_0 &= [0,0,0]\\\\\n",
        "W^x &= \\begin{pmatrix}\n",
        "0 &  0 & 1\\\\\n",
        "1 & -1 & 0\n",
        "\\end{pmatrix} \\\\\n",
        "W^s &= \\begin{pmatrix}\n",
        "1 & 0 &  1\\\\\n",
        "0 & 1 & -1\\\\\n",
        "1 & 1 &  1\n",
        "\\end{pmatrix} \\\\\n",
        "\\vec{b} &= [0, 0, 0] \\\\\n",
        "g(x) &= ReLu(x) = max(0, x)\n",
        "\\end{split}\n",
        "\\end{equation}\n",
        "\n",
        "<br>\n",
        "\n",
        "Calcule manualmente los valores de los vectores $\\vec{s}_1, \\vec{s}_2,\\vec{s}_3$ y de $\\vec{y}_1, \\vec{y}_2,\\vec{y}_3$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fim2W8JioPhL"
      },
      "source": [
        "**Respuesta**\n",
        "\n",
        "1. Definimos $\\vec{x}_1=[1,0]$,  $~\\vec{x}_2=[-1, 1]$, y $~\\vec{x}_3=[1, 1]$ según\n",
        "la posición original de las palabras `el fuego quema` en la tabla\n",
        "de _embeddings_ $E$ anterior.\n",
        "1. Sabemos que todos los estados $s_{i}$ tienen una dimensionalidad de $d_s=3$.\n",
        "Dado que el _bias_ es 0, por simplificación omitimos su notación en los\n",
        "siguientes pasos. Además, para esta red recurrente Elman, $O_{SRNN}(\\cdot)$ es\n",
        "la función identidad, por lo que el output $\\vec{y}_i$\n",
        "es simplemente el estado oculto $\\vec{s}_i$. Es decir, los calculos\n",
        "se concentran en estimar los estados ocultos.\n",
        "1. Computamos el primer estado oculto:\n",
        "\\begin{split}\n",
        "\\vec{s}_1 &= \\max(\\boldsymbol 0, ~\\vec{s}_0W^{s} + \\vec{x}_{1}W^{x}) \\\\\n",
        "          &= \\max(\\boldsymbol 0, ~[0,0,0]\\cdot W^{s} + [1,0]\\cdot W^{x}) \\\\\n",
        "          &= \\max(\\boldsymbol 0, [0,0,0] + [0, 0, 1]) \\\\\n",
        "          &=[0,0,1]\n",
        "\\end{split}\n",
        "1. Por lo tanto, $\\vec{y}_1=[0,0,1]$\n",
        "1. Actualizamos el estado oculto $\\vec{s}_2$ usando el estado anterior $\\vec{s}_1$ y el _input_ actual $\\vec{x}_2$:\n",
        "\\begin{split}\n",
        "\\vec{s}_2 &= \\max(\\boldsymbol 0,~\\vec{s}_1W^{s}+\\vec{x}_2W^x) \\\\\n",
        "          &= \\max(\\boldsymbol 0,~[0,0,1]\\cdot W^{s} + [-1,1]\\cdot W^{x}) \\\\\n",
        "          &= \\max(\\boldsymbol 0,~[1, 1, 1] + [1, -1, -1]) \\\\\n",
        "          &= \\max(\\boldsymbol 0, ~ [2, 0, 0]) \\\\\n",
        "          &= [2, 0, 0]\n",
        "\\end{split}\n",
        "1. Por lo tanto, $\\vec{y}_2=[2,0,0]$.\n",
        "1. Finalmente,\n",
        "\\begin{split}\n",
        "\\vec{s}_3 &= \\max(\\boldsymbol 0,~\\vec{s}_2W^{s}+\\vec{x}_3W^x) \\\\\n",
        "          &= \\max(\\boldsymbol 0,~[2,0,0]\\cdot W^{s} + [1,1]\\cdot W^{x}) \\\\\n",
        "          &= \\max(\\boldsymbol 0,~[2, 0, 2] + [1, -1, 1]) \\\\\n",
        "          &= \\max(\\boldsymbol 0, ~ [3, -1, 3]) \\\\\n",
        "          &= [3, 0, 3]\n",
        "\\end{split}\n",
        "1. $\\vec{y}_3=[3, 0, 3]$.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W4rAT6ELxRZW"
      },
      "source": [
        "### Pregunta 5 (0.5 puntos)\n",
        "¿De qué forma las RNN y las CNN logran aprender representaciones específicas\n",
        "para la tarea objetivo? Compare la forma en que las RNN y las CNN aprenden con los modelos que usan *features* diseñadas manualmente."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6AXbQSgA_t8"
      },
      "source": [
        "**Respuesta**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Las redes convolucionales (CNN) y redes recurrentes (RNN) son un tipo de arquitectura de redes neuronales (NN), las cuales como toda NN, pueden aprender representaciones y resolver alguna tarea objetivo en conjunto a partir de los datos. A diferencia de modelos más clásicos de NLP, los cuales desacoplan la representación de los datos con la solución de la tarea objetivo, y donde los modelos requieren un diseño previo y manual para construir la representación del texto (i.e. _feature engineering_), y así poder resolver la tarea en cuestion (e.g. clasificación de sentimientos). Las redes neuronales puede aprender representaciones complejas respecto a información sin una estructura obvia ni fácil de representar, y que incluso pueden ser reutilizadas en la solución de diversas tareas comparado con representaciones diseñadas \"a la medida\" para una tarea en específico.\n",
        "\n",
        "Respecto al caso particular de trabajar con texto, las arquitecturas de tipo CNN y RNN reciben tensores con secuencias de enteros, los cuales son _tokens_ que representan el texto a cierto nivel (e.g. caracteres, sub-palabras, palabras). Luego, estos enteros se utilizan como identificadores y pasan por una capa de _embeddings_, donde a través de una\n",
        "operación _look-up_, cada _token_ único (aka vocabulario) se le\n",
        "asocia un vector continuo de $d$ dimensiones. Estos son\n",
        "_features_ que representan a los _tokens_ y son aprendidos durante el entrenamiento de las redes.\n",
        "\n",
        "Las ventajas de las arquitecturas CNN y RNN es que el diseño de sus\n",
        "redes facilita aprender relaciones más complejas en los datos versus\n",
        "una arquitectura _fully connected_. En el caso de las CNN\n",
        "se pueden capturar estructuras locales a partir de sus filtros, de los cuales\n",
        "se pueden obtener _features_ de más alto nivel. En cambio, las arquitecturas\n",
        "RNN permiten capturar en un estado la historia de una secuencia de largo arbitrario, y contar como información adicional a la de un _token_\n",
        "en determinado momento, emergiendo conceptos como contexto y temporalidad\n",
        "que no existen una red _fully connected_.\n"
      ],
      "metadata": {
        "id": "zrL4q2Y_ouA4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pregunta 6: Redes Neuronales con Pytorch (3 puntos) 💬\n",
        "\n",
        "<center>\n",
        "<img src=\"https://www.anda.cl/wp-content/uploads/2021/03/0_5vNAtimPjYQr4W72.gif\" alt=\"chatbot\" width=\"400\">\n",
        "</center>"
      ],
      "metadata": {
        "id": "FRJkBpjWyHnb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En esta sección de la tarea deberán implementar un Chatbot que sea capaz de generar una conversación *“básica”* utilizando un dataset de *Star Wars*. **El objetivo** de esta pregunta es que puedan aplicar lo aprendido sobre redes neuronales utilizando Pytorch en un ejemplo práctico.  Durante el desarrollo, se espera que puedan diseñar un bot (que tendrá por atrás un clasificador) que sea capaz de clasificar diferentes etiquetas, cosa que una vez identificada la etiqueta entregue una respuesta acorde a lo preguntado.\n",
        "\n",
        "**Aviso:** Antes de comenzar con una descripción mas profunda de esta sección, les recomendamos que visualicen y se familiaricen con el dataset entregado, de esta forma comprenderán mejor la descripción del enunciado (aquí una pequeña ayudita 🆘)."
      ],
      "metadata": {
        "id": "GEla92bUymrQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "\n",
        "example_data = pd.read_json('https://raw.githubusercontent.com/dccuchile/CC6205/master/assignments/star_wars_chatbot.json')\n",
        "print(\"Cantidad de tags: \", example_data['intents'].shape[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0eKOGlMs3Dx-",
        "outputId": "171e42c3-6b67-4be5-f578-104109346acf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cantidad de tags:  16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A continuación, ejemplos del contenido del primer registro:"
      ],
      "metadata": {
        "id": "V-6fCE5fHkNS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "example_data['intents'][0]['patterns']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "axsi27BpHGOx",
        "outputId": "c89b3678-3195-4503-9a8e-dc678a3efbbf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Hi',\n",
              " 'Hey',\n",
              " 'How are you',\n",
              " 'Is anyone there?',\n",
              " 'Hello',\n",
              " 'Good day',\n",
              " \"What's up\",\n",
              " 'Yo!',\n",
              " 'Howdy',\n",
              " 'Nice to meet you.']"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example_data['intents'][0]['responses']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OV0vGdwoHeg3",
        "outputId": "23e98870-9157-49c2-d4de-6e54082fa7d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Hey',\n",
              " 'Hello, thanks for visiting.',\n",
              " 'Hi there, what can I do for you?',\n",
              " 'Hi there, how can I help?',\n",
              " 'Hello, there.',\n",
              " 'Hello Dear',\n",
              " 'Ooooo Hello, looking for someone or something?',\n",
              " 'Yes, I am here.',\n",
              " 'Listening carefully.',\n",
              " 'Ok, I am with you.']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example_data['intents'][0]['tag']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "0BnYez1oGtx3",
        "outputId": "0f52cc53-6aae-4bac-b64a-e8cc3cd9d817"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'greeting'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clases = pd.Series([\n",
        "    t[\"tag\"]\n",
        "    for t in example_data[\"intents\"]\n",
        "])\n",
        "clases.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v7frEa2cziKv",
        "outputId": "ed71948f-61bd-4d90-fb01-054cb0231383"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "greeting          1\n",
              "goodbye           1\n",
              "thanks            1\n",
              "tasks             1\n",
              "alive             1\n",
              "Menu              1\n",
              "help              1\n",
              "mission           1\n",
              "jedi              1\n",
              "sith              1\n",
              "bounti hounter    1\n",
              "funny             1\n",
              "about me          1\n",
              "creator           1\n",
              "myself            1\n",
              "stories           1\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = get_tokenizer(\"basic_english\")\n",
        "\n",
        "seq_len = pd.Series([\n",
        "    len([\n",
        "      token\n",
        "      for word in f.split()\n",
        "      for token in tokenizer(word)\n",
        "    ])\n",
        "    for p in example_data[\"intents\"]\n",
        "    for f in p[\"patterns\"]\n",
        "])\n",
        "\n",
        "seq_len.describe(), seq_len.quantile(.9)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VOHdDJQ-0Tlf",
        "outputId": "735374ce-6e97-4b44-9e14-97253ffc65e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(count    97.000000\n",
              " mean      5.175258\n",
              " std       2.622063\n",
              " min       1.000000\n",
              " 25%       4.000000\n",
              " 50%       5.000000\n",
              " 75%       7.000000\n",
              " max      13.000000\n",
              " dtype: float64,\n",
              " 9.0)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seq_len.plot(kind=\"hist\", bins=12);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "UTaF5g1J1-Ft",
        "outputId": "98dc0a08-eba6-4982-829b-16ae973b117f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjIAAAGdCAYAAAAIbpn/AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAeG0lEQVR4nO3de5DV9X3/8feRhQXpsgoKuzugoKJGQU0ktQTSxkAFZIiIbaLBgsr0ig1IrEJTNYxGBEdqbAjEjoJMqiRO1RgdbREI1sYbIhp7QVQUkItWhWXXYSW75/eH4/6y7oK7hwPf88HHY+bM5HzP2cNrzkR4zne/ZzeXz+fzAQCQoCOyHgAAUCghAwAkS8gAAMkSMgBAsoQMAJAsIQMAJEvIAADJEjIAQLLKsh5wsDU1NcXWrVujoqIicrlc1nMAgHbI5/Oxe/fuqKmpiSOO2Pd5l8M+ZLZu3Rr9+vXLegYAUIDNmzdH37599/n4YR8yFRUVEfHxG9GjR4+M1wAA7VFbWxv9+vVr/nd8Xw77kPnk20k9evQQMgCQmM+6LMTFvgBAsoQMAJAsIQMAJEvIAADJEjIAQLKEDACQLCEDACRLyAAAyRIyAECyhAwAkCwhAwAkS8gAAMkSMgBAsoQMAJCssqwHAK31n/lo1hNaefOWsVlPAGjFGRkAIFlCBgBIlpABAJIlZACAZAkZACBZQgYASJaQAQCSJWQAgGQJGQAgWUIGAEiWkAEAkiVkAIBkCRkAIFlCBgBIlpABAJIlZACAZAkZACBZQgYASJaQAQCSJWQAgGQJGQAgWUIGAEiWkAEAkiVkAIBkCRkAIFlCBgBIlpABAJKVacjMmTMnvvzlL0dFRUX07t07xo8fH+vXr2/xnD179sTUqVOjV69e8Xu/93tx0UUXxY4dOzJaDACUkkxDZvXq1TF16tR45plnYvny5bF3794477zzor6+vvk5V111Vfzyl7+M+++/P1avXh1bt26NCRMmZLgaACgVZVn+4Y8//niL+0uWLInevXvHCy+8EH/4h38Yu3btirvuuivuvffe+PrXvx4REYsXL44vfOEL8cwzz8Qf/MEfZDEbACgRJXWNzK5duyIiomfPnhER8cILL8TevXtj5MiRzc859dRT47jjjounn366zddoaGiI2traFjcA4PBUMiHT1NQU06dPj2HDhsWgQYMiImL79u3RpUuXOOqoo1o8t0+fPrF9+/Y2X2fOnDlRWVnZfOvXr9/Bng4AZKRkQmbq1KnxyiuvxLJlyw7odWbNmhW7du1qvm3evLlICwGAUpPpNTKfuPLKK+ORRx6JJ598Mvr27dt8vKqqKj766KPYuXNni7MyO3bsiKqqqjZfq7y8PMrLyw/2ZACgBGR6Riafz8eVV14ZDz74YKxcuTIGDBjQ4vGzzz47OnfuHCtWrGg+tn79+ti0aVMMHTr0UM8FAEpMpmdkpk6dGvfee2/84he/iIqKiubrXiorK6Nbt25RWVkZU6ZMiRkzZkTPnj2jR48e8bd/+7cxdOhQn1gCALINmYULF0ZExNe+9rUWxxcvXhyXXXZZRET84z/+YxxxxBFx0UUXRUNDQ4waNSp+/OMfH+KlAEApyjRk8vn8Zz6na9eusWDBgliwYMEhWAQApKRkPrUEANBRQgYASJaQAQCSJWQAgGQJGQAgWUIGAEiWkAEAkiVkAIBkCRkAIFlCBgBIlpABAJIlZACAZAkZACBZQgYASJaQAQCSJWQAgGQJGQAgWUIGAEiWkAEAkiVkAIBkCRkAIFlCBgBIlpABAJIlZACAZAkZACBZQgYASJaQAQCSJWQAgGQJGQAgWUIGAEiWkAEAkiVkAIBkCRkAIFlCBgBIlpABAJIlZACAZAkZACBZQgYASJaQAQCSJWQAgGQJGQAgWUIGAEiWkAEAkiVkAIBkCRkAIFlCBgBIlpABAJIlZACAZAkZACBZQgYASJaQAQCSJWQAgGQJGQAgWUIGAEiWkAEAkiVkAIBkCRkAIFlCBgBIlpABAJIlZACAZAkZACBZQgYASJaQAQCSJWQAgGQJGQAgWUIGAEiWkAEAkiVkAIBkCRkAIFmZhsyTTz4Z48aNi5qamsjlcvHQQw+1ePyyyy6LXC7X4jZ69OhsxgIAJSfTkKmvr48zzzwzFixYsM/njB49OrZt29Z8u++++w7hQgCglJVl+YePGTMmxowZs9/nlJeXR1VV1SFaBACkpOSvkfnVr34VvXv3jlNOOSX++q//Ot577739Pr+hoSFqa2tb3ACAw1NJh8zo0aNj6dKlsWLFipg7d26sXr06xowZE42Njfv8mjlz5kRlZWXzrV+/fodwMQBwKGX6raXPcvHFFzf/78GDB8cZZ5wRJ554YvzqV7+KESNGtPk1s2bNihkzZjTfr62tFTMAcJgq6TMyn3bCCSfEMcccE6+99to+n1NeXh49evRocQMADk9JhcyWLVvivffei+rq6qynAAAlINNvLdXV1bU4u7Jx48ZYt25d9OzZM3r27BmzZ8+Oiy66KKqqquL111+Pa665Jk466aQYNWpUhqsBgFKRacisWbMmzj333Ob7n1zbMnny5Fi4cGG8/PLLcc8998TOnTujpqYmzjvvvLjxxhujvLw8q8kAQAnJNGS+9rWvRT6f3+fj//Zv/3YI1wAAqUnqGhkAgN8lZACAZAkZACBZQgYASJaQAQCSJWQAgGQJGQAgWUIGAEiWkAEAkpXpT/aFrPWf+WjWEwA4AM7IAADJEjIAQLKEDACQLCEDACRLyAAAyRIyAECyCgqZN954o9g7AAA6rKCQOemkk+Lcc8+Nn/70p7Fnz55ibwIAaJeCQmbt2rVxxhlnxIwZM6Kqqir+8i//Mp577rlibwMA2K+CQuass86KH/7wh7F169a4++67Y9u2bTF8+PAYNGhQzJ8/P959991i7wQAaOWALvYtKyuLCRMmxP333x9z586N1157La6++uro169fTJo0KbZt21asnQAArRxQyKxZsyb+5m/+Jqqrq2P+/Plx9dVXx+uvvx7Lly+PrVu3xgUXXFCsnQAArRT0SyPnz58fixcvjvXr18f5558fS5cujfPPPz+OOOLjLhowYEAsWbIk+vfvX8ytAAAtFBQyCxcujCuuuCIuu+yyqK6ubvM5vXv3jrvuuuuAxgEA7E9BIbNhw4bPfE6XLl1i8uTJhbw8AEC7FHSNzOLFi+P+++9vdfz++++Pe+6554BHAQC0R0EhM2fOnDjmmGNaHe/du3fcfPPNBzwKAKA9CgqZTZs2xYABA1odP/7442PTpk0HPAoAoD0KCpnevXvHyy+/3Or4Sy+9FL169TrgUQAA7VFQyFxyySXxne98J1atWhWNjY3R2NgYK1eujGnTpsXFF19c7I0AAG0q6FNLN954Y7z55psxYsSIKCv7+CWamppi0qRJrpEBAA6ZgkKmS5cu8bOf/SxuvPHGeOmll6Jbt24xePDgOP7444u9DwBgnwoKmU+cfPLJcfLJJxdrCwBAhxQUMo2NjbFkyZJYsWJFvPPOO9HU1NTi8ZUrVxZlHADA/hQUMtOmTYslS5bE2LFjY9CgQZHL5Yq9CwDgMxUUMsuWLYuf//zncf755xd7DwBAuxX08esuXbrESSedVOwtAAAdUlDIfPe7340f/vCHkc/ni70HAKDdCvrW0lNPPRWrVq2Kxx57LE4//fTo3Llzi8cfeOCBoowDANifgkLmqKOOigsvvLDYWwAAOqSgkFm8eHGxdwAAdFhB18hERPz2t7+NJ554In7yk5/E7t27IyJi69atUVdXV7RxAAD7U9AZmbfeeitGjx4dmzZtioaGhvjjP/7jqKioiLlz50ZDQ0MsWrSo2DsBAFop6IzMtGnTYsiQIfHBBx9Et27dmo9feOGFsWLFiqKNAwDYn4LOyPzHf/xH/PrXv44uXbq0ON6/f/94++23izIMAOCzFHRGpqmpKRobG1sd37JlS1RUVBzwKACA9igoZM4777y4/fbbm+/ncrmoq6uLG264wa8tAAAOmYK+tXTbbbfFqFGj4rTTTos9e/bEt7/97diwYUMcc8wxcd999xV7IwBAmwoKmb59+8ZLL70Uy5Yti5dffjnq6upiypQpMXHixBYX/wIAHEwFhUxERFlZWVx66aXF3AIA0CEFhczSpUv3+/ikSZMKGgMA0BEFhcy0adNa3N+7d298+OGH0aVLlzjyyCOFDABwSBT0qaUPPvigxa2uri7Wr18fw4cPd7EvAHDIFPy7lj5t4MCBccstt7Q6WwMAcLAULWQiPr4AeOvWrcV8SQCAfSroGpmHH364xf18Ph/btm2LH/3oRzFs2LCiDAMA+CwFhcz48eNb3M/lcnHsscfG17/+9bjtttuKsQsA4DMVFDJNTU3F3gEA0GFFvUYGAOBQKuiMzIwZM9r93Pnz5xfyRwAAfKaCQubFF1+MF198Mfbu3RunnHJKRES8+uqr0alTp/jSl77U/LxcLleclQAAbSgoZMaNGxcVFRVxzz33xNFHHx0RH/+QvMsvvzy++tWvxne/+92ijgQAaEtB18jcdtttMWfOnOaIiYg4+uij46abbvKpJQDgkCkoZGpra+Pdd99tdfzdd9+N3bt3H/AoAID2KChkLrzwwrj88svjgQceiC1btsSWLVviX//1X2PKlCkxYcKEYm8EAGhTQdfILFq0KK6++ur49re/HXv37v34hcrKYsqUKXHrrbcWdSAAwL4UFDJHHnlk/PjHP45bb701Xn/99YiIOPHEE6N79+5FHQcAsD8H9APxtm3bFtu2bYuBAwdG9+7dI5/PF2sXAMBnKihk3nvvvRgxYkScfPLJcf7558e2bdsiImLKlCk+eg0AHDIFhcxVV10VnTt3jk2bNsWRRx7ZfPxb3/pWPP744+1+nSeffDLGjRsXNTU1kcvl4qGHHmrxeD6fj+uvvz6qq6ujW7duMXLkyNiwYUMhkwGAw1BBIfPv//7vMXfu3Ojbt2+L4wMHDoy33nqr3a9TX18fZ555ZixYsKDNx+fNmxd33HFHLFq0KJ599tno3r17jBo1Kvbs2VPIbADgMFPQxb719fUtzsR84v3334/y8vJ2v86YMWNizJgxbT6Wz+fj9ttvj3/4h3+ICy64ICIili5dGn369ImHHnooLr744kKmAwCHkYLOyHz1q1+NpUuXNt/P5XLR1NQU8+bNi3PPPbcowzZu3Bjbt2+PkSNHNh+rrKyMc845J55++ul9fl1DQ0PU1ta2uAEAh6eCzsjMmzcvRowYEWvWrImPPvoorrnmmviv//qveP/99+M///M/izJs+/btERHRp0+fFsf79OnT/Fhb5syZE7Nnzy7KBuD/6z/z0awntOnNW8ZmPQHIUEFnZAYNGhSvvvpqDB8+PC644IKor6+PCRMmxIsvvhgnnnhisTd2yKxZs2LXrl3Nt82bN2e6BwA4eDp8Rmbv3r0xevToWLRoUXzve987GJsiIqKqqioiInbs2BHV1dXNx3fs2BFnnXXWPr+uvLy8Q9fpAADp6vAZmc6dO8fLL798MLa0MGDAgKiqqooVK1Y0H6utrY1nn302hg4detD/fACg9BX0raVLL7007rrrrgP+w+vq6mLdunWxbt26iPj4At9169bFpk2bIpfLxfTp0+Omm26Khx9+OH7zm9/EpEmToqamJsaPH3/AfzYAkL6CLvb97W9/G3fffXc88cQTcfbZZ7f6HUvz589v1+usWbOmxaecZsyYERERkydPjiVLlsQ111wT9fX18Rd/8Rexc+fOGD58eDz++OPRtWvXQmYDAIeZXL4DvyDpjTfeiP79+8eIESP2/YK5XKxcubIo44qhtrY2KisrY9euXdGjR4+s51BiSvWTOLSfTy3B4am9/3536IzMwIEDY9u2bbFq1aqI+PhXEtxxxx2tPiINAHAodOgamU+fvHnssceivr6+qIMAANqroIt9P9GB70oBABRdh0Iml8tFLpdrdQwAIAsdukYmn8/HZZdd1vwD5/bs2RN/9Vd/1epTSw888EDxFgIA7EOHQmby5Mkt7l966aVFHQMA0BEdCpnFixcfrB0AAB12QBf7AgBkScgAAMkq6FcU8LFS/amwftIpnyel+N+h/wbh0HFGBgBIlpABAJIlZACAZAkZACBZQgYASJaQAQCSJWQAgGQJGQAgWUIGAEiWkAEAkiVkAIBkCRkAIFlCBgBIlpABAJIlZACAZJVlPYDi6z/z0awntOnNW8ZmPQGAw4wzMgBAsoQMAJAsIQMAJEvIAADJEjIAQLKEDACQLCEDACRLyAAAyRIyAECyhAwAkCwhAwAkS8gAAMkSMgBAsoQMAJAsIQMAJKss6wF8fvSf+WjWEwA4zDgjAwAkS8gAAMkSMgBAsoQMAJAsIQMAJEvIAADJEjIAQLKEDACQLCEDACRLyAAAyRIyAECyhAwAkCwhAwAkS8gAAMkSMgBAssqyHgBwuOk/89GsJ7TpzVvGZj0Bis4ZGQAgWUIGAEiWkAEAkiVkAIBkCRkAIFlCBgBIlpABAJIlZACAZAkZACBZQgYASJaQAQCSVdIh8/3vfz9yuVyL26mnnpr1LACgRJT8L408/fTT44knnmi+X1ZW8pMBgEOk5KugrKwsqqqqsp4BAJSgkv7WUkTEhg0boqamJk444YSYOHFibNq0ab/Pb2hoiNra2hY3AODwlMvn8/msR+zLY489FnV1dXHKKafEtm3bYvbs2fH222/HK6+8EhUVFW1+zfe///2YPXt2q+O7du2KHj16FHVf/5mPFvX1ACgNb94yNusJn3u1tbVRWVn5mf9+l3TIfNrOnTvj+OOPj/nz58eUKVPafE5DQ0M0NDQ036+trY1+/foJGQDaTchkr70hU/LXyPyuo446Kk4++eR47bXX9vmc8vLyKC8vP4SrAICslPw1Mr+rrq4uXn/99aiurs56CgBQAko6ZK6++upYvXp1vPnmm/HrX/86LrzwwujUqVNccsklWU8DAEpASX9racuWLXHJJZfEe++9F8cee2wMHz48nnnmmTj22GOzngYAlICSDplly5ZlPQEAKGEl/a0lAID9ETIAQLKEDACQLCEDACRLyAAAyRIyAECyhAwAkCwhAwAkS8gAAMkSMgBAsoQMAJAsIQMAJEvIAADJEjIAQLKEDACQLCEDACRLyAAAyRIyAECyhAwAkCwhAwAkS8gAAMkSMgBAsoQMAJAsIQMAJEvIAADJEjIAQLKEDACQLCEDACRLyAAAyRIyAECyhAwAkCwhAwAkS8gAAMkSMgBAsoQMAJAsIQMAJEvIAADJEjIAQLKEDACQLCEDACRLyAAAyRIyAECyhAwAkCwhAwAkS8gAAMkSMgBAsoQMAJAsIQMAJEvIAADJEjIAQLKEDACQLCEDACRLyAAAyRIyAECyhAwAkCwhAwAkS8gAAMkqy3oAAJSa/jMfzXpCMt68ZWymf74zMgBAsoQMAJAsIQMAJEvIAADJEjIAQLKEDACQLCEDACRLyAAAyRIyAECyhAwAkCwhAwAkK4mQWbBgQfTv3z+6du0a55xzTjz33HNZTwIASkDJh8zPfvazmDFjRtxwww2xdu3aOPPMM2PUqFHxzjvvZD0NAMhYyYfM/Pnz48///M/j8ssvj9NOOy0WLVoURx55ZNx9991ZTwMAMlaW9YD9+eijj+KFF16IWbNmNR874ogjYuTIkfH000+3+TUNDQ3R0NDQfH/Xrl0REVFbW1v0fU0NHxb9NQEgJQfj39fffd18Pr/f55V0yPzf//1fNDY2Rp8+fVoc79OnT/zv//5vm18zZ86cmD17dqvj/fr1OygbAeDzrPL2g/v6u3fvjsrKyn0+XtIhU4hZs2bFjBkzmu83NTXF+++/H7169YpcLpfhskOjtrY2+vXrF5s3b44ePXpkPaekea/az3vVft6rjvF+td/n7b3K5/Oxe/fuqKmp2e/zSjpkjjnmmOjUqVPs2LGjxfEdO3ZEVVVVm19TXl4e5eXlLY4dddRRB2tiyerRo8fn4v/oxeC9aj/vVft5rzrG+9V+n6f3an9nYj5R0hf7dunSJc4+++xYsWJF87GmpqZYsWJFDB06NMNlAEApKOkzMhERM2bMiMmTJ8eQIUPi93//9+P222+P+vr6uPzyy7OeBgBkrORD5lvf+la8++67cf3118f27dvjrLPOiscff7zVBcB8rLy8PG644YZW316jNe9V+3mv2s971THer/bzXrUtl/+szzUBAJSokr5GBgBgf4QMAJAsIQMAJEvIAADJEjKHiTlz5sSXv/zlqKioiN69e8f48eNj/fr1Wc8qebfcckvkcrmYPn161lNK1ttvvx2XXnpp9OrVK7p16xaDBw+ONWvWZD2r5DQ2NsZ1110XAwYMiG7dusWJJ54YN95442f+npjPgyeffDLGjRsXNTU1kcvl4qGHHmrxeD6fj+uvvz6qq6ujW7duMXLkyNiwYUM2Y0vA/t6vvXv3xrXXXhuDBw+O7t27R01NTUyaNCm2bt2a3eCMCZnDxOrVq2Pq1KnxzDPPxPLly2Pv3r1x3nnnRX19fdbTStbzzz8fP/nJT+KMM87IekrJ+uCDD2LYsGHRuXPneOyxx+K///u/47bbboujjz4662klZ+7cubFw4cL40Y9+FP/zP/8Tc+fOjXnz5sU//dM/ZT0tc/X19XHmmWfGggUL2nx83rx5cccdd8SiRYvi2Wefje7du8eoUaNiz549h3hpadjf+/Xhhx/G2rVr47rrrou1a9fGAw88EOvXr49vfOMbGSwtEXkOS++8804+IvKrV6/OekpJ2r17d37gwIH55cuX5//oj/4oP23atKwnlaRrr702P3z48KxnJGHs2LH5K664osWxCRMm5CdOnJjRotIUEfkHH3yw+X5TU1O+qqoqf+uttzYf27lzZ768vDx/3333ZbCwtHz6/WrLc889l4+I/FtvvXVoRpUYZ2QOU7t27YqIiJ49e2a8pDRNnTo1xo4dGyNHjsx6Skl7+OGHY8iQIfGnf/qn0bt37/jiF78Y//zP/5z1rJL0la98JVasWBGvvvpqRES89NJL8dRTT8WYMWMyXlbaNm7cGNu3b2/x32JlZWWcc8458fTTT2e4LB27du2KXC73ufy9ghEJ/GRfOq6pqSmmT58ew4YNi0GDBmU9p+QsW7Ys1q5dG88//3zWU0reG2+8EQsXLowZM2bE3//938fzzz8f3/nOd6JLly4xefLkrOeVlJkzZ0ZtbW2ceuqp0alTp2hsbIwf/OAHMXHixKynlbTt27dHRLT6ae19+vRpfox927NnT1x77bVxySWXfG5+keSnCZnD0NSpU+OVV16Jp556KuspJWfz5s0xbdq0WL58eXTt2jXrOSWvqakphgwZEjfffHNERHzxi1+MV155JRYtWiRkPuXnP/95/Mu//Evce++9cfrpp8e6deti+vTpUVNT473ioNi7d29885vfjHw+HwsXLsx6TmZ8a+kwc+WVV8YjjzwSq1atir59+2Y9p+S88MIL8c4778SXvvSlKCsri7Kysli9enXccccdUVZWFo2NjVlPLCnV1dVx2mmntTj2hS98ITZt2pTRotL1d3/3dzFz5sy4+OKLY/DgwfFnf/ZncdVVV8WcOXOynlbSqqqqIiJix44dLY7v2LGj+TFa+yRi3nrrrVi+fPnn9mxMhJA5bOTz+bjyyivjwQcfjJUrV8aAAQOynlSSRowYEb/5zW9i3bp1zbchQ4bExIkTY926ddGpU6esJ5aUYcOGtfoY/6uvvhrHH398RotK14cffhhHHNHyr9ROnTpFU1NTRovSMGDAgKiqqooVK1Y0H6utrY1nn302hg4dmuGy0vVJxGzYsCGeeOKJ6NWrV9aTMuVbS4eJqVOnxr333hu/+MUvoqKiovl7y5WVldGtW7eM15WOioqKVtcNde/ePXr16uV6ojZcddVV8ZWvfCVuvvnm+OY3vxnPPfdc3HnnnXHnnXdmPa3kjBs3Ln7wgx/EcccdF6effnq8+OKLMX/+/Ljiiiuynpa5urq6eO2115rvb9y4MdatWxc9e/aM4447LqZPnx433XRTDBw4MAYMGBDXXXdd1NTUxPjx47MbnaH9vV/V1dXxJ3/yJ7F27dp45JFHorGxsfnv+549e0aXLl2ymp2drD82RXFERJu3xYsXZz2t5Pn49f798pe/zA8aNChfXl6eP/XUU/N33nln1pNKUm1tbX7atGn54447Lt+1a9f8CSeckP/e976Xb2hoyHpa5latWtXm30+TJ0/O5/MffwT7uuuuy/fp0ydfXl6eHzFiRH79+vXZjs7Q/t6vjRs37vPv+1WrVmU9PRO5fN6PnQQA0uQaGQAgWUIGAEiWkAEAkiVkAIBkCRkAIFlCBgBIlpABAJIlZACAZAkZACBZQgYASJaQAQCSJWQAgGT9P1xU7zE/uukEAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Del dataset cargado podemos notar que este viene en un formato `JSON`, por lo que sus datos están almacenados en diccionarios. Las llaves de los diccionarios no son aleatorias y estos nos sirven para identificar puntos relevantes en el desarrollo del bot. A continuación, se realiza una pequeña descripción de las llaves:\n",
        "\n",
        "- `patterns`: Almacena los patrones con los que entrenaremos el modelo 😮, en otras palabras, es el corpus de entrenamiento que contiene solo preguntas o expresiones que deberá responder el bot.\n",
        "- `responses`: Son las respuestas 🙋 relacionadas a los `patterns`, estas las utilizaremos en una etapa posterior a la clasificación, para dar una respuesta aleatoría al usuario.\n",
        "- `tag`: Son las labels con las que entrenaremos nuestro modelo 💻.\n",
        "\n",
        "En síntesis, las `keys` relevantes para el entrenamiento de nuestra red neuronal serán `patterns` (corpus) y `tag` (etiquetas)."
      ],
      "metadata": {
        "id": "v6BvAWCw3zPM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Explicación de la tarea a realizar:"
      ],
      "metadata": {
        "id": "KlOAdMjSSzNN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Explicación de la tarea a realizar**: Implemente una Class llamada `CNNClassifier` que sea capaz de entrenar un modelo de texto a través de una red neuronal Feed Forward y una arquitectura convolucional (CNN 1D) [`torch.nn.Conv1d`](https://pytorch.org/docs/stable/generated/torch.nn.Conv1d.html#conv1d) . Para el diseño de las redes tienen completa libertad, pero se le aconseja que se guíen de la última auxiliar para la construcción. Es **importantísimo** que el modelo a crear posea una capa de `Embedding` que se genere en base al entrenamiento del modelo. Creado el modelo, construya una función batch para cargar los datos de entrenamiento del modelo.\n",
        "\n",
        "Construido el modelo, compare los resultados obtenidos para una red feed forward y una cnn. Para la comprobación de sus resultados ejecute el chatbot y pruebelo, ¿qué configuración tiene mejores resultados?, ¿a qué se deberan estos resultados?\n",
        "\n",
        "Ojo que un ejemplo de prueba con el chatbot puede ser (agregue mas preguntas ud):\n",
        "\n",
        "```\n",
        "Let's chat! (type 'finish_chat' to finish the chat)\n",
        "You: hi\n",
        "GA-97: Yes, I am here.\n",
        "You: can you tell me a joke?\n",
        "GA-97: Have you tried the gluten-free Wookiee treats? No, but I heard they are a little Chewy.\n",
        "```\n",
        "\n",
        "El resto del código referido a la ejecución del chat se los entregamos, por lo que no deberían tener mayores problemas 😸 (en caso de tener problemas con su código, puede modificar cualquier parte sugerida siempre y cuando cumpla lo solicitado).\n",
        "\n",
        "**Igual [mucho texto](https://i0.wp.com/elgeneracionalpost.com/wp-content/uploads/2020/07/mucho-texto.jpg?fit=1280%2C720&ssl=1).... En resumen, ¿Qué se solicita?:**\n",
        "\n",
        "- [X] Diseñar una red neuronal Feed Forward.\n",
        "- [x] Diseñar un red convolucional.\n",
        "- [X] Utilizar una capa de embeddings para generar representaciones vectoriales del corpus.\n",
        "- [X] Crear el método forward de la clase `CNNClassifier`.\n",
        "- [X] Crear la función BATCH.\n",
        "- [X] Probar el modelo y comparar los resultados obtenidos con la red Feed Forward y la red CNN. Comente sus resultados de forma cualitativa, señalando con qué tipo de red obtuvo mejores resultados con el chatbot.\n",
        "\n",
        "**Nota-1:** El modelo creado debe tener la opción de entrenar a traves de una feed forward y una CNN. Esto no significa que entrenará una FF y una CN, el modelo deberá recibir un booleano que especifique que tipo de red utilizará.\n",
        "\n",
        "**Nota-2:** El dataset se descargará automáticamente en la sección `Carga de Dataset 📚`, no os preocupéis."
      ],
      "metadata": {
        "id": "9yGApnWVI4cO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Pasemos al Código 🦾\n",
        "\n",
        "Esqueleto propuesto (se **RECOMIENDA** que cambien **SOLO** la red neuronal y la función Batch) 🦴:"
      ],
      "metadata": {
        "id": "a4bKfAdEy3oD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Instalamos librerias necesarias e importamos 😀"
      ],
      "metadata": {
        "id": "RUwxivx2MpMV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Esto toma su tiempo en ejecutarse\n",
        "%%capture\n",
        "!pip install torch==1.8.0+cu111 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "!pip install torchtext==0.9.0"
      ],
      "metadata": {
        "id": "TjSZkBsk1H4f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import json\n",
        "import torch\n",
        "import random\n",
        "from random import choice\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
        "\n",
        "from torch.optim import SGD, lr_scheduler\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.autograd import Variable\n",
        "\n",
        "from itertools import zip_longest\n",
        "\n",
        "import plotly.express as px\n",
        "\n",
        "import numpy as np\n",
        "import nltk\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "\n",
        "from sklearn.metrics import classification_report, accuracy_score"
      ],
      "metadata": {
        "id": "RfZ6SL-Q1Kwd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Carga de Dataset 📚"
      ],
      "metadata": {
        "id": "oj-Epe7XJLrL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# we obtain the dataset\n",
        "!wget 'https://raw.githubusercontent.com/dccuchile/CC6205/master/assignments/star_wars_chatbot.json'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hvlLqYRrVN6l",
        "outputId": "29d9b91f-6db6-4910-868f-9c3879dc1f12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-06-10 13:35:39--  https://raw.githubusercontent.com/dccuchile/CC6205/master/assignments/star_wars_chatbot.json\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 14469 (14K) [text/plain]\n",
            "Saving to: ‘star_wars_chatbot.json’\n",
            "\n",
            "\rstar_wars_chatbot.j   0%[                    ]       0  --.-KB/s               \rstar_wars_chatbot.j 100%[===================>]  14.13K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-06-10 13:35:39 (36.6 MB/s) - ‘star_wars_chatbot.json’ saved [14469/14469]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset using json\n",
        "with open('star_wars_chatbot.json', 'r') as f:\n",
        "    dataset = json.load(f)\n",
        "\n",
        "# Create a vocab with the dataset and get the number of classes that have\n",
        "tokenizer = get_tokenizer(\"basic_english\")\n",
        "vocab = build_vocab_from_iterator(tokenizer(x) for list_words in dataset['intents'] for x in list_words['patterns'])\n",
        "\n",
        "# num_classes = len(dataset['intents']) # esto es demasiado ordinario\n",
        "num_classes = clases.nunique()\n",
        "\n",
        "# Add <unk> and <pad> -> 0, 1 respectively. Makes <unk> default token for missing\n",
        "# mapping word->?->'<unk>'\n",
        "UNK_IDX = 0\n",
        "vocab.insert_token('<unk>', UNK_IDX)\n",
        "vocab.set_default_index(UNK_IDX)\n",
        "vocab.insert_token('<pad>', 1)\n",
        "\n",
        "# Define a list with the labels\n",
        "labels = sorted(set([tag for tag in [intents['tag'] for intents in dataset['intents']]]))\n",
        "\n",
        "# Define a train_list where we can find the info in the format: [(tag_0, text_0)...,(tag_n-1, text_n-1)]\n",
        "train_list = [(labels.index(intents['tag']), text) for intents in dataset['intents'] for text in intents['patterns']]"
      ],
      "metadata": {
        "id": "MbbIsFUG1TXW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# first 5 word index, 0, ..., 4\n",
        "vocab.get_itos()[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vi9Gal8pelYs",
        "outputId": "0b7339dc-5934-4669-e734-3522e1715883"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<unk>', '<pad>', '.', '?', 'you']"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Creación del modelo (2 puntos en total)"
      ],
      "metadata": {
        "id": "a52SUNKPJQxi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Construya el modelo\n",
        "class CNNClassifier(nn.Module):\n",
        "    def __init__(self, vocab_size, sequence_length, embed_dim=32, num_classes=10,\n",
        "                 use_cnn=False, cnn_pool_channels=24, cnn_kernel_size=3,\n",
        "                 pad_idx=1, hidden_sizes=[100, 90]):\n",
        "      super().__init__()\n",
        "      self.vocab_size = vocab_size\n",
        "      self.embed_dim = embed_dim\n",
        "      self.T = sequence_length\n",
        "      self.num_classes = num_classes\n",
        "\n",
        "      self.use_cnn = use_cnn\n",
        "\n",
        "      #padidx -> Se indica el índice del token de padding para que no le afecten los pesos\n",
        "      self.embedding = nn.Embedding(vocab_size, embed_dim, pad_idx)\n",
        "\n",
        "      if self.use_cnn:\n",
        "        # self.K es el tamaño del kernel y la idea es que cubra K tokens de largo la dimension del embedding\n",
        "        self.K = self.embed_dim * cnn_kernel_size\n",
        "\n",
        "        # la convolucion mueve una ventana de largo self.K, y va saltando\n",
        "        # según un stride de self.embed_dim, así salta la representación\n",
        "        # de 1 token según las dimensiones del embedding\n",
        "        self.conv_layer = nn.Conv1d(in_channels=1, out_channels=cnn_pool_channels,\n",
        "                               kernel_size=self.K, stride=self.embed_dim)\n",
        "\n",
        "        # TODO: utilizar nn.MaxPool1d en vez de torch.max(..)[0]\n",
        "        #self.pool_layer = nn.MaxPool1d(kernel_size=self.K)\n",
        "        self.linear = nn.Linear(cnn_pool_channels, self.num_classes)\n",
        "\n",
        "      else:\n",
        "        self.hidden_len = len(hidden_sizes)\n",
        "        self.feed_forward = None\n",
        "        layers = []\n",
        "\n",
        "        if self.hidden_len > 0:\n",
        "          # Caso capas ocultas:\n",
        "          # primer mapeo de capa de embedding a primera capa oculta\n",
        "          layers.append(nn.Linear(self.T * self.embed_dim, hidden_sizes[0]))\n",
        "          layers.append(nn.Tanh())\n",
        "\n",
        "          # agregar capas intermedias\n",
        "          for i, s in enumerate(hidden_sizes[1:]):\n",
        "            layers.append(\n",
        "                torch.nn.Linear(hidden_sizes[i], s)\n",
        "            )\n",
        "            # agregar no-linaridad entre capas excepto en la última. Generalmente\n",
        "            # no se agrega nada entre la última capa oculta y capa de output\n",
        "            if i != (self.hidden_len - 2):\n",
        "              layers.append(nn.Tanh())\n",
        "\n",
        "          # agregar capa final\n",
        "          layers.append(nn.Linear(hidden_sizes[-1], self.num_classes))\n",
        "          self.feed_forward = torch.nn.ModuleList(layers)\n",
        "\n",
        "        else:\n",
        "          # Caso sin capas ocultas: se mapea la capa de embedding directo a las clases\n",
        "          layers.append(nn.Linear(self.T * self.embed_dim, num_classes))\n",
        "          self.feed_forward = torch.nn.ModuleList(layers)\n",
        "          #self.feed_forward = nn.Linear(self.T * self.embed_dim, num_classes)\n",
        "\n",
        "    def init_weights(self):\n",
        "      # Esto puede ser util para inicializar los pesos\n",
        "      pass\n",
        "\n",
        "    def forward(self, x):\n",
        "      # Dimensiones del input x:          # (B, T)\n",
        "      out = self.embedding(x)             # (B, T, E)\n",
        "      out = out.view(out.shape[0], -1)    # (B, T * E)\n",
        "      if self.use_cnn:\n",
        "        # --------------------------------# Caso arquitectura CNN, C = # de filtros o kernels, K: tamaño del kernel\n",
        "        out = out.unsqueeze(1)            # (B, C, T * E)\n",
        "        out = self.conv_layer(out)        # (B, C, T * E - K + 1)\n",
        "        out = torch.relu(out)\n",
        "        out = torch.max(out, dim=2)[0]    # (B, C)\n",
        "        out = self.linear(out)            # (B, num_classes)\n",
        "        return out\n",
        "      else:\n",
        "        # --------------------------------# Caso arquitectura FeedForward, H[i] = Dimension Hidden i\n",
        "        for layer in self.feed_forward:   # (B, T * E) -> (B, H[i])        - caso con capas ocultas\n",
        "          out = layer(out)                # (B, T * E) -> (B, num_classes) - caso sin capas ocultas\n",
        "        return out                        # (B, num_classes)"
      ],
      "metadata": {
        "id": "n-vQ24tMJG5H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Función Batch 👷 (0,5 puntos)"
      ],
      "metadata": {
        "id": "dGN-T0JoJtmS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defina su función de BATCH\n",
        "def generate_batch(batch, max_sequence=60, train=True, debug=False):\n",
        "  \"\"\"\n",
        "    Collate Function para pasar a función DataLoader y procesar un batch de\n",
        "    observaciones con la estructura: (label, [\"esto\", \"es\", \"un\", \"text\"]).\n",
        "\n",
        "    Se utiliza tokenizer y vocab (como variables globales) inicializados\n",
        "    previamente para el corpus de entrenamiento.\n",
        "\n",
        "    Se retorna una tupla con dos tensores: ((B, T), (B, ))\n",
        "    Donde B: batch size\n",
        "          T: tamaño de la secuencia más larga en el batch\n",
        "  \"\"\"\n",
        "\n",
        "  #debug\n",
        "\n",
        "  if debug:\n",
        "    for text in batch:\n",
        "      print(\"texto\", text)\n",
        "\n",
        "      for word in text[0].split():\n",
        "        print(\"palabra\", word)\n",
        "\n",
        "        for token in tokenizer(word):\n",
        "          print(\"token\", token)\n",
        "\n",
        "\n",
        "  # creamos una lista con una lista de enteros representando los token de cada texto\n",
        "  text_i = 1 if train else 0\n",
        "  x = [[vocab[token] for word in text[text_i].split() for token in tokenizer(word)] for text in batch]\n",
        "\n",
        "  # Normalizamos usando el máximo entregado vía parámetro (i.e. max_sequence)\n",
        "  #-----------------------------------------------------------------------------\n",
        "  x = torch.tensor([\n",
        "      xs + [vocab['<pad>']] * (max_sequence - len(xs))\n",
        "      if len(xs) <= max_sequence\n",
        "      else xs[:max_sequence]\n",
        "      for xs in x\n",
        "  ])\n",
        "\n",
        "  if train:\n",
        "    # creamos tensor con valores del target para cada observación del batch\n",
        "    y = torch.tensor([obs[0] for obs in batch])\n",
        "    return x, y\n",
        "\n",
        "  return x"
      ],
      "metadata": {
        "id": "K1AZpXc7JxTa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Sanity Checks 💊\n",
        "\n",
        "@Cristóbal: esta sección la agregué para realizar pruebas antes de llegar y saltar a entrenar.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "L2Bi4lWPqy4I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En esta sección realizamos pruebas en la construcción de `DataLoader`, inicializción de la red, y que los datos fluyan correctamente\n",
        "a través del modelo."
      ],
      "metadata": {
        "id": "7c_yAG-Kq7IB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora podemos usar nuestra función para procesar los batches y obtener\n",
        "un tensor `y` para las clases, de tamano `(B,)`, junto a un tensor con las\n",
        "secuencias tokenizadas y normalizadas de tamaño `(B, T)`. Siendo `B` el\n",
        "tamaño del _batch_, y `T` el largo de la secuencia máxima en el dataset\n",
        "de entrenamiento post proceso."
      ],
      "metadata": {
        "id": "3tApDaTdiJvR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE=8\n",
        "dl = DataLoader(train_list, batch_size=BATCH_SIZE, collate_fn=generate_batch, shuffle=True)"
      ],
      "metadata": {
        "id": "qBByY9bqSDr0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Dimensiones (x, y) de un batch con tamaño {BATCH_SIZE}:\\n\")\n",
        "xs, ys = next(iter(dl))\n",
        "print(f\"xs: {xs.shape}\")\n",
        "print(f\"ys: {ys.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W7Qbqf8mS9xX",
        "outputId": "3f4fef39-0b98-43c7-bed7-94a1922b87e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dimensiones (x, y) de un batch con tamaño 8:\n",
            "\n",
            "xs: torch.Size([8, 60])\n",
            "ys: torch.Size([8])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# verificar integer con mapeo stoi de vocab...\n",
        "#vocab[tokenizer('Tell')[0]]"
      ],
      "metadata": {
        "id": "F0aoCvrgTfJM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Caso FeedForward sin capas ocultas:** mapeo directo de los _embeddings_ a las clases."
      ],
      "metadata": {
        "id": "IfxGDZHS8I00"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_CLASSES=10\n",
        "USE_CNN=False\n",
        "model = CNNClassifier(vocab_size=len(vocab), sequence_length=60, embed_dim=32,\n",
        "                      num_classes=NUM_CLASSES, use_cnn=USE_CNN, cnn_pool_channels=None,\n",
        "                      cnn_kernel_size=None, pad_idx=vocab['<pad>'],\n",
        "                      hidden_sizes=[])"
      ],
      "metadata": {
        "id": "U-fXIr4T8MUH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Batch size: {xs.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8vUMZBkX8PTC",
        "outputId": "f6c86dd0-9d0b-4d98-f47e-f2f866ee5cc9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch size: torch.Size([8, 60])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Arquitectura del modelo, caso embedding mapeado directo al output:\\n\\n {model}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4WS7hV7i8Qli",
        "outputId": "e0dea0c1-f7f0-4946-bd0b-583e9643e761"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Arquitectura del modelo, caso embedding mapeado directo al output:\n",
            "\n",
            " CNNClassifier(\n",
            "  (embedding): Embedding(132, 32, padding_idx=1)\n",
            "  (feed_forward): ModuleList(\n",
            "    (0): Linear(in_features=1920, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Pruebas realizadas con arquitectura diseñada para {NUM_CLASSES} clases de output\\n\")\n",
        "print(f\"Forward pass y dimensiones del output: {model(xs).shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XeC6LSHC8YTM",
        "outputId": "fe7361c8-c07c-43eb-9d6e-97cd9c7be868"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pruebas realizadas con arquitectura diseñada para 10 clases de output\n",
            "\n",
            "Forward pass y dimensiones del output: torch.Size([8, 10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Caso FeedForward una sola capa oculta:**"
      ],
      "metadata": {
        "id": "jMB5ffr07HHE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_CLASSES=20\n",
        "USE_CNN=False\n",
        "model = CNNClassifier(vocab_size=len(vocab), sequence_length=60, embed_dim=32,\n",
        "                      num_classes=NUM_CLASSES, use_cnn=USE_CNN, cnn_pool_channels=None,\n",
        "                      cnn_kernel_size=None, pad_idx=vocab['<pad>'],\n",
        "                      hidden_sizes=[200])"
      ],
      "metadata": {
        "id": "c6l6oOT37yAw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Batch size: {xs.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ic2BPbu372Bw",
        "outputId": "838ca5ff-cd4b-44e6-a92b-1fa7474c6cba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch size: torch.Size([8, 60])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Arquitectura del modelo, caso una sola capa oculta:\\n\\n {model}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N0VdQPx373cd",
        "outputId": "058a6881-1f9f-4347-cd27-3131d56a1d02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Arquitectura del modelo, caso una sola capa oculta:\n",
            "\n",
            " CNNClassifier(\n",
            "  (embedding): Embedding(132, 32, padding_idx=1)\n",
            "  (feed_forward): ModuleList(\n",
            "    (0): Linear(in_features=1920, out_features=200, bias=True)\n",
            "    (1): Tanh()\n",
            "    (2): Linear(in_features=200, out_features=20, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Pruebas realizadas con arquitectura diseñada para {NUM_CLASSES} clases de output\\n\")\n",
        "print(f\"Forward pass y dimensiones del output: {model(xs).shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d2mtJRKS8Aqx",
        "outputId": "ef9285d2-c88a-4338-dfed-8af6f154c710"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pruebas realizadas con arquitectura diseñada para 20 clases de output\n",
            "\n",
            "Forward pass y dimensiones del output: torch.Size([8, 20])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Caso FeedForward multiples capas ocultas:**"
      ],
      "metadata": {
        "id": "w6VpYApL6c9y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_CLASSES=4\n",
        "USE_CNN=False\n",
        "model = CNNClassifier(vocab_size=len(vocab), sequence_length=60, embed_dim=32,\n",
        "                      num_classes=NUM_CLASSES, use_cnn=USE_CNN, cnn_pool_channels=None,\n",
        "                      cnn_kernel_size=None, pad_idx=vocab['<pad>'],\n",
        "                      hidden_sizes=[20, 25, 50, 25, 20])"
      ],
      "metadata": {
        "id": "4O18NlF1l9Sg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Batch size: {xs.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SBXhpB2QsMqq",
        "outputId": "0ad312a5-afc0-483e-9b9e-3fe2e3489424"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch size: torch.Size([8, 60])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Arquitectura del modelo, caso capas ocultas:\\n\\n {model}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZW8EfVcX2dcs",
        "outputId": "983cc512-fd8e-4cfb-817a-44fccbfdcc3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Arquitectura del modelo, caso capas ocultas:\n",
            "\n",
            " CNNClassifier(\n",
            "  (embedding): Embedding(132, 32, padding_idx=1)\n",
            "  (feed_forward): ModuleList(\n",
            "    (0): Linear(in_features=1920, out_features=20, bias=True)\n",
            "    (1): Tanh()\n",
            "    (2): Linear(in_features=20, out_features=25, bias=True)\n",
            "    (3): Tanh()\n",
            "    (4): Linear(in_features=25, out_features=50, bias=True)\n",
            "    (5): Tanh()\n",
            "    (6): Linear(in_features=50, out_features=25, bias=True)\n",
            "    (7): Tanh()\n",
            "    (8): Linear(in_features=25, out_features=20, bias=True)\n",
            "    (9): Linear(in_features=20, out_features=4, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Pruebas realizadas con arquitectura diseñada para {NUM_CLASSES} clases de output\\n\")\n",
        "print(f\"Forward pass y dimensiones del output: {model(xs).shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SjDwXsnArbyz",
        "outputId": "23630570-0f79-4765-c1c9-9c967ac9f7ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pruebas realizadas con arquitectura diseñada para 4 clases de output\n",
            "\n",
            "Forward pass y dimensiones del output: torch.Size([8, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Caso CNN:**"
      ],
      "metadata": {
        "id": "LmkKZdl1NjCt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_CLASSES=4\n",
        "NUM_FEATURES=64\n",
        "USE_CNN=True\n",
        "model = CNNClassifier(vocab_size=len(vocab), sequence_length=60, embed_dim=32,\n",
        "                      num_classes=NUM_CLASSES, use_cnn=USE_CNN,\n",
        "                      cnn_pool_channels=NUM_FEATURES, cnn_kernel_size=8,\n",
        "                      pad_idx=vocab['<pad>'], hidden_sizes=None)"
      ],
      "metadata": {
        "id": "5j7aJ6C2NlYD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Batch size: {xs.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Nn3pEDkOCQM",
        "outputId": "98e91fc2-d501-4fd8-8470-7502536b1f17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch size: torch.Size([8, 60])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"La operación de convolución entrega {NUM_FEATURES} features para realizar la clasificación por la última capa lineal\\n\")\n",
        "print(f\"Arquitectura del modelo, caso capas ocultas:\\n\\n {model}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d2zhap9JOD8e",
        "outputId": "309314d3-34f5-4f25-b401-46f362e1de6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "La operación de convolución entrega 64 features para realizar la clasificación por la última capa lineal\n",
            "\n",
            "Arquitectura del modelo, caso capas ocultas:\n",
            "\n",
            " CNNClassifier(\n",
            "  (embedding): Embedding(132, 32, padding_idx=1)\n",
            "  (conv_layer): Conv1d(1, 64, kernel_size=(256,), stride=(32,))\n",
            "  (linear): Linear(in_features=64, out_features=4, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Pruebas realizadas con arquitectura diseñada para {NUM_CLASSES} clases de output\\n\")\n",
        "print(f\"Forward pass y dimensiones del output: {model(xs).shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "44jNDDkHOWCF",
        "outputId": "382e0773-44f4-42e0-ee3c-2ccfad70d21a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pruebas realizadas con arquitectura diseñada para 4 clases de output\n",
            "\n",
            "Forward pass y dimensiones del output: torch.Size([8, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Entrenamiento 🥊"
      ],
      "metadata": {
        "id": "YChwpNrrNRBe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### Funciones"
      ],
      "metadata": {
        "id": "3Op1hOqgsg33"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def training_loop(model, train_list, epochs=1000, batch_size=16, lr=1e-1,\n",
        "                  optimizer=SGD, criterion=nn.CrossEntropyLoss,\n",
        "                  scheduler=lr_scheduler, print_every=100):\n",
        "\n",
        "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "  print(f\"GPU is avaible: {device}\")\n",
        "\n",
        "  model = model.to(device)\n",
        "\n",
        "  optimizer = optimizer(model.parameters(), lr=lr)\n",
        "  criterion = criterion().to(device)\n",
        "  scheduler = scheduler.LambdaLR(optimizer, lr_lambda=[lambda epoch: .9 ** (epoch // 10)])\n",
        "\n",
        "  print(f'train: {len(train_list)} elements')\n",
        "\n",
        "  # We train the model using the intents\n",
        "  loss_list = []\n",
        "  acc_list = []\n",
        "\n",
        "  for epoch in range(1, epochs):\n",
        "    train_loader = DataLoader(train_list, batch_size=BATCH_SIZE, shuffle=True,\n",
        "                              collate_fn=lambda x: generate_batch(x, SEQ_LEN))\n",
        "\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    y_true_list = []\n",
        "    y_pred_list = []\n",
        "\n",
        "    for i, (texts, cls) in enumerate(train_loader):\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      texts = texts.to(device)\n",
        "      cls = cls.to(device)\n",
        "\n",
        "      output = model(texts)\n",
        "\n",
        "      probs = torch.softmax(output, dim=1)\n",
        "      y_hat = probs.argmax(dim=-1)\n",
        "      y_true_list.extend(cls.cpu().detach().tolist())\n",
        "      y_pred_list.extend(y_hat.cpu().detach().tolist())\n",
        "\n",
        "      loss = criterion(output, cls)\n",
        "      total_loss += loss.item()\n",
        "\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "    acc = accuracy_score(y_true_list, y_pred_list)\n",
        "    acc_list.append(acc)\n",
        "    loss_list.append(total_loss)\n",
        "\n",
        "    if epoch % print_every == 0:\n",
        "      print(\n",
        "          f'Epoch: {epoch + 1} \\t Epoch loss: {round(total_loss, 3)}'\n",
        "          f' \\t Epoc Acc (train): {round(acc, 5)}'\n",
        "      )\n",
        "\n",
        "  print(f'\\nfinal loss: {total_loss:.4f}')\n",
        "  print(f\"Best acc: {max(acc_list)} (Época {np.argmax(acc_list)})\")\n",
        "  return model, loss_list, acc_list\n",
        "\n",
        "\n",
        "def text_single_input(model, q_text, seq_len, **kwargs):\n",
        "  padded_X = generate_batch(\n",
        "    [(q_text,)], seq_len, False, **kwargs\n",
        "  )\n",
        "\n",
        "  model.eval()\n",
        "  output = model(padded_X)\n",
        "\n",
        "  _, predicted = torch.max(output, dim=1)\n",
        "  return labels[predicted]\n",
        "\n",
        "\n",
        "def save_model(model, data_dict, file_name):\n",
        "  # We save de model using pytorch (this is optional, just to learn how to do this in pytorch)\n",
        "  data_dict[\"model_state\"] = model.state_dict()\n",
        "  torch.save(data_dict, file_name)\n",
        "\n",
        "  print(f'training complete. file saved to {file_name}')\n",
        "\n",
        "def chat_bot(responses, model, seq_len, bot_name=\"GA-97\", **kwargs):\n",
        "  device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "  model.eval()\n",
        "\n",
        "  print(\"Let's chat! (type 'finish_chat' to finish the chat)\")\n",
        "\n",
        "  while True:\n",
        "      q_text = input(\"You: \")\n",
        "\n",
        "      if q_text == 'finish_chat':\n",
        "          break\n",
        "\n",
        "      padded_X = generate_batch(\n",
        "          [(q_text,)], seq_len, False, **kwargs\n",
        "      )\n",
        "\n",
        "      output = model(padded_X)\n",
        "      _, predicted = torch.max(output, dim=1)\n",
        "\n",
        "      tag = labels[predicted.item()]\n",
        "\n",
        "      probs = torch.softmax(output, dim=1)\n",
        "      prob = probs[0][predicted.item()]\n",
        "\n",
        "      if prob.item() > 0.50:\n",
        "        print(f\"{bot_name}: {random.choice(responses[tag])}\")\n",
        "\n",
        "      else:\n",
        "        print(f\"{bot_name}: My model can't understand you...\")"
      ],
      "metadata": {
        "id": "NwCt9PCRmJqR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### Experimentos"
      ],
      "metadata": {
        "id": "DBXqFyQsslc1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hiperparámetros generales a los distintos experimentos\n",
        "BATCH_SIZE = 16\n",
        "LR = 1e-1\n",
        "INPUT_SIZE = len(vocab)\n",
        "OUTPUT_SIZE = num_classes\n",
        "SEQ_LEN = 10"
      ],
      "metadata": {
        "id": "m9n2vQAjpoBj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mlp_1 = CNNClassifier(INPUT_SIZE, SEQ_LEN, num_classes=OUTPUT_SIZE,\n",
        "                      use_cnn=False, hidden_sizes=[])\n",
        "\n",
        "mlp_1, loss_mlp_1, acc_mlp_1 = training_loop(mlp_1, train_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OFcru6ROpW3d",
        "outputId": "9d967c7f-dc72-4b42-ba7e-6a1043ae2895"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU is avaible: cpu\n",
            "train: 97 elements\n",
            "Epoch: 101 \t Epoch loss: 0.117 \t Epoc Acc (train): 1.0\n",
            "Epoch: 201 \t Epoch loss: 0.074 \t Epoc Acc (train): 1.0\n",
            "Epoch: 301 \t Epoch loss: 0.036 \t Epoc Acc (train): 1.0\n",
            "Epoch: 401 \t Epoch loss: 0.035 \t Epoc Acc (train): 1.0\n",
            "Epoch: 501 \t Epoch loss: 0.023 \t Epoc Acc (train): 1.0\n",
            "Epoch: 601 \t Epoch loss: 0.021 \t Epoc Acc (train): 1.0\n",
            "Epoch: 701 \t Epoch loss: 0.015 \t Epoc Acc (train): 1.0\n",
            "Epoch: 801 \t Epoch loss: 0.013 \t Epoc Acc (train): 1.0\n",
            "Epoch: 901 \t Epoch loss: 0.011 \t Epoc Acc (train): 1.0\n",
            "\n",
            "final loss: 0.0119\n",
            "Best acc: 1.0 (Época 17)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mlp_2 = CNNClassifier(INPUT_SIZE, SEQ_LEN, num_classes=OUTPUT_SIZE,\n",
        "                      use_cnn=False, hidden_sizes=[10])\n",
        "\n",
        "mlp_2, loss_mlp_2, acc_mlp_2 = training_loop(mlp_2, train_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J2grMqR6sqUj",
        "outputId": "32583d13-bd72-49ea-b860-ba7cc50dfc63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU is avaible: cpu\n",
            "train: 97 elements\n",
            "Epoch: 101 \t Epoch loss: 0.449 \t Epoc Acc (train): 1.0\n",
            "Epoch: 201 \t Epoch loss: 0.198 \t Epoc Acc (train): 1.0\n",
            "Epoch: 301 \t Epoch loss: 0.118 \t Epoc Acc (train): 1.0\n",
            "Epoch: 401 \t Epoch loss: 0.073 \t Epoc Acc (train): 1.0\n",
            "Epoch: 501 \t Epoch loss: 0.066 \t Epoc Acc (train): 1.0\n",
            "Epoch: 601 \t Epoch loss: 0.062 \t Epoc Acc (train): 1.0\n",
            "Epoch: 701 \t Epoch loss: 0.04 \t Epoc Acc (train): 1.0\n",
            "Epoch: 801 \t Epoch loss: 0.038 \t Epoc Acc (train): 1.0\n",
            "Epoch: 901 \t Epoch loss: 0.03 \t Epoc Acc (train): 1.0\n",
            "\n",
            "final loss: 0.0303\n",
            "Best acc: 1.0 (Época 48)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_1 = CNNClassifier(INPUT_SIZE, SEQ_LEN, num_classes=OUTPUT_SIZE,\n",
        "                      use_cnn=True, hidden_sizes=[])\n",
        "\n",
        "cnn_1, loss_cnn_2, acc_cnn_2 = training_loop(cnn_1, train_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l4r64iv6s7ZG",
        "outputId": "49c222bc-a3b0-4496-fc04-ba519220cb60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU is avaible: cpu\n",
            "train: 97 elements\n",
            "Epoch: 101 \t Epoch loss: 0.08 \t Epoc Acc (train): 1.0\n",
            "Epoch: 201 \t Epoch loss: 0.024 \t Epoc Acc (train): 1.0\n",
            "Epoch: 301 \t Epoch loss: 0.014 \t Epoc Acc (train): 1.0\n",
            "Epoch: 401 \t Epoch loss: 0.012 \t Epoc Acc (train): 1.0\n",
            "Epoch: 501 \t Epoch loss: 0.007 \t Epoc Acc (train): 1.0\n",
            "Epoch: 601 \t Epoch loss: 0.006 \t Epoc Acc (train): 1.0\n",
            "Epoch: 701 \t Epoch loss: 0.005 \t Epoc Acc (train): 1.0\n",
            "Epoch: 801 \t Epoch loss: 0.004 \t Epoc Acc (train): 1.0\n",
            "Epoch: 901 \t Epoch loss: 0.003 \t Epoc Acc (train): 1.0\n",
            "\n",
            "final loss: 0.0037\n",
            "Best acc: 1.0 (Época 22)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### A probar! 🧪"
      ],
      "metadata": {
        "id": "9dlS4_X-L3DN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "q_text = \"'Do you know any joke?'\" # this must classify the label \"funny\"\n",
        "\n",
        "print(text_single_input(mlp_1, q_text, SEQ_LEN))\n",
        "print(text_single_input(mlp_2, q_text, SEQ_LEN))\n",
        "print(text_single_input(cnn_1, q_text, SEQ_LEN))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6IhhAKFXL3eH",
        "outputId": "e6809cde-6de9-4c01-83a9-382f285dab60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Menu\n",
            "sith\n",
            "Menu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ya pero prometiste hacer un chatbot, no una simple clasificación...."
      ],
      "metadata": {
        "id": "udemze3zL549"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Guardamos modelo 🦺 (opcional)"
      ],
      "metadata": {
        "id": "OpSYGx2tL0tC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_dict = {\n",
        "  \"input_size\": INPUT_SIZE,\n",
        "  \"output_size\": OUTPUT_SIZE,\n",
        "  \"sequence_length\": SEQ_LEN,\n",
        "  \"labels\": labels\n",
        "}\n",
        "\n",
        "mlp_1_dict = data_dict.copy()\n",
        "mlp_1_dict[\"hidden_sizes\"] = []\n",
        "mlp_1_dict[\"use_cnn\"] = False\n",
        "\n",
        "mlp_2_dict = data_dict.copy()\n",
        "mlp_2_dict[\"hidden_sizes\"] = [10]\n",
        "mlp_2_dict[\"use_cnn\"] = False\n",
        "\n",
        "cnn_1_dict = data_dict.copy()\n",
        "cnn_1_dict[\"hidden_sizes\"] = []\n",
        "cnn_1_dict[\"use_cnn\"] = True\n",
        "\n",
        "save_model(mlp_1, mlp_1_dict, \"mlp_1.pth\")\n",
        "save_model(mlp_2, mlp_2_dict, \"mlp_2.pth\")\n",
        "save_model(cnn_1, cnn_1_dict, \"cnn_1.pth\")"
      ],
      "metadata": {
        "id": "ZBC4TyiqLzDv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0bca8586-70ec-4cf6-d51a-f1b63f7a56ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training complete. file saved to mlp_1.pth\n",
            "training complete. file saved to mlp_2.pth\n",
            "training complete. file saved to cnn_1.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Chatbot 💬"
      ],
      "metadata": {
        "id": "ZYClbTtsMCjE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "responses = {key['tag']: key['responses'] for key in dataset['intents']}\n",
        "\n",
        "chat_bot(responses, mlp_1, SEQ_LEN)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UyaApiA2v0sk",
        "outputId": "b65cdeec-f14d-44ec-9735-957f9401103a"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Let's chat! (type 'finish_chat' to finish the chat)\n",
            "You: hello there\n",
            "GA-97: Hi there, how can I help?\n",
            "You: I have a bad feeling about this\n",
            "GA-97: My model can't understand you...\n",
            "You: finish_chat\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat_bot(responses, mlp_2, SEQ_LEN)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1xiDZUDFx43s",
        "outputId": "6c55a741-8f13-42eb-b7d4-2f536cf94851"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Let's chat! (type 'finish_chat' to finish the chat)\n",
            "You: hello there\n",
            "GA-97: Hey\n",
            "You: I have a bad feeling about this\n",
            "GA-97: be carreful with your choise: Fuzzy Tauntaun, Bloody Rancor, Jedi Mind Trick, T-16 Skyhopper, Yub Nub, Jet Juice, Hyperdrive, Rancor Beer.\n",
            "You: finish_chat\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat_bot(responses, cnn_1, SEQ_LEN)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EcP1Sv2hyCmw",
        "outputId": "ea687a21-4375-4027-e599-16e1628d99fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Let's chat! (type 'finish_chat' to finish the chat)\n",
            "You: hello there\n",
            "GA-97: Hello, there.\n",
            "You: I have a bad feeling about this\n",
            "GA-97: be carreful with your choise: Fuzzy Tauntaun, Bloody Rancor, Jedi Mind Trick, T-16 Skyhopper, Yub Nub, Jet Juice, Hyperdrive, Rancor Beer.\n",
            "You: finish_chat\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Comente los resultados aquí (0,5 puntos)"
      ],
      "metadata": {
        "id": "5Hu2QTuSURCt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dada la baja cantidad de datos proporcionados, no se realizó una división adicional para datos de prueba. Por tanto, solo se realizó medición de accuracy de cada época en los datos de entrenamiento. En los tres experimentos realizados, se observa un aparente sobreajuste, ya que todos alcanzan un accuracy de 1 en los datos de entrenamiento. Nuevamente, esto se deba a la baja cantidad de datos proporcionados, ya que las redes neuronales, al ser modelos complejos, requieren de gran cantidad de datos para alcanzar un buen poder predictivo y a la vez buena capacidad de generalización.\n",
        "\n",
        "En cuanto a las pruebas de inferencia realizadas, es difícil realizar conclusiones frente a la baja cantidad de casos, pero al menos para una frase en particular se observa que el modelo MLP sin capas ocultas no logra obtener una probabilidad sobre 0.5.\n",
        "\n",
        "En conclusión, si bien las distintas arquitecturas propuestas parecen indicar que se obtiene un mejor desempeño, ya sea con una red MLP con capas ocultas, o con una CNN de 1 dimensión, se requiere de mayor cantidad de datos de entrenamiento (y una partición de test para evaluar desempeño) para determinar qué arquitectura es mejor para resolver esta tarea."
      ],
      "metadata": {
        "id": "fdFV63WVUX32"
      }
    }
  ]
}